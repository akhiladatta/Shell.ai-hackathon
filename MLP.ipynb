{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile \n",
    "# with ZipFile('20210101.zip', 'r') as zipObj:\n",
    "#    # Extract all the contents of zip file in current directory\n",
    "#    zipObj.extractall()\n",
    "\n",
    "# # !pip3 install lxml \n",
    "# # t_df = pd.read_csv('test/1/weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('2018.txt')\n",
    "df2 = pd.read_csv('2019.txt')\n",
    "df3 = pd.read_csv('2020.txt')\n",
    "df4 = pd.read_csv('2021.txt')\n",
    "# df5 = pd.read_csv('2017_imgs.csv')\n",
    "df5 = pd.read_csv('2021_recent.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3,df4], ignore_index=True)\n",
    "df = df.drop(['Solar Eclipse Shading'],axis = 1)\n",
    "df = pd.concat([df, df5], ignore_index=True)\n",
    "df.columns = ['Date', 'MST','GHI', 'DNI','Zenith Angle','Azimuth Angle','Dry Temp','Wet Temp','Dew Temp', 'RH','TCC','Wind Speed','Wind Direction','Pressure','Precipitation','Snow Depth','Moisture','Albedo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MST</th>\n",
       "      <th>GHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>Zenith Angle</th>\n",
       "      <th>Azimuth Angle</th>\n",
       "      <th>Dry Temp</th>\n",
       "      <th>Wet Temp</th>\n",
       "      <th>Dew Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>TCC</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Direction</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Snow Depth</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Albedo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:06</td>\n",
       "      <td>6.92743</td>\n",
       "      <td>-0.029810</td>\n",
       "      <td>89.88053</td>\n",
       "      <td>118.69174</td>\n",
       "      <td>8.88</td>\n",
       "      <td>1.949</td>\n",
       "      <td>-7.351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>299.1</td>\n",
       "      <td>814.620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:07</td>\n",
       "      <td>8.75574</td>\n",
       "      <td>0.044716</td>\n",
       "      <td>89.73395</td>\n",
       "      <td>118.85123</td>\n",
       "      <td>9.24</td>\n",
       "      <td>2.006</td>\n",
       "      <td>-7.594</td>\n",
       "      <td>27.49</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>292.6</td>\n",
       "      <td>814.606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:08</td>\n",
       "      <td>10.16190</td>\n",
       "      <td>0.372632</td>\n",
       "      <td>89.58648</td>\n",
       "      <td>119.01100</td>\n",
       "      <td>9.69</td>\n",
       "      <td>2.276</td>\n",
       "      <td>-7.624</td>\n",
       "      <td>26.60</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.45</td>\n",
       "      <td>291.5</td>\n",
       "      <td>814.632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:09</td>\n",
       "      <td>11.81470</td>\n",
       "      <td>159.069000</td>\n",
       "      <td>89.43807</td>\n",
       "      <td>119.17104</td>\n",
       "      <td>9.91</td>\n",
       "      <td>2.406</td>\n",
       "      <td>-7.594</td>\n",
       "      <td>26.28</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>305.9</td>\n",
       "      <td>814.617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:10</td>\n",
       "      <td>13.30970</td>\n",
       "      <td>212.480000</td>\n",
       "      <td>89.28871</td>\n",
       "      <td>119.33135</td>\n",
       "      <td>10.21</td>\n",
       "      <td>2.528</td>\n",
       "      <td>-7.772</td>\n",
       "      <td>25.36</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>294.3</td>\n",
       "      <td>814.599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063277</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:30</td>\n",
       "      <td>5.13126</td>\n",
       "      <td>-0.565152</td>\n",
       "      <td>89.35451</td>\n",
       "      <td>240.65056</td>\n",
       "      <td>18.01</td>\n",
       "      <td>7.275</td>\n",
       "      <td>-4.025</td>\n",
       "      <td>21.12</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>292.4</td>\n",
       "      <td>819.896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063278</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:31</td>\n",
       "      <td>4.74091</td>\n",
       "      <td>-0.496351</td>\n",
       "      <td>89.50345</td>\n",
       "      <td>240.81060</td>\n",
       "      <td>18.00</td>\n",
       "      <td>7.240</td>\n",
       "      <td>-4.060</td>\n",
       "      <td>21.07</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>286.6</td>\n",
       "      <td>819.894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063279</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:32</td>\n",
       "      <td>4.32255</td>\n",
       "      <td>-0.427550</td>\n",
       "      <td>89.65144</td>\n",
       "      <td>240.97036</td>\n",
       "      <td>18.00</td>\n",
       "      <td>7.234</td>\n",
       "      <td>-4.066</td>\n",
       "      <td>21.06</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>289.7</td>\n",
       "      <td>819.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063280</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:33</td>\n",
       "      <td>3.88617</td>\n",
       "      <td>-0.437379</td>\n",
       "      <td>89.79851</td>\n",
       "      <td>241.12985</td>\n",
       "      <td>17.96</td>\n",
       "      <td>7.310</td>\n",
       "      <td>-3.990</td>\n",
       "      <td>21.25</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.45</td>\n",
       "      <td>299.4</td>\n",
       "      <td>819.918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063281</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:34</td>\n",
       "      <td>3.47374</td>\n",
       "      <td>-0.525837</td>\n",
       "      <td>89.94474</td>\n",
       "      <td>241.28908</td>\n",
       "      <td>17.78</td>\n",
       "      <td>7.236</td>\n",
       "      <td>-3.964</td>\n",
       "      <td>21.54</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>296.3</td>\n",
       "      <td>819.902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063282 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date    MST       GHI         DNI  Zenith Angle  Azimuth Angle  \\\n",
       "0        12/1/2017  07:06   6.92743   -0.029810      89.88053      118.69174   \n",
       "1        12/1/2017  07:07   8.75574    0.044716      89.73395      118.85123   \n",
       "2        12/1/2017  07:08  10.16190    0.372632      89.58648      119.01100   \n",
       "3        12/1/2017  07:09  11.81470  159.069000      89.43807      119.17104   \n",
       "4        12/1/2017  07:10  13.30970  212.480000      89.28871      119.33135   \n",
       "...            ...    ...       ...         ...           ...            ...   \n",
       "1063277  12/1/2021  16:30   5.13126   -0.565152      89.35451      240.65056   \n",
       "1063278  12/1/2021  16:31   4.74091   -0.496351      89.50345      240.81060   \n",
       "1063279  12/1/2021  16:32   4.32255   -0.427550      89.65144      240.97036   \n",
       "1063280  12/1/2021  16:33   3.88617   -0.437379      89.79851      241.12985   \n",
       "1063281  12/1/2021  16:34   3.47374   -0.525837      89.94474      241.28908   \n",
       "\n",
       "         Dry Temp  Wet Temp  Dew Temp     RH  TCC  Wind Speed  Wind Direction  \\\n",
       "0            8.88     1.949    -7.351  28.77   -1        3.45           299.1   \n",
       "1            9.24     2.006    -7.594  27.49   -1        3.70           292.6   \n",
       "2            9.69     2.276    -7.624  26.60   -1        2.45           291.5   \n",
       "3            9.91     2.406    -7.594  26.28   -1        3.20           305.9   \n",
       "4           10.21     2.528    -7.772  25.36   -1        3.45           294.3   \n",
       "...           ...       ...       ...    ...  ...         ...             ...   \n",
       "1063277     18.01     7.275    -4.025  21.12   -1        3.70           292.4   \n",
       "1063278     18.00     7.240    -4.060  21.07   -1        3.45           286.6   \n",
       "1063279     18.00     7.234    -4.066  21.06   -1        3.45           289.7   \n",
       "1063280     17.96     7.310    -3.990  21.25   -1        2.45           299.4   \n",
       "1063281     17.78     7.236    -3.964  21.54   -1        2.70           296.3   \n",
       "\n",
       "         Pressure  Precipitation  Snow Depth  Moisture  Albedo  \n",
       "0         814.620            0.0       0.490       0.0     0.0  \n",
       "1         814.606            0.0       0.623       0.0     0.0  \n",
       "2         814.632            0.0       0.520       0.0     0.0  \n",
       "3         814.617            0.0       0.515       0.0     0.0  \n",
       "4         814.599            0.0       0.531       0.0     0.0  \n",
       "...           ...            ...         ...       ...     ...  \n",
       "1063277   819.896            0.0      -0.219       0.0     0.0  \n",
       "1063278   819.894            0.0      -0.217       0.0     0.0  \n",
       "1063279   819.900            0.0      -0.253       0.0     0.0  \n",
       "1063280   819.918            0.0      -0.352       0.0     0.0  \n",
       "1063281   819.902            0.0      -0.385       0.0     0.0  \n",
       "\n",
       "[1063282 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.concat([df5,df], ignore_index=True)\n",
    "# df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GHI</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>385.443902</td>\n",
       "      <td>302.393122</td>\n",
       "      <td>-2.89371</td>\n",
       "      <td>118.864250</td>\n",
       "      <td>322.367000</td>\n",
       "      <td>605.216750</td>\n",
       "      <td>1473.88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNI</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>461.994091</td>\n",
       "      <td>402.638444</td>\n",
       "      <td>-15.73200</td>\n",
       "      <td>3.031123</td>\n",
       "      <td>487.150500</td>\n",
       "      <td>876.658000</td>\n",
       "      <td>1088.22000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zenith Angle</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>59.103354</td>\n",
       "      <td>19.139813</td>\n",
       "      <td>16.30284</td>\n",
       "      <td>45.119928</td>\n",
       "      <td>61.610625</td>\n",
       "      <td>74.494555</td>\n",
       "      <td>90.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azimuth Angle</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>179.998820</td>\n",
       "      <td>65.771194</td>\n",
       "      <td>58.41938</td>\n",
       "      <td>121.841260</td>\n",
       "      <td>179.992035</td>\n",
       "      <td>238.157205</td>\n",
       "      <td>301.58467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dry Temp</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>14.476784</td>\n",
       "      <td>10.706395</td>\n",
       "      <td>-22.74000</td>\n",
       "      <td>6.402000</td>\n",
       "      <td>15.220000</td>\n",
       "      <td>23.110000</td>\n",
       "      <td>37.81000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wet Temp</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>6.434731</td>\n",
       "      <td>7.011710</td>\n",
       "      <td>-23.07000</td>\n",
       "      <td>1.156000</td>\n",
       "      <td>6.936000</td>\n",
       "      <td>12.568000</td>\n",
       "      <td>20.39500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dew Temp</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>-1.590654</td>\n",
       "      <td>8.006333</td>\n",
       "      <td>-33.93600</td>\n",
       "      <td>-7.563000</td>\n",
       "      <td>-1.757000</td>\n",
       "      <td>4.677000</td>\n",
       "      <td>19.75500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>38.898452</td>\n",
       "      <td>23.928393</td>\n",
       "      <td>1.94700</td>\n",
       "      <td>20.420000</td>\n",
       "      <td>32.020000</td>\n",
       "      <td>52.150000</td>\n",
       "      <td>100.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCC</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>22.105960</td>\n",
       "      <td>449.624590</td>\n",
       "      <td>-7999.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind Speed</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>2.948327</td>\n",
       "      <td>2.003500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>23.45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind Direction</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>132.244410</td>\n",
       "      <td>104.051609</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>37.450000</td>\n",
       "      <td>107.700000</td>\n",
       "      <td>255.700000</td>\n",
       "      <td>360.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>816.425841</td>\n",
       "      <td>5.542931</td>\n",
       "      <td>742.23600</td>\n",
       "      <td>813.369000</td>\n",
       "      <td>817.028000</td>\n",
       "      <td>820.263000</td>\n",
       "      <td>847.96300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>0.524214</td>\n",
       "      <td>2.434816</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Depth</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>-12.523690</td>\n",
       "      <td>327.697840</td>\n",
       "      <td>-7999.00000</td>\n",
       "      <td>-0.042000</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>30.26000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moisture</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>0.065645</td>\n",
       "      <td>0.244644</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albedo</th>\n",
       "      <td>1063282.0</td>\n",
       "      <td>-0.032665</td>\n",
       "      <td>167.970480</td>\n",
       "      <td>-99999.00000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count        mean         std          min         25%  \\\n",
       "GHI             1063282.0  385.443902  302.393122     -2.89371  118.864250   \n",
       "DNI             1063282.0  461.994091  402.638444    -15.73200    3.031123   \n",
       "Zenith Angle    1063282.0   59.103354   19.139813     16.30284   45.119928   \n",
       "Azimuth Angle   1063282.0  179.998820   65.771194     58.41938  121.841260   \n",
       "Dry Temp        1063282.0   14.476784   10.706395    -22.74000    6.402000   \n",
       "Wet Temp        1063282.0    6.434731    7.011710    -23.07000    1.156000   \n",
       "Dew Temp        1063282.0   -1.590654    8.006333    -33.93600   -7.563000   \n",
       "RH              1063282.0   38.898452   23.928393      1.94700   20.420000   \n",
       "TCC             1063282.0   22.105960  449.624590  -7999.00000   14.000000   \n",
       "Wind Speed      1063282.0    2.948327    2.003500      0.00000    1.700000   \n",
       "Wind Direction  1063282.0  132.244410  104.051609      0.00000   37.450000   \n",
       "Pressure        1063282.0  816.425841    5.542931    742.23600  813.369000   \n",
       "Precipitation   1063282.0    0.524214    2.434816      0.00000    0.000000   \n",
       "Snow Depth      1063282.0  -12.523690  327.697840  -7999.00000   -0.042000   \n",
       "Moisture        1063282.0    0.065645    0.244644      0.00000    0.000000   \n",
       "Albedo          1063282.0   -0.032665  167.970480 -99999.00000    0.175000   \n",
       "\n",
       "                       50%         75%         max  \n",
       "GHI             322.367000  605.216750  1473.88000  \n",
       "DNI             487.150500  876.658000  1088.22000  \n",
       "Zenith Angle     61.610625   74.494555    90.00000  \n",
       "Azimuth Angle   179.992035  238.157205   301.58467  \n",
       "Dry Temp         15.220000   23.110000    37.81000  \n",
       "Wet Temp          6.936000   12.568000    20.39500  \n",
       "Dew Temp         -1.757000    4.677000    19.75500  \n",
       "RH               32.020000   52.150000   100.20000  \n",
       "TCC              36.000000   88.000000   100.00000  \n",
       "Wind Speed        2.700000    3.700000    23.45000  \n",
       "Wind Direction  107.700000  255.700000   360.00000  \n",
       "Pressure        817.028000  820.263000   847.96300  \n",
       "Precipitation     0.000000    0.000000    42.16000  \n",
       "Snow Depth        0.216000    0.634000    30.26000  \n",
       "Moisture          0.000000    0.000000     1.00000  \n",
       "Albedo            0.199000    0.239900     2.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe().transpose()\n",
    "def calc_time(time):\n",
    "    a, b = time.split(':')\n",
    "    return ( int(a)*60 + int(b) )\n",
    "\n",
    "def calc_day(days_list):\n",
    "    unique_days_list = list(days_list.unique())\n",
    "    return ([unique_days_list.index(day)+1 for day in days_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tGnfYnKwE-KY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71089/1330820370.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Albedo'][df['Albedo']>1] = 1\n"
     ]
    }
   ],
   "source": [
    "df['Snow Depth'].replace(-7999, np.NaN, inplace  = True)\n",
    "df['Snow Depth'].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "df['Albedo'].replace(-99999, np.NaN, inplace  = True)\n",
    "df['Albedo'].fillna(method=\"ffill\", inplace=True)\n",
    "df['Albedo'][df['Albedo']>1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Time'] = [calc_time(i) for i in df['MST']]\n",
    "df['day'] = calc_day(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_nearest(series):\n",
    "    fact = series.astype('category').factorize()\n",
    "\n",
    "    series_cat = pd.Series(fact[0]).replace(-1, np.nan) # get string as categorical (-1 is NaN)\n",
    "    series_cat_interp = series_cat.interpolate(\"nearest\") # interpolate categorical\n",
    "\n",
    "    cat_to_string = {i:x for i,x in enumerate(fact[1])} # dict connecting category to string\n",
    "    series_str_interp = series_cat_interp.map(cat_to_string) # turn category back to string\n",
    "\n",
    "    return series_str_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_df = df.copy(deep=False)\n",
    "\n",
    "imgs_df['Normal imgs NE'] = np.NaN\n",
    "imgs_df['Normal imgs UE'] = np.NaN\n",
    "imgs_df['Proj imgs NE'] = np.NaN\n",
    "imgs_df['Proj imgs UE'] = np.NaN\n",
    "imgs_df['BRBG imgs'] = np.NaN\n",
    "imgs_df['CDOC imgs'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "import os\n",
    "for dir in os.listdir('Images/'):\n",
    "    all_images.append(listdir_fullpath('Images/' + dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_day = [] \n",
    "for i in range(len(all_images)):\n",
    "    images_per_day.append(len(all_images[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_flat = list(np.concatenate(all_images).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lst = []\n",
    "for time in imgs_df['MST']:\n",
    "    time_lst.append(time.split(':')[0] + time.split(':')[1])\n",
    "imgs_df['MST_img'] = time_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(s):\n",
    "    if(len(s) == 1):\n",
    "        return '0'+s\n",
    "    else:\n",
    "        return s\n",
    "date_lst = []\n",
    "for date in imgs_df['Date']:\n",
    "    date_lst.append( date.split('/')[2] + pad(date.split('/')[0]) + pad(date.split('/')[1]) )\n",
    "imgs_df['Date_img'] = date_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dict = dict.fromkeys(all_images_flat , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = []\n",
    "c2 = []\n",
    "c3 = []\n",
    "c4 = []\n",
    "c5 = []\n",
    "c6 = []\n",
    "for i in range(len(imgs_df)):\n",
    "    for j in list(imgs_df.columns[20:26]):\n",
    "        if(j == imgs_df.columns[20]):\n",
    "            x = 'Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_11.jpg'\n",
    "            if x in paths_dict.keys():\n",
    "                c1.append('Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_11.jpg')\n",
    "            else:\n",
    "                c1.append(np.NaN)\n",
    "        if(j == imgs_df.columns[21]):\n",
    "            x = 'Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_12.jpg'\n",
    "            if x in paths_dict.keys():\n",
    "                c2.append('Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_12.jpg')\n",
    "            else:\n",
    "                c2.append(np.NaN)\n",
    "        if(j == imgs_df.columns[22]):\n",
    "            x = 'Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_11_NE.jpg'\n",
    "            if x in paths_dict.keys():\n",
    "                c3.append('Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_11_NE.jpg')\n",
    "            else:\n",
    "                c3.append(np.NaN)\n",
    "        if(j == imgs_df.columns[23]):\n",
    "            x = 'Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_12_UE.jpg'\n",
    "            if x in paths_dict.keys():\n",
    "                c4.append('Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_12_UE.jpg')\n",
    "            else:\n",
    "                c4.append(np.NaN)\n",
    "        if(j == imgs_df.columns[24]):\n",
    "            x = 'Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_1112_BRBG.png'\n",
    "            if x in paths_dict.keys():\n",
    "                c5.append('Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_1112_BRBG.png')\n",
    "            else:\n",
    "                c5.append(np.NaN)\n",
    "        if(j == imgs_df.columns[25]):\n",
    "            x = 'Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_1112_CDOC.png'\n",
    "            if x in paths_dict.keys():\n",
    "                c6.append('Images/'+ date_lst[i]+'/'+ date_lst[i] + time_lst[i] + '00' + '_1112_CDOC.png')\n",
    "            else:\n",
    "                c6.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_df[imgs_df.columns[20]] = c1\n",
    "imgs_df[imgs_df.columns[21]] = c2 \n",
    "imgs_df[imgs_df.columns[22]] = c3\n",
    "imgs_df[imgs_df.columns[23]] = c4 \n",
    "imgs_df[imgs_df.columns[24]]= c5\n",
    "imgs_df[imgs_df.columns[25]] = c6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_imgs_days = ['20180417', '20180418', '20180419','20181228','20181231','20190101','20200404','20200405','20210829','20211025','20211104']\n",
    "for day in del_imgs_days:\n",
    "    imgs_df = imgs_df[imgs_df['Date_img'] != day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "aRsmaOkCKNgB",
    "outputId": "763a9657-c879-4246-9ef6-efa76e1eb2b5"
   },
   "outputs": [],
   "source": [
    "grouped_imgs_df = imgs_df.groupby(['day'], sort = False, as_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "id": "lvIBloFNN98a"
   },
   "outputs": [],
   "source": [
    "indexes = np.array([])\n",
    "for name,group in grouped_imgs_df:\n",
    "  x = group['Proj imgs NE']\n",
    "  indexes = np.append(indexes,list(range(group[~(x.isnull())].index[0],group[~(x.isnull())].index[-1] + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_imgs_df = imgs_df.loc[indexes.astype('int64')]\n",
    "cleaned_imgs_df = cleaned_imgs_df.reset_index(drop=True)\n",
    "cleaned_imgs_df = cleaned_imgs_df[~((cleaned_imgs_df['Proj imgs NE'].isnull()) & (cleaned_imgs_df['Time']%10 != 0))]\n",
    "cleaned_imgs_df = cleaned_imgs_df.reset_index(drop=True)\n",
    "cleaned_imgs_df['day'] = cleaned_imgs_df['day'] - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103741 entries, 0 to 103740\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Date            103741 non-null  object \n",
      " 1   MST             103741 non-null  object \n",
      " 2   GHI             103741 non-null  float64\n",
      " 3   DNI             103741 non-null  float64\n",
      " 4   Zenith Angle    103741 non-null  float64\n",
      " 5   Azimuth Angle   103741 non-null  float64\n",
      " 6   Dry Temp        103741 non-null  float64\n",
      " 7   Wet Temp        103741 non-null  float64\n",
      " 8   Dew Temp        103741 non-null  float64\n",
      " 9   RH              103741 non-null  float64\n",
      " 10  TCC             103741 non-null  int64  \n",
      " 11  Wind Speed      103741 non-null  float64\n",
      " 12  Wind Direction  103741 non-null  float64\n",
      " 13  Pressure        103741 non-null  float64\n",
      " 14  Precipitation   103741 non-null  float64\n",
      " 15  Snow Depth      103741 non-null  float64\n",
      " 16  Moisture        103741 non-null  float64\n",
      " 17  Albedo          103741 non-null  float64\n",
      " 18  Time            103741 non-null  int64  \n",
      " 19  day             103741 non-null  int64  \n",
      " 20  Normal imgs NE  100057 non-null  object \n",
      " 21  Normal imgs UE  100022 non-null  object \n",
      " 22  Proj imgs NE    100059 non-null  object \n",
      " 23  Proj imgs UE    99049 non-null   object \n",
      " 24  BRBG imgs       100035 non-null  object \n",
      " 25  CDOC imgs       100034 non-null  object \n",
      " 26  MST_img         103741 non-null  object \n",
      " 27  Date_img        103741 non-null  object \n",
      "dtypes: float64(15), int64(3), object(10)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_imgs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MST</th>\n",
       "      <th>GHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>Zenith Angle</th>\n",
       "      <th>Azimuth Angle</th>\n",
       "      <th>Dry Temp</th>\n",
       "      <th>Wet Temp</th>\n",
       "      <th>Dew Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>...</th>\n",
       "      <th>Time</th>\n",
       "      <th>day</th>\n",
       "      <th>Normal imgs NE</th>\n",
       "      <th>Normal imgs UE</th>\n",
       "      <th>Proj imgs NE</th>\n",
       "      <th>Proj imgs UE</th>\n",
       "      <th>BRBG imgs</th>\n",
       "      <th>CDOC imgs</th>\n",
       "      <th>MST_img</th>\n",
       "      <th>Date_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>12/13/2017</td>\n",
       "      <td>10:10</td>\n",
       "      <td>197.2190</td>\n",
       "      <td>21.647000</td>\n",
       "      <td>67.50562</td>\n",
       "      <td>153.88002</td>\n",
       "      <td>7.154</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-14.087</td>\n",
       "      <td>17.71</td>\n",
       "      <td>...</td>\n",
       "      <td>610</td>\n",
       "      <td>-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010</td>\n",
       "      <td>20171213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>12/13/2017</td>\n",
       "      <td>10:20</td>\n",
       "      <td>199.0420</td>\n",
       "      <td>8.177880</td>\n",
       "      <td>66.69650</td>\n",
       "      <td>156.21306</td>\n",
       "      <td>7.155</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-14.191</td>\n",
       "      <td>17.54</td>\n",
       "      <td>...</td>\n",
       "      <td>620</td>\n",
       "      <td>-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020</td>\n",
       "      <td>20171213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>12/13/2017</td>\n",
       "      <td>10:30</td>\n",
       "      <td>206.2440</td>\n",
       "      <td>1.967480</td>\n",
       "      <td>65.95946</td>\n",
       "      <td>158.58791</td>\n",
       "      <td>7.137</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>-14.211</td>\n",
       "      <td>17.53</td>\n",
       "      <td>...</td>\n",
       "      <td>630</td>\n",
       "      <td>-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1030</td>\n",
       "      <td>20171213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>12/18/2017</td>\n",
       "      <td>15:20</td>\n",
       "      <td>108.7940</td>\n",
       "      <td>357.324000</td>\n",
       "      <td>78.75047</td>\n",
       "      <td>226.28961</td>\n",
       "      <td>12.980</td>\n",
       "      <td>4.058</td>\n",
       "      <td>-7.042</td>\n",
       "      <td>22.50</td>\n",
       "      <td>...</td>\n",
       "      <td>920</td>\n",
       "      <td>-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1520</td>\n",
       "      <td>20171218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>12/18/2017</td>\n",
       "      <td>15:30</td>\n",
       "      <td>50.2618</td>\n",
       "      <td>94.328900</td>\n",
       "      <td>80.15189</td>\n",
       "      <td>228.12896</td>\n",
       "      <td>12.150</td>\n",
       "      <td>3.675</td>\n",
       "      <td>-7.125</td>\n",
       "      <td>23.59</td>\n",
       "      <td>...</td>\n",
       "      <td>930</td>\n",
       "      <td>-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1530</td>\n",
       "      <td>20171218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103063</th>\n",
       "      <td>11/24/2021</td>\n",
       "      <td>14:20</td>\n",
       "      <td>96.2764</td>\n",
       "      <td>0.098286</td>\n",
       "      <td>70.10909</td>\n",
       "      <td>217.86452</td>\n",
       "      <td>3.722</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>-5.997</td>\n",
       "      <td>46.20</td>\n",
       "      <td>...</td>\n",
       "      <td>860</td>\n",
       "      <td>1424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1420</td>\n",
       "      <td>20211124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103064</th>\n",
       "      <td>11/24/2021</td>\n",
       "      <td>14:30</td>\n",
       "      <td>111.0960</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>71.31526</td>\n",
       "      <td>219.98416</td>\n",
       "      <td>3.740</td>\n",
       "      <td>-0.461</td>\n",
       "      <td>-6.261</td>\n",
       "      <td>45.10</td>\n",
       "      <td>...</td>\n",
       "      <td>870</td>\n",
       "      <td>1424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1430</td>\n",
       "      <td>20211124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103433</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>09:20</td>\n",
       "      <td>133.8930</td>\n",
       "      <td>8.575550</td>\n",
       "      <td>70.82863</td>\n",
       "      <td>143.31848</td>\n",
       "      <td>17.040</td>\n",
       "      <td>7.053</td>\n",
       "      <td>-3.447</td>\n",
       "      <td>23.58</td>\n",
       "      <td>...</td>\n",
       "      <td>560</td>\n",
       "      <td>1431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0920</td>\n",
       "      <td>20211201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103434</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>09:30</td>\n",
       "      <td>139.2060</td>\n",
       "      <td>64.550100</td>\n",
       "      <td>69.71298</td>\n",
       "      <td>145.47641</td>\n",
       "      <td>17.170</td>\n",
       "      <td>7.130</td>\n",
       "      <td>-3.270</td>\n",
       "      <td>23.74</td>\n",
       "      <td>...</td>\n",
       "      <td>570</td>\n",
       "      <td>1431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0930</td>\n",
       "      <td>20211201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103435</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>09:40</td>\n",
       "      <td>200.4330</td>\n",
       "      <td>278.313000</td>\n",
       "      <td>68.65734</td>\n",
       "      <td>147.68375</td>\n",
       "      <td>17.780</td>\n",
       "      <td>7.491</td>\n",
       "      <td>-2.909</td>\n",
       "      <td>23.55</td>\n",
       "      <td>...</td>\n",
       "      <td>580</td>\n",
       "      <td>1431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0940</td>\n",
       "      <td>20211201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2890 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date    MST       GHI         DNI  Zenith Angle  Azimuth Angle  \\\n",
       "638     12/13/2017  10:10  197.2190   21.647000      67.50562      153.88002   \n",
       "639     12/13/2017  10:20  199.0420    8.177880      66.69650      156.21306   \n",
       "640     12/13/2017  10:30  206.2440    1.967480      65.95946      158.58791   \n",
       "949     12/18/2017  15:20  108.7940  357.324000      78.75047      226.28961   \n",
       "950     12/18/2017  15:30   50.2618   94.328900      80.15189      228.12896   \n",
       "...            ...    ...       ...         ...           ...            ...   \n",
       "103063  11/24/2021  14:20   96.2764    0.098286      70.10909      217.86452   \n",
       "103064  11/24/2021  14:30  111.0960    0.304688      71.31526      219.98416   \n",
       "103433   12/1/2021  09:20  133.8930    8.575550      70.82863      143.31848   \n",
       "103434   12/1/2021  09:30  139.2060   64.550100      69.71298      145.47641   \n",
       "103435   12/1/2021  09:40  200.4330  278.313000      68.65734      147.68375   \n",
       "\n",
       "        Dry Temp  Wet Temp  Dew Temp     RH  ...  Time   day  Normal imgs NE  \\\n",
       "638        7.154    -0.387   -14.087  17.71  ...   610   -18             NaN   \n",
       "639        7.155    -0.491   -14.191  17.54  ...   620   -18             NaN   \n",
       "640        7.137    -0.511   -14.211  17.53  ...   630   -18             NaN   \n",
       "949       12.980     4.058    -7.042  22.50  ...   920   -13             NaN   \n",
       "950       12.150     3.675    -7.125  23.59  ...   930   -13             NaN   \n",
       "...          ...       ...       ...    ...  ...   ...   ...             ...   \n",
       "103063     3.722    -0.397    -5.997  46.20  ...   860  1424             NaN   \n",
       "103064     3.740    -0.461    -6.261  45.10  ...   870  1424             NaN   \n",
       "103433    17.040     7.053    -3.447  23.58  ...   560  1431             NaN   \n",
       "103434    17.170     7.130    -3.270  23.74  ...   570  1431             NaN   \n",
       "103435    17.780     7.491    -2.909  23.55  ...   580  1431             NaN   \n",
       "\n",
       "        Normal imgs UE  Proj imgs NE  Proj imgs UE  BRBG imgs  CDOC imgs  \\\n",
       "638                NaN           NaN           NaN        NaN        NaN   \n",
       "639                NaN           NaN           NaN        NaN        NaN   \n",
       "640                NaN           NaN           NaN        NaN        NaN   \n",
       "949                NaN           NaN           NaN        NaN        NaN   \n",
       "950                NaN           NaN           NaN        NaN        NaN   \n",
       "...                ...           ...           ...        ...        ...   \n",
       "103063             NaN           NaN           NaN        NaN        NaN   \n",
       "103064             NaN           NaN           NaN        NaN        NaN   \n",
       "103433             NaN           NaN           NaN        NaN        NaN   \n",
       "103434             NaN           NaN           NaN        NaN        NaN   \n",
       "103435             NaN           NaN           NaN        NaN        NaN   \n",
       "\n",
       "        MST_img  Date_img  \n",
       "638        1010  20171213  \n",
       "639        1020  20171213  \n",
       "640        1030  20171213  \n",
       "949        1520  20171218  \n",
       "950        1530  20171218  \n",
       "...         ...       ...  \n",
       "103063     1420  20211124  \n",
       "103064     1430  20211124  \n",
       "103433     0920  20211201  \n",
       "103434     0930  20211201  \n",
       "103435     0940  20211201  \n",
       "\n",
       "[2890 rows x 28 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_imgs_df[cleaned_imgs_df['Proj imgs NE'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(cleaned_imgs_df[~(cleaned_imgs_df['Proj imgs NE'].isnull()) & (cleaned_imgs_df['Time']%10 != 0)].index):\n",
    "    time = cleaned_imgs_df['Time'].iloc[i]\n",
    "    if(time%10 <=5):\n",
    "        if type(cleaned_imgs_df['Proj imgs NE'].iloc[i-1])!=str:\n",
    "            cleaned_imgs_df.loc[(i-1),(cleaned_imgs_df.columns[20:26])] = cleaned_imgs_df.loc[(i),(cleaned_imgs_df.columns[20:26])]\n",
    "        else:\n",
    "            if type(cleaned_imgs_df['Proj imgs NE'].iloc[i+1])!=str:\n",
    "                cleaned_imgs_df.loc[(i+1),(cleaned_imgs_df.columns[20:26])] = cleaned_imgs_df.loc[(i),(cleaned_imgs_df.columns[20:26])]\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_imgs_df.drop(list(cleaned_imgs_df[~(cleaned_imgs_df['Proj imgs NE'].isnull()) & (cleaned_imgs_df['Time']%10 != 0)].index),inplace = True)\n",
    "cleaned_imgs_df.reset_index(drop = True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run after re running above 2 or 4 cells\n",
    "for day in test_days_list_unique:\n",
    "    for col in list(cleaned_imgs_df.columns[20:26]):\n",
    "        cleaned_imgs_df.loc[(cleaned_imgs_df[cleaned_imgs_df['day']==day][col].index).astype('int64'), (col)] = list(fillna_nearest(cleaned_imgs_df[cleaned_imgs_df['day']==day][col]))\n",
    "        cleaned_imgs_df.loc[(cleaned_imgs_df[cleaned_imgs_df['day']==day][col].index).astype('int64'), (col)] = list(fillna_nearest(cleaned_imgs_df[cleaned_imgs_df['day']==day][col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features(cleaned_imgs_df)\n",
    "current_last_day = 1431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    103477.000000\n",
       "mean        705.831866\n",
       "std         420.092240\n",
       "min         -29.000000\n",
       "25%         335.000000\n",
       "50%         698.000000\n",
       "75%        1070.000000\n",
       "max        1431.000000\n",
       "Name: day, dtype: float64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_imgs_df['day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MST</th>\n",
       "      <th>GHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>Zenith Angle</th>\n",
       "      <th>Azimuth Angle</th>\n",
       "      <th>Dry Temp</th>\n",
       "      <th>Wet Temp</th>\n",
       "      <th>Dew Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>...</th>\n",
       "      <th>Proj imgs UE</th>\n",
       "      <th>BRBG imgs</th>\n",
       "      <th>CDOC imgs</th>\n",
       "      <th>MST_img</th>\n",
       "      <th>Date_img</th>\n",
       "      <th>Declination Angle</th>\n",
       "      <th>distance factor</th>\n",
       "      <th>Wind_x</th>\n",
       "      <th>Wind_y</th>\n",
       "      <th>Clear Sky GHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:10</td>\n",
       "      <td>13.30970</td>\n",
       "      <td>212.480000</td>\n",
       "      <td>89.28871</td>\n",
       "      <td>119.33135</td>\n",
       "      <td>10.21</td>\n",
       "      <td>2.528</td>\n",
       "      <td>-7.772</td>\n",
       "      <td>25.36</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201071000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201071000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201071000_1112_CDOC.png</td>\n",
       "      <td>0710</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>1.419725</td>\n",
       "      <td>-3.144341</td>\n",
       "      <td>13.583751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:20</td>\n",
       "      <td>30.88390</td>\n",
       "      <td>361.561000</td>\n",
       "      <td>87.75468</td>\n",
       "      <td>120.95016</td>\n",
       "      <td>11.07</td>\n",
       "      <td>2.992</td>\n",
       "      <td>-7.408</td>\n",
       "      <td>24.72</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201072000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201072000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201072000_1112_CDOC.png</td>\n",
       "      <td>0720</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>2.028488</td>\n",
       "      <td>-3.389356</td>\n",
       "      <td>42.804430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:30</td>\n",
       "      <td>52.38490</td>\n",
       "      <td>475.751000</td>\n",
       "      <td>86.18760</td>\n",
       "      <td>122.59905</td>\n",
       "      <td>11.32</td>\n",
       "      <td>3.279</td>\n",
       "      <td>-7.111</td>\n",
       "      <td>24.95</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201073000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201073000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201073000_1112_CDOC.png</td>\n",
       "      <td>0730</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>1.115431</td>\n",
       "      <td>-2.999302</td>\n",
       "      <td>72.530971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:40</td>\n",
       "      <td>25.40700</td>\n",
       "      <td>14.517500</td>\n",
       "      <td>84.62281</td>\n",
       "      <td>124.28029</td>\n",
       "      <td>10.99</td>\n",
       "      <td>3.106</td>\n",
       "      <td>-7.094</td>\n",
       "      <td>25.54</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201074000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201074000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201074000_1112_CDOC.png</td>\n",
       "      <td>0740</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>-0.034556</td>\n",
       "      <td>-2.199729</td>\n",
       "      <td>102.067937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:50</td>\n",
       "      <td>106.54600</td>\n",
       "      <td>634.944000</td>\n",
       "      <td>83.07628</td>\n",
       "      <td>125.99608</td>\n",
       "      <td>11.02</td>\n",
       "      <td>3.051</td>\n",
       "      <td>-7.349</td>\n",
       "      <td>24.93</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201075000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201075000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201075000_1112_CDOC.png</td>\n",
       "      <td>0750</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>0.567782</td>\n",
       "      <td>-2.383301</td>\n",
       "      <td>131.095973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93737</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>15:50</td>\n",
       "      <td>95.93110</td>\n",
       "      <td>625.967000</td>\n",
       "      <td>83.14403</td>\n",
       "      <td>233.99678</td>\n",
       "      <td>20.41</td>\n",
       "      <td>8.315</td>\n",
       "      <td>-3.985</td>\n",
       "      <td>18.25</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201155000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201155000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201155000_1112_CDOC.png</td>\n",
       "      <td>1550</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.270873</td>\n",
       "      <td>-2.936815</td>\n",
       "      <td>129.828019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93738</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:00</td>\n",
       "      <td>70.30890</td>\n",
       "      <td>554.892000</td>\n",
       "      <td>84.69147</td>\n",
       "      <td>235.70981</td>\n",
       "      <td>20.19</td>\n",
       "      <td>8.261</td>\n",
       "      <td>-4.029</td>\n",
       "      <td>18.43</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201160000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201160000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201160000_1112_CDOC.png</td>\n",
       "      <td>1600</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.916700</td>\n",
       "      <td>-3.164848</td>\n",
       "      <td>100.775266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93739</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:10</td>\n",
       "      <td>15.40180</td>\n",
       "      <td>2.712680</td>\n",
       "      <td>86.25671</td>\n",
       "      <td>237.38831</td>\n",
       "      <td>19.45</td>\n",
       "      <td>7.935</td>\n",
       "      <td>-3.965</td>\n",
       "      <td>19.40</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201161000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201161000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201161000_1112_CDOC.png</td>\n",
       "      <td>1610</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>0.919554</td>\n",
       "      <td>-3.065032</td>\n",
       "      <td>71.222927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93740</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:20</td>\n",
       "      <td>10.41260</td>\n",
       "      <td>-0.732237</td>\n",
       "      <td>87.82324</td>\n",
       "      <td>239.03447</td>\n",
       "      <td>18.47</td>\n",
       "      <td>7.521</td>\n",
       "      <td>-3.979</td>\n",
       "      <td>20.60</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201162000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201162000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201162000_1112_CDOC.png</td>\n",
       "      <td>1620</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>2.107806</td>\n",
       "      <td>-2.407728</td>\n",
       "      <td>41.500880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93741</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:30</td>\n",
       "      <td>5.13126</td>\n",
       "      <td>-0.565152</td>\n",
       "      <td>89.35451</td>\n",
       "      <td>240.65056</td>\n",
       "      <td>18.01</td>\n",
       "      <td>7.275</td>\n",
       "      <td>-4.025</td>\n",
       "      <td>21.12</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201163000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201163000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201163000_1112_CDOC.png</td>\n",
       "      <td>1630</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.409960</td>\n",
       "      <td>-3.420820</td>\n",
       "      <td>12.328009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93742 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    MST        GHI         DNI  Zenith Angle  Azimuth Angle  \\\n",
       "0      12/1/2017  07:10   13.30970  212.480000      89.28871      119.33135   \n",
       "1      12/1/2017  07:20   30.88390  361.561000      87.75468      120.95016   \n",
       "2      12/1/2017  07:30   52.38490  475.751000      86.18760      122.59905   \n",
       "3      12/1/2017  07:40   25.40700   14.517500      84.62281      124.28029   \n",
       "4      12/1/2017  07:50  106.54600  634.944000      83.07628      125.99608   \n",
       "...          ...    ...        ...         ...           ...            ...   \n",
       "93737  12/1/2021  15:50   95.93110  625.967000      83.14403      233.99678   \n",
       "93738  12/1/2021  16:00   70.30890  554.892000      84.69147      235.70981   \n",
       "93739  12/1/2021  16:10   15.40180    2.712680      86.25671      237.38831   \n",
       "93740  12/1/2021  16:20   10.41260   -0.732237      87.82324      239.03447   \n",
       "93741  12/1/2021  16:30    5.13126   -0.565152      89.35451      240.65056   \n",
       "\n",
       "       Dry Temp  Wet Temp  Dew Temp     RH  ...  \\\n",
       "0         10.21     2.528    -7.772  25.36  ...   \n",
       "1         11.07     2.992    -7.408  24.72  ...   \n",
       "2         11.32     3.279    -7.111  24.95  ...   \n",
       "3         10.99     3.106    -7.094  25.54  ...   \n",
       "4         11.02     3.051    -7.349  24.93  ...   \n",
       "...         ...       ...       ...    ...  ...   \n",
       "93737     20.41     8.315    -3.985  18.25  ...   \n",
       "93738     20.19     8.261    -4.029  18.43  ...   \n",
       "93739     19.45     7.935    -3.965  19.40  ...   \n",
       "93740     18.47     7.521    -3.979  20.60  ...   \n",
       "93741     18.01     7.275    -4.025  21.12  ...   \n",
       "\n",
       "                                   Proj imgs UE  \\\n",
       "0      Images/20171201/20171201071000_12_UE.jpg   \n",
       "1      Images/20171201/20171201072000_12_UE.jpg   \n",
       "2      Images/20171201/20171201073000_12_UE.jpg   \n",
       "3      Images/20171201/20171201074000_12_UE.jpg   \n",
       "4      Images/20171201/20171201075000_12_UE.jpg   \n",
       "...                                         ...   \n",
       "93737  Images/20211201/20211201155000_12_UE.jpg   \n",
       "93738  Images/20211201/20211201160000_12_UE.jpg   \n",
       "93739  Images/20211201/20211201161000_12_UE.jpg   \n",
       "93740  Images/20211201/20211201162000_12_UE.jpg   \n",
       "93741  Images/20211201/20211201163000_12_UE.jpg   \n",
       "\n",
       "                                          BRBG imgs  \\\n",
       "0      Images/20171201/20171201071000_1112_BRBG.png   \n",
       "1      Images/20171201/20171201072000_1112_BRBG.png   \n",
       "2      Images/20171201/20171201073000_1112_BRBG.png   \n",
       "3      Images/20171201/20171201074000_1112_BRBG.png   \n",
       "4      Images/20171201/20171201075000_1112_BRBG.png   \n",
       "...                                             ...   \n",
       "93737  Images/20211201/20211201155000_1112_BRBG.png   \n",
       "93738  Images/20211201/20211201160000_1112_BRBG.png   \n",
       "93739  Images/20211201/20211201161000_1112_BRBG.png   \n",
       "93740  Images/20211201/20211201162000_1112_BRBG.png   \n",
       "93741  Images/20211201/20211201163000_1112_BRBG.png   \n",
       "\n",
       "                                          CDOC imgs  MST_img  Date_img  \\\n",
       "0      Images/20171201/20171201071000_1112_CDOC.png     0710  20171201   \n",
       "1      Images/20171201/20171201072000_1112_CDOC.png     0720  20171201   \n",
       "2      Images/20171201/20171201073000_1112_CDOC.png     0730  20171201   \n",
       "3      Images/20171201/20171201074000_1112_CDOC.png     0740  20171201   \n",
       "4      Images/20171201/20171201075000_1112_CDOC.png     0750  20171201   \n",
       "...                                             ...      ...       ...   \n",
       "93737  Images/20211201/20211201155000_1112_CDOC.png     1550  20211201   \n",
       "93738  Images/20211201/20211201160000_1112_CDOC.png     1600  20211201   \n",
       "93739  Images/20211201/20211201161000_1112_CDOC.png     1610  20211201   \n",
       "93740  Images/20211201/20211201162000_1112_CDOC.png     1620  20211201   \n",
       "93741  Images/20211201/20211201163000_1112_CDOC.png     1630  20211201   \n",
       "\n",
       "       Declination Angle  distance factor    Wind_x    Wind_y Clear Sky GHI  \n",
       "0              -0.409105         0.878124  1.419725 -3.144341     13.583751  \n",
       "1              -0.409105         0.878124  2.028488 -3.389356     42.804430  \n",
       "2              -0.409105         0.878124  1.115431 -2.999302     72.530971  \n",
       "3              -0.409105         0.878124 -0.034556 -2.199729    102.067937  \n",
       "4              -0.409105         0.878124  0.567782 -2.383301    131.095973  \n",
       "...                  ...              ...       ...       ...           ...  \n",
       "93737          -0.409105         0.869764  1.270873 -2.936815    129.828019  \n",
       "93738          -0.409105         0.869764  1.916700 -3.164848    100.775266  \n",
       "93739          -0.409105         0.869764  0.919554 -3.065032     71.222927  \n",
       "93740          -0.409105         0.869764  2.107806 -2.407728     41.500880  \n",
       "93741          -0.409105         0.869764  1.409960 -3.420820     12.328009  \n",
       "\n",
       "[93742 rows x 31 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_imgs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "null_percent = []\n",
    "grouped_cleaned_imgs_df = cleaned_imgs_df.groupby(['day'], sort = False, as_index = False)\n",
    "for day,group in grouped_cleaned_imgs_df:\n",
    "    null_percent.append([(group['Proj imgs NE'].isnull().sum())/len(group['Proj imgs NE']), day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 0.12280701754385964]\n",
      "[133, 0.10588235294117647]\n",
      "[139, 0.1388888888888889]\n",
      "[174, 0.11235955056179775]\n",
      "[210, 0.10465116279069768]\n",
      "[211, 0.11764705882352941]\n",
      "[212, 0.15294117647058825]\n",
      "[213, 0.12941176470588237]\n",
      "[215, 0.14285714285714285]\n",
      "[216, 0.23809523809523808]\n",
      "[283, 0.11764705882352941]\n",
      "[289, 0.13636363636363635]\n",
      "[291, 0.13636363636363635]\n",
      "[292, 0.125]\n",
      "[341, 0.14285714285714285]\n",
      "[356, 0.10909090909090909]\n",
      "[358, 0.12727272727272726]\n",
      "[360, 0.21428571428571427]\n",
      "[372, 0.14035087719298245]\n",
      "[374, 0.12280701754385964]\n",
      "[433, 0.4782608695652174]\n",
      "[445, 0.1232876712328767]\n",
      "[449, 0.13513513513513514]\n",
      "[452, 0.17567567567567569]\n",
      "[453, 0.14864864864864866]\n",
      "[454, 0.10666666666666667]\n",
      "[459, 0.13157894736842105]\n",
      "[460, 0.15789473684210525]\n",
      "[461, 0.16883116883116883]\n",
      "[462, 0.12987012987012986]\n",
      "[464, 0.21794871794871795]\n",
      "[467, 0.22784810126582278]\n",
      "[468, 0.189873417721519]\n",
      "[471, 0.26582278481012656]\n",
      "[473, 0.20253164556962025]\n",
      "[474, 0.19753086419753085]\n",
      "[475, 0.2962962962962963]\n",
      "[476, 0.25925925925925924]\n",
      "[477, 0.38271604938271603]\n",
      "[479, 0.4875]\n",
      "[480, 0.6363636363636364]\n",
      "[483, 0.17073170731707318]\n",
      "[484, 0.20481927710843373]\n",
      "[487, 0.13253012048192772]\n",
      "[490, 0.16176470588235295]\n",
      "[494, 0.11764705882352941]\n",
      "[496, 0.13095238095238096]\n",
      "[499, 0.12790697674418605]\n",
      "[501, 0.11627906976744186]\n",
      "[504, 0.12790697674418605]\n",
      "[505, 0.20689655172413793]\n",
      "[506, 0.12643678160919541]\n",
      "[507, 0.1724137931034483]\n",
      "[528, 0.15730337078651685]\n",
      "[536, 0.16853932584269662]\n",
      "[541, 0.12222222222222222]\n",
      "[551, 0.2727272727272727]\n",
      "[553, 0.11363636363636363]\n",
      "[556, 0.10227272727272728]\n",
      "[557, 0.11363636363636363]\n",
      "[582, 0.27380952380952384]\n",
      "[584, 0.6190476190476191]\n",
      "[616, 0.12]\n",
      "[623, 0.28378378378378377]\n",
      "[624, 0.14864864864864866]\n",
      "[632, 0.2676056338028169]\n",
      "[636, 0.49295774647887325]\n",
      "[637, 0.30985915492957744]\n",
      "[647, 0.14705882352941177]\n",
      "[679, 0.1]\n",
      "[757, 0.11666666666666667]\n",
      "[822, 0.21875]\n",
      "[827, 0.40384615384615385]\n",
      "[995, 0.13432835820895522]\n",
      "[1019, 0.10606060606060606]\n",
      "[1052, 0.1016949152542373]\n",
      "[1206, 0.1728395061728395]\n",
      "[1338, 0.11864406779661017]\n",
      "[1365, 0.39436619718309857]\n",
      "[1366, 0.2535211267605634]\n",
      "[1412, 0.21666666666666667]\n"
     ]
    }
   ],
   "source": [
    "del_days = []\n",
    "for a, b in null_percent:\n",
    "    if(a>=0.1):\n",
    "        print([b, a])\n",
    "        del_days.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day(index_list,day):\n",
    "    global cleaned_imgs_df, current_last_day\n",
    "    for start,end,length in index_list:\n",
    "        cleaned_imgs_df.loc[(list(range(start,end+1))), ('day')] = [current_last_day+1 for i in range(start,end+1)]\n",
    "        current_last_day = current_last_day + 1\n",
    "    cleaned_imgs_df = cleaned_imgs_df[cleaned_imgs_df['day'] != day]\n",
    "    cleaned_imgs_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "def cut_down(day):\n",
    "    global cleaned_imgs_df\n",
    "    if(len(list(cleaned_imgs_df[cleaned_imgs_df['day'] == day].index)) == 0): return\n",
    "    start_index = list(cleaned_imgs_df[cleaned_imgs_df['day'] == day].index)[0]\n",
    "    freq = 0\n",
    "    index_list = []\n",
    "    for i in list(cleaned_imgs_df[cleaned_imgs_df['day'] == day].index):\n",
    "        if cleaned_imgs_df['Proj imgs NE'].loc[i] is np.NaN:\n",
    "            if freq>=12:\n",
    "                index_list.append([start_index, i-1,freq])\n",
    "#             print(freq)\n",
    "            freq = 0\n",
    "            start_index = i + 1\n",
    "#             if(freq>12):\n",
    "#                 freq = 1\n",
    "        else:\n",
    "            freq = freq + 1\n",
    "            \n",
    "    if freq>=12:\n",
    "        index_list.append([start_index,i,freq])\n",
    "#     return index_list\n",
    "    if len(index_list)!=0:\n",
    "        create_day(index_list, day)\n",
    "    else:\n",
    "        cleaned_imgs_df = cleaned_imgs_df[cleaned_imgs_df['day'] != day]\n",
    "        cleaned_imgs_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_days_imputed = [72,121,130,203,285,355,444,478,481,482,489,495,498,502,503,508,612,629,1330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u00udgkwswg89hmuTA357/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "for day in del_days:\n",
    "    if day in test_days_list_unique:\n",
    "        pass\n",
    "    else:\n",
    "        cut_down(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, -18],\n",
       " [3, -13],\n",
       " [3, -2],\n",
       " [5, -1],\n",
       " [3, 0],\n",
       " [3, 19],\n",
       " [1, 25],\n",
       " [1, 26],\n",
       " [3, 27],\n",
       " [1, 27],\n",
       " [1, 28],\n",
       " [1, 29],\n",
       " [1, 31],\n",
       " [3, 32],\n",
       " [1, 32],\n",
       " [1, 33],\n",
       " [1, 34],\n",
       " [1, 44],\n",
       " [1, 45],\n",
       " [3, 47],\n",
       " [5, 48],\n",
       " [1, 48],\n",
       " [1, 49],\n",
       " [3, 50],\n",
       " [1, 50],\n",
       " [1, 52],\n",
       " [1, 53],\n",
       " [3, 54],\n",
       " [1, 54],\n",
       " [1, 55],\n",
       " [1, 58],\n",
       " [1, 59],\n",
       " [1, 62],\n",
       " [1, 63],\n",
       " [1, 65],\n",
       " [1, 66],\n",
       " [1, 67],\n",
       " [1, 69],\n",
       " [1, 70],\n",
       " [1, 71],\n",
       " [1, 73],\n",
       " [1, 74],\n",
       " [1, 75],\n",
       " [1, 76],\n",
       " [1, 78],\n",
       " [1, 79],\n",
       " [1, 80],\n",
       " [3, 81],\n",
       " [1, 81],\n",
       " [1, 82],\n",
       " [1, 85],\n",
       " [1, 86],\n",
       " [1, 87],\n",
       " [1, 88],\n",
       " [1, 89],\n",
       " [1, 91],\n",
       " [3, 96],\n",
       " [1, 96],\n",
       " [1, 97],\n",
       " [3, 99],\n",
       " [1, 99],\n",
       " [1, 101],\n",
       " [1, 103],\n",
       " [3, 106],\n",
       " [1, 106],\n",
       " [1, 110],\n",
       " [1, 111],\n",
       " [3, 112],\n",
       " [1, 112],\n",
       " [1, 113],\n",
       " [4, 114],\n",
       " [1, 114],\n",
       " [1, 116],\n",
       " [1, 117],\n",
       " [1, 118],\n",
       " [1, 119],\n",
       " [3, 120],\n",
       " [1, 123],\n",
       " [1, 124],\n",
       " [1, 126],\n",
       " [1, 127],\n",
       " [1, 131],\n",
       " [3, 132],\n",
       " [1, 132],\n",
       " [1, 134],\n",
       " [1, 135],\n",
       " [3, 136],\n",
       " [1, 136],\n",
       " [1, 137],\n",
       " [1, 146],\n",
       " [1, 147],\n",
       " [1, 147],\n",
       " [6, 148],\n",
       " [1, 148],\n",
       " [1, 151],\n",
       " [1, 152],\n",
       " [1, 153],\n",
       " [1, 154],\n",
       " [1, 155],\n",
       " [1, 156],\n",
       " [1, 156],\n",
       " [1, 157],\n",
       " [3, 158],\n",
       " [1, 158],\n",
       " [1, 160],\n",
       " [3, 162],\n",
       " [3, 164],\n",
       " [1, 164],\n",
       " [1, 165],\n",
       " [1, 165],\n",
       " [1, 165],\n",
       " [1, 165],\n",
       " [1, 165],\n",
       " [1, 165],\n",
       " [1, 165],\n",
       " [1, 165],\n",
       " [1, 166],\n",
       " [1, 169],\n",
       " [4, 170],\n",
       " [3, 171],\n",
       " [1, 171],\n",
       " [1, 172],\n",
       " [1, 173],\n",
       " [1, 175],\n",
       " [1, 176],\n",
       " [1, 177],\n",
       " [1, 180],\n",
       " [1, 182],\n",
       " [1, 182],\n",
       " [1, 182],\n",
       " [1, 185],\n",
       " [3, 188],\n",
       " [1, 188],\n",
       " [1, 189],\n",
       " [3, 189],\n",
       " [1, 190],\n",
       " [4, 192],\n",
       " [1, 192],\n",
       " [1, 192],\n",
       " [1, 193],\n",
       " [1, 194],\n",
       " [1, 194],\n",
       " [1, 194],\n",
       " [1, 195],\n",
       " [3, 197],\n",
       " [1, 197],\n",
       " [1, 197],\n",
       " [1, 197],\n",
       " [1, 199],\n",
       " [1, 199],\n",
       " [1, 200],\n",
       " [1, 201],\n",
       " [1, 201],\n",
       " [1, 201],\n",
       " [1, 206],\n",
       " [1, 206],\n",
       " [1, 206],\n",
       " [1, 206],\n",
       " [1, 206],\n",
       " [1, 207],\n",
       " [1, 207],\n",
       " [1, 207],\n",
       " [1, 207],\n",
       " [1, 207],\n",
       " [1, 208],\n",
       " [1, 208],\n",
       " [1, 208],\n",
       " [1, 208],\n",
       " [1, 209],\n",
       " [1, 209],\n",
       " [1, 209],\n",
       " [1, 209],\n",
       " [1, 209],\n",
       " [1, 217],\n",
       " [1, 219],\n",
       " [1, 221],\n",
       " [1, 221],\n",
       " [1, 224],\n",
       " [1, 224],\n",
       " [1, 226],\n",
       " [1, 226],\n",
       " [1, 226],\n",
       " [1, 226],\n",
       " [1, 226],\n",
       " [1, 226],\n",
       " [1, 226],\n",
       " [1, 227],\n",
       " [3, 227],\n",
       " [1, 228],\n",
       " [4, 228],\n",
       " [1, 231],\n",
       " [1, 233],\n",
       " [1, 235],\n",
       " [1, 235],\n",
       " [1, 235],\n",
       " [1, 235],\n",
       " [1, 235],\n",
       " [1, 235],\n",
       " [1, 238],\n",
       " [1, 239],\n",
       " [1, 240],\n",
       " [3, 241],\n",
       " [1, 241],\n",
       " [1, 243],\n",
       " [1, 243],\n",
       " [1, 243],\n",
       " [1, 243],\n",
       " [1, 243],\n",
       " [1, 244],\n",
       " [1, 245],\n",
       " [1, 246],\n",
       " [4, 247],\n",
       " [1, 247],\n",
       " [1, 249],\n",
       " [3, 250],\n",
       " [1, 250],\n",
       " [3, 251],\n",
       " [1, 251],\n",
       " [1, 252],\n",
       " [1, 252],\n",
       " [1, 253],\n",
       " [1, 255],\n",
       " [1, 256],\n",
       " [1, 257],\n",
       " [1, 258],\n",
       " [1, 260],\n",
       " [1, 260],\n",
       " [1, 260],\n",
       " [1, 260],\n",
       " [1, 260],\n",
       " [1, 261],\n",
       " [1, 262],\n",
       " [3, 263],\n",
       " [1, 263],\n",
       " [1, 264],\n",
       " [3, 264],\n",
       " [1, 264],\n",
       " [1, 266],\n",
       " [1, 266],\n",
       " [1, 267],\n",
       " [1, 269],\n",
       " [2, 270],\n",
       " [1, 271],\n",
       " [1, 272],\n",
       " [1, 272],\n",
       " [1, 272],\n",
       " [1, 272],\n",
       " [1, 274],\n",
       " [1, 274],\n",
       " [1, 274],\n",
       " [1, 275],\n",
       " [4, 275],\n",
       " [1, 275],\n",
       " [1, 279],\n",
       " [1, 279],\n",
       " [1, 279],\n",
       " [1, 279],\n",
       " [1, 280],\n",
       " [1, 280],\n",
       " [1, 280],\n",
       " [1, 281],\n",
       " [1, 281],\n",
       " [4, 282],\n",
       " [1, 282],\n",
       " [1, 282],\n",
       " [1, 286],\n",
       " [1, 286],\n",
       " [1, 287],\n",
       " [1, 287],\n",
       " [1, 287],\n",
       " [1, 287],\n",
       " [3, 288],\n",
       " [1, 288],\n",
       " [1, 290],\n",
       " [1, 290],\n",
       " [3, 293],\n",
       " [1, 293],\n",
       " [1, 294],\n",
       " [3, 295],\n",
       " [1, 313],\n",
       " [1, 313],\n",
       " [1, 313],\n",
       " [3, 315],\n",
       " [1, 321],\n",
       " [1, 321],\n",
       " [1, 321],\n",
       " [1, 321],\n",
       " [4, 326],\n",
       " [3, 330],\n",
       " [1, 335],\n",
       " [1, 337],\n",
       " [1, 337],\n",
       " [1, 340],\n",
       " [3, 340],\n",
       " [1, 343],\n",
       " [1, 347],\n",
       " [1, 347],\n",
       " [1, 350],\n",
       " [1, 350],\n",
       " [1, 350],\n",
       " [1, 351],\n",
       " [3, 351],\n",
       " [1, 351],\n",
       " [1, 352],\n",
       " [1, 352],\n",
       " [1, 354],\n",
       " [1, 357],\n",
       " [1, 357],\n",
       " [1, 357],\n",
       " [1, 357],\n",
       " [1, 359],\n",
       " [1, 359],\n",
       " [1, 359],\n",
       " [1, 359],\n",
       " [1, 361],\n",
       " [2, 361],\n",
       " [2, 361],\n",
       " [1, 367],\n",
       " [1, 367],\n",
       " [1, 368],\n",
       " [1, 369],\n",
       " [1, 369],\n",
       " [1, 370],\n",
       " [1, 370],\n",
       " [1, 371],\n",
       " [1, 371],\n",
       " [1, 371],\n",
       " [1, 371],\n",
       " [1, 371],\n",
       " [1, 373],\n",
       " [1, 373],\n",
       " [1, 373],\n",
       " [1, 375],\n",
       " [2, 375],\n",
       " [1, 381],\n",
       " [1, 381],\n",
       " [1, 381],\n",
       " [3, 382],\n",
       " [3, 383],\n",
       " [1, 390],\n",
       " [1, 390],\n",
       " [1, 390],\n",
       " [1, 391],\n",
       " [1, 392],\n",
       " [3, 393],\n",
       " [1, 393],\n",
       " [1, 394],\n",
       " [1, 395],\n",
       " [1, 396],\n",
       " [1, 397],\n",
       " [1, 398],\n",
       " [1, 398],\n",
       " [1, 400],\n",
       " [1, 401],\n",
       " [1, 403],\n",
       " [3, 404],\n",
       " [3, 406],\n",
       " [1, 410],\n",
       " [1, 412],\n",
       " [1, 413],\n",
       " [1, 414],\n",
       " [1, 415],\n",
       " [1, 416],\n",
       " [1, 416],\n",
       " [1, 416],\n",
       " [1, 417],\n",
       " [3, 419],\n",
       " [1, 419],\n",
       " [1, 422],\n",
       " [1, 423],\n",
       " [1, 425],\n",
       " [3, 427],\n",
       " [1, 427],\n",
       " [1, 432],\n",
       " [1, 432],\n",
       " [1, 439],\n",
       " [3, 440],\n",
       " [2, 440],\n",
       " [1, 442],\n",
       " [1, 443],\n",
       " [1, 443],\n",
       " [2, 443],\n",
       " [1, 443],\n",
       " [2, 443],\n",
       " [1, 447],\n",
       " [1, 447],\n",
       " [1, 447],\n",
       " [1, 447],\n",
       " [1, 447],\n",
       " [1, 447],\n",
       " [1, 448],\n",
       " [1, 448],\n",
       " [1, 448],\n",
       " [1, 448],\n",
       " [1, 448],\n",
       " [2, 448],\n",
       " [1, 450],\n",
       " [1, 450],\n",
       " [1, 450],\n",
       " [1, 450],\n",
       " [1, 451],\n",
       " [1, 451],\n",
       " [1, 451],\n",
       " [1, 451],\n",
       " [1, 451],\n",
       " [1, 455],\n",
       " [1, 455],\n",
       " [1, 455],\n",
       " [1, 455],\n",
       " [1, 455],\n",
       " [1, 455],\n",
       " [1, 457],\n",
       " [1, 457],\n",
       " [1, 457],\n",
       " [1, 457],\n",
       " [1, 458],\n",
       " [1, 458],\n",
       " [1, 458],\n",
       " [1, 458],\n",
       " [1, 458],\n",
       " [1, 463],\n",
       " [1, 463],\n",
       " [2, 463],\n",
       " [1, 463],\n",
       " [1, 465],\n",
       " [1, 465],\n",
       " [1, 465],\n",
       " [1, 465],\n",
       " [1, 469],\n",
       " [1, 469],\n",
       " [1, 469],\n",
       " [1, 469],\n",
       " [1, 469],\n",
       " [1, 470],\n",
       " [1, 470],\n",
       " [1, 470],\n",
       " [1, 470],\n",
       " [1, 472],\n",
       " [1, 472],\n",
       " [1, 472],\n",
       " [1, 472],\n",
       " [1, 485],\n",
       " [1, 485],\n",
       " [1, 485],\n",
       " [1, 485],\n",
       " [1, 485],\n",
       " [1, 485],\n",
       " [1, 486],\n",
       " [2, 486],\n",
       " [1, 488],\n",
       " [1, 488],\n",
       " [1, 488],\n",
       " [1, 492],\n",
       " [1, 492],\n",
       " [1, 492],\n",
       " [1, 492],\n",
       " [1, 497],\n",
       " [1, 497],\n",
       " [1, 497],\n",
       " [1, 497],\n",
       " [1, 497],\n",
       " [2, 497],\n",
       " [1, 500],\n",
       " [1, 500],\n",
       " [1, 500],\n",
       " [1, 500],\n",
       " [1, 500],\n",
       " [1, 500],\n",
       " [1, 500],\n",
       " [1, 510],\n",
       " [1, 510],\n",
       " [1, 510],\n",
       " [1, 510],\n",
       " [1, 510],\n",
       " [1, 510],\n",
       " [1, 511],\n",
       " [3, 517],\n",
       " [3, 520],\n",
       " [1, 526],\n",
       " [3, 526],\n",
       " [1, 527],\n",
       " [1, 527],\n",
       " [1, 527],\n",
       " [1, 527],\n",
       " [1, 530],\n",
       " [1, 530],\n",
       " [1, 530],\n",
       " [1, 530],\n",
       " [1, 530],\n",
       " [2, 531],\n",
       " [2, 535],\n",
       " [1, 537],\n",
       " [1, 538],\n",
       " [1, 539],\n",
       " [1, 540],\n",
       " [3, 540],\n",
       " [1, 540],\n",
       " [1, 540],\n",
       " [1, 540],\n",
       " [1, 543],\n",
       " [1, 544],\n",
       " [1, 545],\n",
       " [3, 550],\n",
       " [1, 550],\n",
       " [4, 550],\n",
       " [3, 552],\n",
       " [3, 555],\n",
       " [3, 555],\n",
       " [1, 555],\n",
       " [2, 558],\n",
       " [2, 558],\n",
       " [2, 559],\n",
       " [1, 562],\n",
       " [3, 564],\n",
       " [3, 565],\n",
       " [3, 571],\n",
       " [2, 577],\n",
       " [1, 577],\n",
       " [3, 578],\n",
       " [1, 578],\n",
       " [1, 578],\n",
       " [2, 578],\n",
       " [1, 579],\n",
       " [4, 579],\n",
       " [1, 579],\n",
       " [1, 580],\n",
       " [2, 581],\n",
       " [4, 583],\n",
       " [1, 583],\n",
       " [1, 586],\n",
       " [3, 586],\n",
       " [1, 586],\n",
       " [3, 593],\n",
       " [1, 594],\n",
       " [1, 597],\n",
       " [1, 598],\n",
       " [3, 599],\n",
       " [3, 599],\n",
       " [1, 599],\n",
       " [1, 600],\n",
       " [1, 601],\n",
       " [1, 602],\n",
       " [1, 602],\n",
       " [3, 602],\n",
       " [3, 603],\n",
       " [1, 603],\n",
       " [3, 604],\n",
       " [1, 604],\n",
       " [1, 605],\n",
       " [1, 608],\n",
       " [1, 610],\n",
       " [1, 611],\n",
       " [4, 614],\n",
       " [1, 617],\n",
       " [1, 618],\n",
       " [1, 618],\n",
       " [1, 618],\n",
       " [1, 619],\n",
       " [3, 620],\n",
       " [1, 620],\n",
       " [2, 622],\n",
       " [1, 625],\n",
       " [1, 627],\n",
       " [1, 627],\n",
       " [1, 628],\n",
       " [1, 630],\n",
       " [2, 630],\n",
       " [1, 630],\n",
       " [1, 631],\n",
       " [1, 633],\n",
       " [1, 634],\n",
       " [1, 635],\n",
       " [1, 635],\n",
       " [1, 635],\n",
       " [1, 635],\n",
       " [1, 635],\n",
       " [3, 640],\n",
       " [1, 644],\n",
       " [1, 646],\n",
       " [1, 648],\n",
       " [3, 652],\n",
       " [3, 652],\n",
       " [5, 653],\n",
       " [1, 653],\n",
       " [1, 654],\n",
       " [3, 656],\n",
       " [1, 656],\n",
       " [1, 658],\n",
       " [3, 662],\n",
       " [3, 665],\n",
       " [3, 669],\n",
       " [3, 673],\n",
       " [4, 675],\n",
       " [1, 675],\n",
       " [1, 675],\n",
       " [3, 676],\n",
       " [3, 680],\n",
       " [3, 682],\n",
       " [3, 687],\n",
       " [3, 688],\n",
       " [3, 690],\n",
       " [3, 696],\n",
       " [3, 697],\n",
       " [3, 705],\n",
       " [1, 712],\n",
       " [3, 713],\n",
       " [3, 719],\n",
       " [3, 721],\n",
       " [3, 722],\n",
       " [2, 725],\n",
       " [3, 732],\n",
       " [1, 741],\n",
       " [1, 741],\n",
       " [3, 751],\n",
       " [1, 756],\n",
       " [1, 758],\n",
       " [1, 759],\n",
       " [1, 760],\n",
       " [1, 761],\n",
       " [1, 762],\n",
       " [1, 762],\n",
       " [1, 763],\n",
       " [1, 764],\n",
       " [3, 765],\n",
       " [1, 765],\n",
       " [1, 766],\n",
       " [1, 767],\n",
       " [1, 768],\n",
       " [1, 769],\n",
       " [1, 770],\n",
       " [1, 771],\n",
       " [1, 772],\n",
       " [1, 773],\n",
       " [1, 774],\n",
       " [1, 775],\n",
       " [1, 776],\n",
       " [1, 777],\n",
       " [1, 778],\n",
       " [1, 779],\n",
       " [1, 780],\n",
       " [1, 781],\n",
       " [1, 782],\n",
       " [1, 783],\n",
       " [3, 784],\n",
       " [1, 784],\n",
       " [3, 785],\n",
       " [1, 785],\n",
       " [3, 786],\n",
       " [1, 786],\n",
       " [1, 787],\n",
       " [1, 788],\n",
       " [1, 789],\n",
       " [3, 790],\n",
       " [1, 790],\n",
       " [1, 791],\n",
       " [1, 792],\n",
       " [1, 793],\n",
       " [1, 794],\n",
       " [1, 795],\n",
       " [1, 796],\n",
       " [1, 797],\n",
       " [1, 798],\n",
       " [1, 799],\n",
       " [1, 800],\n",
       " [1, 801],\n",
       " [1, 802],\n",
       " [1, 803],\n",
       " [1, 804],\n",
       " [1, 805],\n",
       " [1, 806],\n",
       " [1, 807],\n",
       " [1, 808],\n",
       " [1, 809],\n",
       " [3, 810],\n",
       " [1, 810],\n",
       " [1, 811],\n",
       " [3, 812],\n",
       " [1, 812],\n",
       " [1, 813],\n",
       " [3, 814],\n",
       " [1, 814],\n",
       " [1, 815],\n",
       " [1, 816],\n",
       " [3, 817],\n",
       " [3, 817],\n",
       " [1, 817],\n",
       " [1, 818],\n",
       " [1, 819],\n",
       " [1, 820],\n",
       " [1, 821],\n",
       " [2, 823],\n",
       " [1, 823],\n",
       " [3, 823],\n",
       " [1, 823],\n",
       " [3, 828],\n",
       " [1, 828],\n",
       " [1, 829],\n",
       " [1, 830],\n",
       " [1, 831],\n",
       " [2, 832],\n",
       " [1, 832],\n",
       " [1, 833],\n",
       " [1, 834],\n",
       " [1, 835],\n",
       " [1, 836],\n",
       " [3, 837],\n",
       " [1, 838],\n",
       " [1, 839],\n",
       " [6, 840],\n",
       " [1, 840],\n",
       " [1, 841],\n",
       " [1, 842],\n",
       " [1, 843],\n",
       " [1, 844],\n",
       " [1, 845],\n",
       " [1, 846],\n",
       " [3, 847],\n",
       " [1, 847],\n",
       " [1, 848],\n",
       " [1, 849],\n",
       " [1, 851],\n",
       " [1, 852],\n",
       " [1, 853],\n",
       " [3, 854],\n",
       " [1, 854],\n",
       " [1, 855],\n",
       " [3, 856],\n",
       " [1, 858],\n",
       " [1, 859],\n",
       " [1, 860],\n",
       " [1, 861],\n",
       " [3, 862],\n",
       " [1, 862],\n",
       " [1, 863],\n",
       " [1, 864],\n",
       " [1, 865],\n",
       " [1, 866],\n",
       " [3, 867],\n",
       " [3, 869],\n",
       " [1, 869],\n",
       " [1, 870],\n",
       " [3, 871],\n",
       " [1, 871],\n",
       " [1, 872],\n",
       " [1, 873],\n",
       " [4, 874],\n",
       " [3, 875],\n",
       " [1, 875],\n",
       " [1, 876],\n",
       " [2, 877],\n",
       " [1, 877],\n",
       " [1, 878],\n",
       " [3, 879],\n",
       " [3, 879],\n",
       " [1, 881],\n",
       " [1, 882],\n",
       " [1, 883],\n",
       " [1, 884],\n",
       " [1, 885],\n",
       " [3, 886],\n",
       " [1, 886],\n",
       " [1, 887],\n",
       " [1, 888],\n",
       " [1, 889],\n",
       " [1, 890],\n",
       " [3, 891],\n",
       " [1, 891],\n",
       " [1, 892],\n",
       " [1, 893],\n",
       " [3, 894],\n",
       " [1, 894],\n",
       " [3, 894],\n",
       " [1, 895],\n",
       " [1, 896],\n",
       " [1, 897],\n",
       " [1, 898],\n",
       " [1, 899],\n",
       " [1, 900],\n",
       " [1, 901],\n",
       " [1, 902],\n",
       " [1, 903],\n",
       " [1, 904],\n",
       " [3, 905],\n",
       " [1, 905],\n",
       " [1, 906],\n",
       " [3, 907],\n",
       " [1, 907],\n",
       " [1, 908],\n",
       " [1, 908],\n",
       " [1, 909],\n",
       " [1, 910],\n",
       " [1, 911],\n",
       " [1, 911],\n",
       " [1, 912],\n",
       " [3, 913],\n",
       " [1, 913],\n",
       " [1, 914],\n",
       " [1, 915],\n",
       " [1, 916],\n",
       " [1, 917],\n",
       " [1, 918],\n",
       " [3, 918],\n",
       " [3, 919],\n",
       " [1, 919],\n",
       " [1, 920],\n",
       " [1, 921],\n",
       " [1, 922],\n",
       " [1, 925],\n",
       " [1, 926],\n",
       " [3, 926],\n",
       " [1, 927],\n",
       " [1, 928],\n",
       " [1, 929],\n",
       " [3, 929],\n",
       " [1, 930],\n",
       " [1, 931],\n",
       " [1, 932],\n",
       " [1, 933],\n",
       " [1, 934],\n",
       " [1, 937],\n",
       " [1, 938],\n",
       " [1, 939],\n",
       " [3, 940],\n",
       " [1, 940],\n",
       " [1, 941],\n",
       " [1, 942],\n",
       " [3, 942],\n",
       " [1, 943],\n",
       " [1, 944],\n",
       " [1, 945],\n",
       " [1, 946],\n",
       " [1, 947],\n",
       " [1, 948],\n",
       " [1, 949],\n",
       " [1, 950],\n",
       " [1, 951],\n",
       " [1, 952],\n",
       " [3, 953],\n",
       " [1, 953],\n",
       " [1, 954],\n",
       " [1, 955],\n",
       " [1, 956],\n",
       " [1, 957],\n",
       " [3, 958],\n",
       " [1, 960],\n",
       " [1, 962],\n",
       " [3, 963],\n",
       " [1, 963],\n",
       " [1, 964],\n",
       " [1, 965],\n",
       " [3, 966],\n",
       " [1, 966],\n",
       " [1, 967],\n",
       " [1, 967],\n",
       " [1, 967],\n",
       " [1, 968],\n",
       " [1, 969],\n",
       " [3, 970],\n",
       " [1, 970],\n",
       " [1, 971],\n",
       " [1, 972],\n",
       " [1, 973],\n",
       " [1, 974],\n",
       " [1, 975],\n",
       " [1, 976],\n",
       " [1, 977],\n",
       " [1, 978],\n",
       " [1, 979],\n",
       " [3, 980],\n",
       " [1, 980],\n",
       " [1, 981],\n",
       " [1, 982],\n",
       " [1, 983],\n",
       " [1, 984],\n",
       " [3, 985],\n",
       " [1, 987],\n",
       " [1, 988],\n",
       " [1, 989],\n",
       " [1, 990],\n",
       " [1, 991],\n",
       " [1, 992],\n",
       " [3, 992],\n",
       " [1, 992],\n",
       " [1, 993],\n",
       " [1, 994],\n",
       " [3, 997],\n",
       " [1, 997],\n",
       " [1, 998],\n",
       " [1, 999],\n",
       " [1, 1000],\n",
       " [1, 1001],\n",
       " [1, 1002],\n",
       " [1, 1003],\n",
       " [1, 1004],\n",
       " [1, 1005],\n",
       " [1, 1006],\n",
       " [1, 1007],\n",
       " [3, 1008],\n",
       " [1, 1008],\n",
       " [3, 1009],\n",
       " [1, 1009],\n",
       " [1, 1010],\n",
       " [1, 1010],\n",
       " [1, 1012],\n",
       " [1, 1013],\n",
       " [1, 1014],\n",
       " [1, 1015],\n",
       " [1, 1016],\n",
       " [1, 1017],\n",
       " [1, 1018],\n",
       " [1, 1020],\n",
       " [1, 1021],\n",
       " [1, 1022],\n",
       " [1, 1023],\n",
       " [1, 1024],\n",
       " [3, 1035],\n",
       " [3, 1045],\n",
       " [3, 1064],\n",
       " [3, 1066],\n",
       " [3, 1072],\n",
       " [3, 1075],\n",
       " [3, 1087],\n",
       " [3, 1089],\n",
       " [3, 1098],\n",
       " [3, 1108],\n",
       " [3, 1111],\n",
       " [1, 1124],\n",
       " [1, 1126],\n",
       " [1, 1128],\n",
       " [3, 1130],\n",
       " [1, 1130],\n",
       " [1, 1131],\n",
       " [3, 1134],\n",
       " [1, 1134],\n",
       " [1, 1135],\n",
       " [1, 1137],\n",
       " [1, 1138],\n",
       " [1, 1139],\n",
       " [1, 1140],\n",
       " [1, 1141],\n",
       " [3, 1142],\n",
       " [1, 1142],\n",
       " [3, 1143],\n",
       " [1, 1143],\n",
       " [1, 1145],\n",
       " [1, 1147],\n",
       " [3, 1148],\n",
       " [1, 1148],\n",
       " [1, 1151],\n",
       " [1, 1152],\n",
       " [3, 1153],\n",
       " [1, 1153],\n",
       " [1, 1154],\n",
       " [1, 1155],\n",
       " [1, 1158],\n",
       " [1, 1159],\n",
       " [1, 1161],\n",
       " [1, 1162],\n",
       " [1, 1163],\n",
       " [1, 1164],\n",
       " [1, 1165],\n",
       " [4, 1166],\n",
       " [1, 1171],\n",
       " [1, 1172],\n",
       " [1, 1173],\n",
       " [1, 1174],\n",
       " [3, 1176],\n",
       " [1, 1176],\n",
       " [3, 1177],\n",
       " [1, 1177],\n",
       " [3, 1178],\n",
       " [1, 1178],\n",
       " [1, 1179],\n",
       " [1, 1180],\n",
       " [1, 1181],\n",
       " [1, 1182],\n",
       " [1, 1183],\n",
       " [1, 1184],\n",
       " [1, 1190],\n",
       " [1, 1192],\n",
       " [1, 1193],\n",
       " [1, 1194],\n",
       " [1, 1195],\n",
       " [1, 1198],\n",
       " [1, 1199],\n",
       " [1, 1200],\n",
       " [1, 1201],\n",
       " [3, 1203],\n",
       " [1, 1203],\n",
       " [1, 1204],\n",
       " [1, 1204],\n",
       " [1, 1208],\n",
       " [4, 1208],\n",
       " [1, 1208],\n",
       " [1, 1209],\n",
       " [1, 1213],\n",
       " [3, 1214],\n",
       " [1, 1214],\n",
       " [3, 1215],\n",
       " [1, 1215],\n",
       " ...]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing -ve TCC values and their frequencies\n",
    "y =list(cleaned_imgs_df[cleaned_imgs_df['Proj imgs NE'].isnull()].index)\n",
    "\n",
    "freqs = []\n",
    "freq = 1\n",
    "for i in range(len(y)-1):\n",
    "    if(y[i] == y[i+1]-1):\n",
    "        freq = freq + 1\n",
    "    else:\n",
    "        freqs.append([freq, cleaned_imgs_df['day'].loc[y[i]]])\n",
    "        freq = 1\n",
    "\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in freqs:\n",
    "    if(a>1): \n",
    "        cut_down(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_imgs_df = cleaned_imgs_df.copy(deep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for a,b in freqs:\n",
    "        x.append(b)\n",
    "y = pd.Series(x).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-18,\n",
       " -13,\n",
       " -2,\n",
       " -1,\n",
       " 0,\n",
       " 19,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 44,\n",
       " 45,\n",
       " 47,\n",
       " 48,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 50,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 54,\n",
       " 55,\n",
       " 58,\n",
       " 59,\n",
       " 62,\n",
       " 63,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 81,\n",
       " 82,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 91,\n",
       " 96,\n",
       " 96,\n",
       " 97,\n",
       " 99,\n",
       " 99,\n",
       " 101,\n",
       " 103,\n",
       " 106,\n",
       " 106,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 114,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 123,\n",
       " 124,\n",
       " 126,\n",
       " 127,\n",
       " 131,\n",
       " 132,\n",
       " 132,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 136,\n",
       " 137,\n",
       " 146,\n",
       " 147,\n",
       " 147,\n",
       " 148,\n",
       " 148,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 158,\n",
       " 160,\n",
       " 162,\n",
       " 164,\n",
       " 164,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 166,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 180,\n",
       " 182,\n",
       " 182,\n",
       " 182,\n",
       " 185,\n",
       " 188,\n",
       " 188,\n",
       " 189,\n",
       " 189,\n",
       " 190,\n",
       " 192,\n",
       " 192,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 194,\n",
       " 194,\n",
       " 195,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 199,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 201,\n",
       " 201,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 208,\n",
       " 208,\n",
       " 208,\n",
       " 208,\n",
       " 209,\n",
       " 209,\n",
       " 209,\n",
       " 209,\n",
       " 209,\n",
       " 217,\n",
       " 219,\n",
       " 221,\n",
       " 221,\n",
       " 224,\n",
       " 224,\n",
       " 226,\n",
       " 226,\n",
       " 226,\n",
       " 226,\n",
       " 226,\n",
       " 226,\n",
       " 226,\n",
       " 227,\n",
       " 227,\n",
       " 228,\n",
       " 228,\n",
       " 231,\n",
       " 233,\n",
       " 235,\n",
       " 235,\n",
       " 235,\n",
       " 235,\n",
       " 235,\n",
       " 235,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 241,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 247,\n",
       " 249,\n",
       " 250,\n",
       " 250,\n",
       " 251,\n",
       " 251,\n",
       " 252,\n",
       " 252,\n",
       " 253,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 260,\n",
       " 260,\n",
       " 260,\n",
       " 260,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 263,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 266,\n",
       " 266,\n",
       " 267,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 272,\n",
       " 272,\n",
       " 272,\n",
       " 274,\n",
       " 274,\n",
       " 274,\n",
       " 275,\n",
       " 275,\n",
       " 275,\n",
       " 279,\n",
       " 279,\n",
       " 279,\n",
       " 279,\n",
       " 280,\n",
       " 280,\n",
       " 280,\n",
       " 281,\n",
       " 281,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 286,\n",
       " 286,\n",
       " 287,\n",
       " 287,\n",
       " 287,\n",
       " 287,\n",
       " 288,\n",
       " 288,\n",
       " 290,\n",
       " 290,\n",
       " 293,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 313,\n",
       " 313,\n",
       " 313,\n",
       " 315,\n",
       " 321,\n",
       " 321,\n",
       " 321,\n",
       " 321,\n",
       " 326,\n",
       " 330,\n",
       " 335,\n",
       " 337,\n",
       " 337,\n",
       " 340,\n",
       " 340,\n",
       " 343,\n",
       " 347,\n",
       " 347,\n",
       " 350,\n",
       " 350,\n",
       " 350,\n",
       " 351,\n",
       " 351,\n",
       " 351,\n",
       " 352,\n",
       " 352,\n",
       " 354,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 359,\n",
       " 359,\n",
       " 359,\n",
       " 359,\n",
       " 361,\n",
       " 361,\n",
       " 361,\n",
       " 367,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 369,\n",
       " 370,\n",
       " 370,\n",
       " 371,\n",
       " 371,\n",
       " 371,\n",
       " 371,\n",
       " 371,\n",
       " 373,\n",
       " 373,\n",
       " 373,\n",
       " 375,\n",
       " 375,\n",
       " 381,\n",
       " 381,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 390,\n",
       " 390,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 398,\n",
       " 400,\n",
       " 401,\n",
       " 403,\n",
       " 404,\n",
       " 406,\n",
       " 410,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 417,\n",
       " 419,\n",
       " 419,\n",
       " 422,\n",
       " 423,\n",
       " 425,\n",
       " 427,\n",
       " 427,\n",
       " 432,\n",
       " 432,\n",
       " 439,\n",
       " 440,\n",
       " 440,\n",
       " 442,\n",
       " 443,\n",
       " 443,\n",
       " 443,\n",
       " 443,\n",
       " 443,\n",
       " 447,\n",
       " 447,\n",
       " 447,\n",
       " 447,\n",
       " 447,\n",
       " 447,\n",
       " 448,\n",
       " 448,\n",
       " 448,\n",
       " 448,\n",
       " 448,\n",
       " 448,\n",
       " 450,\n",
       " 450,\n",
       " 450,\n",
       " 450,\n",
       " 451,\n",
       " 451,\n",
       " 451,\n",
       " 451,\n",
       " 451,\n",
       " 455,\n",
       " 455,\n",
       " 455,\n",
       " 455,\n",
       " 455,\n",
       " 455,\n",
       " 457,\n",
       " 457,\n",
       " 457,\n",
       " 457,\n",
       " 458,\n",
       " 458,\n",
       " 458,\n",
       " 458,\n",
       " 458,\n",
       " 463,\n",
       " 463,\n",
       " 463,\n",
       " 463,\n",
       " 465,\n",
       " 465,\n",
       " 465,\n",
       " 465,\n",
       " 469,\n",
       " 469,\n",
       " 469,\n",
       " 469,\n",
       " 469,\n",
       " 470,\n",
       " 470,\n",
       " 470,\n",
       " 470,\n",
       " 472,\n",
       " 472,\n",
       " 472,\n",
       " 472,\n",
       " 485,\n",
       " 485,\n",
       " 485,\n",
       " 485,\n",
       " 485,\n",
       " 485,\n",
       " 486,\n",
       " 486,\n",
       " 488,\n",
       " 488,\n",
       " 488,\n",
       " 492,\n",
       " 492,\n",
       " 492,\n",
       " 492,\n",
       " 497,\n",
       " 497,\n",
       " 497,\n",
       " 497,\n",
       " 497,\n",
       " 497,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 511,\n",
       " 517,\n",
       " 520,\n",
       " 526,\n",
       " 526,\n",
       " 527,\n",
       " 527,\n",
       " 527,\n",
       " 527,\n",
       " 530,\n",
       " 530,\n",
       " 530,\n",
       " 530,\n",
       " 530,\n",
       " 531,\n",
       " 535,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 540,\n",
       " 540,\n",
       " 540,\n",
       " 540,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 550,\n",
       " 550,\n",
       " 550,\n",
       " 552,\n",
       " 555,\n",
       " 555,\n",
       " 555,\n",
       " 558,\n",
       " 558,\n",
       " 559,\n",
       " 562,\n",
       " 564,\n",
       " 565,\n",
       " 571,\n",
       " 577,\n",
       " 577,\n",
       " 578,\n",
       " 578,\n",
       " 578,\n",
       " 578,\n",
       " 579,\n",
       " 579,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 583,\n",
       " 583,\n",
       " 586,\n",
       " 586,\n",
       " 586,\n",
       " 593,\n",
       " 594,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 599,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 602,\n",
       " 602,\n",
       " 603,\n",
       " 603,\n",
       " 604,\n",
       " 604,\n",
       " 605,\n",
       " 608,\n",
       " 610,\n",
       " 611,\n",
       " 614,\n",
       " 617,\n",
       " 618,\n",
       " 618,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 620,\n",
       " 622,\n",
       " 625,\n",
       " 627,\n",
       " 627,\n",
       " 628,\n",
       " 630,\n",
       " 630,\n",
       " 630,\n",
       " 631,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 635,\n",
       " 635,\n",
       " 635,\n",
       " 635,\n",
       " 640,\n",
       " 644,\n",
       " 646,\n",
       " 648,\n",
       " 652,\n",
       " 652,\n",
       " 653,\n",
       " 653,\n",
       " 654,\n",
       " 656,\n",
       " 656,\n",
       " 658,\n",
       " 662,\n",
       " 665,\n",
       " 669,\n",
       " 673,\n",
       " 675,\n",
       " 675,\n",
       " 675,\n",
       " 676,\n",
       " 680,\n",
       " 682,\n",
       " 687,\n",
       " 688,\n",
       " 690,\n",
       " 696,\n",
       " 697,\n",
       " 705,\n",
       " 712,\n",
       " 713,\n",
       " 719,\n",
       " 721,\n",
       " 722,\n",
       " 725,\n",
       " 732,\n",
       " 741,\n",
       " 741,\n",
       " 751,\n",
       " 756,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 784,\n",
       " 785,\n",
       " 785,\n",
       " 786,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 817,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 823,\n",
       " 823,\n",
       " 823,\n",
       " 823,\n",
       " 828,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 869,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 879,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 894,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 907,\n",
       " 908,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 918,\n",
       " 919,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 925,\n",
       " 926,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 960,\n",
       " 962,\n",
       " 963,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 966,\n",
       " 967,\n",
       " 967,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 992,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 997,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " 1001,\n",
       " 1002,\n",
       " 1003,\n",
       " 1004,\n",
       " 1005,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1008,\n",
       " 1009,\n",
       " 1009,\n",
       " 1010,\n",
       " 1010,\n",
       " 1012,\n",
       " 1013,\n",
       " 1014,\n",
       " 1015,\n",
       " 1016,\n",
       " 1017,\n",
       " 1018,\n",
       " 1020,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1035,\n",
       " 1045,\n",
       " 1064,\n",
       " 1066,\n",
       " 1072,\n",
       " 1075,\n",
       " 1087,\n",
       " 1089,\n",
       " 1098,\n",
       " 1108,\n",
       " 1111,\n",
       " 1124,\n",
       " 1126,\n",
       " 1128,\n",
       " 1130,\n",
       " 1130,\n",
       " 1131,\n",
       " 1134,\n",
       " 1134,\n",
       " 1135,\n",
       " 1137,\n",
       " 1138,\n",
       " 1139,\n",
       " 1140,\n",
       " 1141,\n",
       " 1142,\n",
       " 1142,\n",
       " 1143,\n",
       " 1143,\n",
       " 1145,\n",
       " 1147,\n",
       " 1148,\n",
       " 1148,\n",
       " 1151,\n",
       " 1152,\n",
       " 1153,\n",
       " 1153,\n",
       " 1154,\n",
       " 1155,\n",
       " 1158,\n",
       " 1159,\n",
       " 1161,\n",
       " 1162,\n",
       " 1163,\n",
       " 1164,\n",
       " 1165,\n",
       " 1166,\n",
       " 1171,\n",
       " 1172,\n",
       " 1173,\n",
       " 1174,\n",
       " 1176,\n",
       " 1176,\n",
       " 1177,\n",
       " 1177,\n",
       " 1178,\n",
       " 1178,\n",
       " 1179,\n",
       " 1180,\n",
       " 1181,\n",
       " 1182,\n",
       " 1183,\n",
       " 1184,\n",
       " 1190,\n",
       " 1192,\n",
       " 1193,\n",
       " 1194,\n",
       " 1195,\n",
       " 1198,\n",
       " 1199,\n",
       " 1200,\n",
       " 1201,\n",
       " 1203,\n",
       " 1203,\n",
       " 1204,\n",
       " 1204,\n",
       " 1208,\n",
       " 1208,\n",
       " 1208,\n",
       " 1209,\n",
       " 1213,\n",
       " 1214,\n",
       " 1214,\n",
       " 1215,\n",
       " 1215,\n",
       " ...]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in x:\n",
    "    cut_down(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for day in list(y[y > 2].index):\n",
    "#     cut_down(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Proj imgs NE', 'Proj imgs UE', 'BRBG imgs', 'CDOC imgs', 'MST_img',\n",
       "       'Date_img'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_imgs_df.columns[20:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MST</th>\n",
       "      <th>GHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>Zenith Angle</th>\n",
       "      <th>Azimuth Angle</th>\n",
       "      <th>Dry Temp</th>\n",
       "      <th>Wet Temp</th>\n",
       "      <th>Dew Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>...</th>\n",
       "      <th>Proj imgs UE</th>\n",
       "      <th>BRBG imgs</th>\n",
       "      <th>CDOC imgs</th>\n",
       "      <th>MST_img</th>\n",
       "      <th>Date_img</th>\n",
       "      <th>Declination Angle</th>\n",
       "      <th>distance factor</th>\n",
       "      <th>Wind_x</th>\n",
       "      <th>Wind_y</th>\n",
       "      <th>Clear Sky GHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:10</td>\n",
       "      <td>13.30970</td>\n",
       "      <td>212.480000</td>\n",
       "      <td>89.28871</td>\n",
       "      <td>119.33135</td>\n",
       "      <td>10.21</td>\n",
       "      <td>2.528</td>\n",
       "      <td>-7.772</td>\n",
       "      <td>25.36</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201071000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201071000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201071000_1112_CDOC.png</td>\n",
       "      <td>0710</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>1.419725</td>\n",
       "      <td>-3.144341</td>\n",
       "      <td>13.583751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:20</td>\n",
       "      <td>30.88390</td>\n",
       "      <td>361.561000</td>\n",
       "      <td>87.75468</td>\n",
       "      <td>120.95016</td>\n",
       "      <td>11.07</td>\n",
       "      <td>2.992</td>\n",
       "      <td>-7.408</td>\n",
       "      <td>24.72</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201072000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201072000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201072000_1112_CDOC.png</td>\n",
       "      <td>0720</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>2.028488</td>\n",
       "      <td>-3.389356</td>\n",
       "      <td>42.804430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:30</td>\n",
       "      <td>52.38490</td>\n",
       "      <td>475.751000</td>\n",
       "      <td>86.18760</td>\n",
       "      <td>122.59905</td>\n",
       "      <td>11.32</td>\n",
       "      <td>3.279</td>\n",
       "      <td>-7.111</td>\n",
       "      <td>24.95</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201073000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201073000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201073000_1112_CDOC.png</td>\n",
       "      <td>0730</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>1.115431</td>\n",
       "      <td>-2.999302</td>\n",
       "      <td>72.530971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:40</td>\n",
       "      <td>25.40700</td>\n",
       "      <td>14.517500</td>\n",
       "      <td>84.62281</td>\n",
       "      <td>124.28029</td>\n",
       "      <td>10.99</td>\n",
       "      <td>3.106</td>\n",
       "      <td>-7.094</td>\n",
       "      <td>25.54</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201074000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201074000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201074000_1112_CDOC.png</td>\n",
       "      <td>0740</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>-0.034556</td>\n",
       "      <td>-2.199729</td>\n",
       "      <td>102.067937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:50</td>\n",
       "      <td>106.54600</td>\n",
       "      <td>634.944000</td>\n",
       "      <td>83.07628</td>\n",
       "      <td>125.99608</td>\n",
       "      <td>11.02</td>\n",
       "      <td>3.051</td>\n",
       "      <td>-7.349</td>\n",
       "      <td>24.93</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201075000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201075000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201075000_1112_CDOC.png</td>\n",
       "      <td>0750</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>0.567782</td>\n",
       "      <td>-2.383301</td>\n",
       "      <td>131.095973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93737</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>15:50</td>\n",
       "      <td>95.93110</td>\n",
       "      <td>625.967000</td>\n",
       "      <td>83.14403</td>\n",
       "      <td>233.99678</td>\n",
       "      <td>20.41</td>\n",
       "      <td>8.315</td>\n",
       "      <td>-3.985</td>\n",
       "      <td>18.25</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201155000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201155000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201155000_1112_CDOC.png</td>\n",
       "      <td>1550</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.270873</td>\n",
       "      <td>-2.936815</td>\n",
       "      <td>129.828019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93738</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:00</td>\n",
       "      <td>70.30890</td>\n",
       "      <td>554.892000</td>\n",
       "      <td>84.69147</td>\n",
       "      <td>235.70981</td>\n",
       "      <td>20.19</td>\n",
       "      <td>8.261</td>\n",
       "      <td>-4.029</td>\n",
       "      <td>18.43</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201160000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201160000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201160000_1112_CDOC.png</td>\n",
       "      <td>1600</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.916700</td>\n",
       "      <td>-3.164848</td>\n",
       "      <td>100.775266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93739</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:10</td>\n",
       "      <td>15.40180</td>\n",
       "      <td>2.712680</td>\n",
       "      <td>86.25671</td>\n",
       "      <td>237.38831</td>\n",
       "      <td>19.45</td>\n",
       "      <td>7.935</td>\n",
       "      <td>-3.965</td>\n",
       "      <td>19.40</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201161000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201161000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201161000_1112_CDOC.png</td>\n",
       "      <td>1610</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>0.919554</td>\n",
       "      <td>-3.065032</td>\n",
       "      <td>71.222927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93740</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:20</td>\n",
       "      <td>10.41260</td>\n",
       "      <td>-0.732237</td>\n",
       "      <td>87.82324</td>\n",
       "      <td>239.03447</td>\n",
       "      <td>18.47</td>\n",
       "      <td>7.521</td>\n",
       "      <td>-3.979</td>\n",
       "      <td>20.60</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201162000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201162000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201162000_1112_CDOC.png</td>\n",
       "      <td>1620</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>2.107806</td>\n",
       "      <td>-2.407728</td>\n",
       "      <td>41.500880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93741</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:30</td>\n",
       "      <td>5.13126</td>\n",
       "      <td>-0.565152</td>\n",
       "      <td>89.35451</td>\n",
       "      <td>240.65056</td>\n",
       "      <td>18.01</td>\n",
       "      <td>7.275</td>\n",
       "      <td>-4.025</td>\n",
       "      <td>21.12</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201163000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201163000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201163000_1112_CDOC.png</td>\n",
       "      <td>1630</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.409960</td>\n",
       "      <td>-3.420820</td>\n",
       "      <td>12.328009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93742 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    MST        GHI         DNI  Zenith Angle  Azimuth Angle  \\\n",
       "0      12/1/2017  07:10   13.30970  212.480000      89.28871      119.33135   \n",
       "1      12/1/2017  07:20   30.88390  361.561000      87.75468      120.95016   \n",
       "2      12/1/2017  07:30   52.38490  475.751000      86.18760      122.59905   \n",
       "3      12/1/2017  07:40   25.40700   14.517500      84.62281      124.28029   \n",
       "4      12/1/2017  07:50  106.54600  634.944000      83.07628      125.99608   \n",
       "...          ...    ...        ...         ...           ...            ...   \n",
       "93737  12/1/2021  15:50   95.93110  625.967000      83.14403      233.99678   \n",
       "93738  12/1/2021  16:00   70.30890  554.892000      84.69147      235.70981   \n",
       "93739  12/1/2021  16:10   15.40180    2.712680      86.25671      237.38831   \n",
       "93740  12/1/2021  16:20   10.41260   -0.732237      87.82324      239.03447   \n",
       "93741  12/1/2021  16:30    5.13126   -0.565152      89.35451      240.65056   \n",
       "\n",
       "       Dry Temp  Wet Temp  Dew Temp     RH  ...  \\\n",
       "0         10.21     2.528    -7.772  25.36  ...   \n",
       "1         11.07     2.992    -7.408  24.72  ...   \n",
       "2         11.32     3.279    -7.111  24.95  ...   \n",
       "3         10.99     3.106    -7.094  25.54  ...   \n",
       "4         11.02     3.051    -7.349  24.93  ...   \n",
       "...         ...       ...       ...    ...  ...   \n",
       "93737     20.41     8.315    -3.985  18.25  ...   \n",
       "93738     20.19     8.261    -4.029  18.43  ...   \n",
       "93739     19.45     7.935    -3.965  19.40  ...   \n",
       "93740     18.47     7.521    -3.979  20.60  ...   \n",
       "93741     18.01     7.275    -4.025  21.12  ...   \n",
       "\n",
       "                                   Proj imgs UE  \\\n",
       "0      Images/20171201/20171201071000_12_UE.jpg   \n",
       "1      Images/20171201/20171201072000_12_UE.jpg   \n",
       "2      Images/20171201/20171201073000_12_UE.jpg   \n",
       "3      Images/20171201/20171201074000_12_UE.jpg   \n",
       "4      Images/20171201/20171201075000_12_UE.jpg   \n",
       "...                                         ...   \n",
       "93737  Images/20211201/20211201155000_12_UE.jpg   \n",
       "93738  Images/20211201/20211201160000_12_UE.jpg   \n",
       "93739  Images/20211201/20211201161000_12_UE.jpg   \n",
       "93740  Images/20211201/20211201162000_12_UE.jpg   \n",
       "93741  Images/20211201/20211201163000_12_UE.jpg   \n",
       "\n",
       "                                          BRBG imgs  \\\n",
       "0      Images/20171201/20171201071000_1112_BRBG.png   \n",
       "1      Images/20171201/20171201072000_1112_BRBG.png   \n",
       "2      Images/20171201/20171201073000_1112_BRBG.png   \n",
       "3      Images/20171201/20171201074000_1112_BRBG.png   \n",
       "4      Images/20171201/20171201075000_1112_BRBG.png   \n",
       "...                                             ...   \n",
       "93737  Images/20211201/20211201155000_1112_BRBG.png   \n",
       "93738  Images/20211201/20211201160000_1112_BRBG.png   \n",
       "93739  Images/20211201/20211201161000_1112_BRBG.png   \n",
       "93740  Images/20211201/20211201162000_1112_BRBG.png   \n",
       "93741  Images/20211201/20211201163000_1112_BRBG.png   \n",
       "\n",
       "                                          CDOC imgs  MST_img  Date_img  \\\n",
       "0      Images/20171201/20171201071000_1112_CDOC.png     0710  20171201   \n",
       "1      Images/20171201/20171201072000_1112_CDOC.png     0720  20171201   \n",
       "2      Images/20171201/20171201073000_1112_CDOC.png     0730  20171201   \n",
       "3      Images/20171201/20171201074000_1112_CDOC.png     0740  20171201   \n",
       "4      Images/20171201/20171201075000_1112_CDOC.png     0750  20171201   \n",
       "...                                             ...      ...       ...   \n",
       "93737  Images/20211201/20211201155000_1112_CDOC.png     1550  20211201   \n",
       "93738  Images/20211201/20211201160000_1112_CDOC.png     1600  20211201   \n",
       "93739  Images/20211201/20211201161000_1112_CDOC.png     1610  20211201   \n",
       "93740  Images/20211201/20211201162000_1112_CDOC.png     1620  20211201   \n",
       "93741  Images/20211201/20211201163000_1112_CDOC.png     1630  20211201   \n",
       "\n",
       "       Declination Angle  distance factor    Wind_x    Wind_y Clear Sky GHI  \n",
       "0              -0.409105         0.878124  1.419725 -3.144341     13.583751  \n",
       "1              -0.409105         0.878124  2.028488 -3.389356     42.804430  \n",
       "2              -0.409105         0.878124  1.115431 -2.999302     72.530971  \n",
       "3              -0.409105         0.878124 -0.034556 -2.199729    102.067937  \n",
       "4              -0.409105         0.878124  0.567782 -2.383301    131.095973  \n",
       "...                  ...              ...       ...       ...           ...  \n",
       "93737          -0.409105         0.869764  1.270873 -2.936815    129.828019  \n",
       "93738          -0.409105         0.869764  1.916700 -3.164848    100.775266  \n",
       "93739          -0.409105         0.869764  0.919554 -3.065032     71.222927  \n",
       "93740          -0.409105         0.869764  2.107806 -2.407728     41.500880  \n",
       "93741          -0.409105         0.869764  1.409960 -3.420820     12.328009  \n",
       "\n",
       "[93742 rows x 31 columns]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for day in cleaned_imgs_df.day.unique():\n",
    "        for col in list(cleaned_imgs_df.columns[18:24]):\n",
    "            cleaned_imgs_df.loc[(cleaned_imgs_df[cleaned_imgs_df['day']==day][col].index).astype('int64'), (col)] = cleaned_imgs_df[cleaned_imgs_df['day']==day][col].ffill()\n",
    "            cleaned_imgs_df.loc[(cleaned_imgs_df[cleaned_imgs_df['day']==day][col].index).astype('int64'), (col)] = cleaned_imgs_df[cleaned_imgs_df['day']==day][col].bfill()\n",
    "cleaned_imgs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MST</th>\n",
       "      <th>GHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>Zenith Angle</th>\n",
       "      <th>Azimuth Angle</th>\n",
       "      <th>Dry Temp</th>\n",
       "      <th>Wet Temp</th>\n",
       "      <th>Dew Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>...</th>\n",
       "      <th>Proj imgs UE</th>\n",
       "      <th>BRBG imgs</th>\n",
       "      <th>CDOC imgs</th>\n",
       "      <th>MST_img</th>\n",
       "      <th>Date_img</th>\n",
       "      <th>Declination Angle</th>\n",
       "      <th>distance factor</th>\n",
       "      <th>Wind_x</th>\n",
       "      <th>Wind_y</th>\n",
       "      <th>Clear Sky GHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:10</td>\n",
       "      <td>13.30970</td>\n",
       "      <td>212.480000</td>\n",
       "      <td>89.28871</td>\n",
       "      <td>119.33135</td>\n",
       "      <td>10.21</td>\n",
       "      <td>2.528</td>\n",
       "      <td>-7.772</td>\n",
       "      <td>25.36</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201071000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201071000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201071000_1112_CDOC.png</td>\n",
       "      <td>0710</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>1.419725</td>\n",
       "      <td>-3.144341</td>\n",
       "      <td>13.583751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:20</td>\n",
       "      <td>30.88390</td>\n",
       "      <td>361.561000</td>\n",
       "      <td>87.75468</td>\n",
       "      <td>120.95016</td>\n",
       "      <td>11.07</td>\n",
       "      <td>2.992</td>\n",
       "      <td>-7.408</td>\n",
       "      <td>24.72</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201072000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201072000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201072000_1112_CDOC.png</td>\n",
       "      <td>0720</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>2.028488</td>\n",
       "      <td>-3.389356</td>\n",
       "      <td>42.804430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:30</td>\n",
       "      <td>52.38490</td>\n",
       "      <td>475.751000</td>\n",
       "      <td>86.18760</td>\n",
       "      <td>122.59905</td>\n",
       "      <td>11.32</td>\n",
       "      <td>3.279</td>\n",
       "      <td>-7.111</td>\n",
       "      <td>24.95</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201073000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201073000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201073000_1112_CDOC.png</td>\n",
       "      <td>0730</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>1.115431</td>\n",
       "      <td>-2.999302</td>\n",
       "      <td>72.530971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:40</td>\n",
       "      <td>25.40700</td>\n",
       "      <td>14.517500</td>\n",
       "      <td>84.62281</td>\n",
       "      <td>124.28029</td>\n",
       "      <td>10.99</td>\n",
       "      <td>3.106</td>\n",
       "      <td>-7.094</td>\n",
       "      <td>25.54</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201074000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201074000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201074000_1112_CDOC.png</td>\n",
       "      <td>0740</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>-0.034556</td>\n",
       "      <td>-2.199729</td>\n",
       "      <td>102.067937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>07:50</td>\n",
       "      <td>106.54600</td>\n",
       "      <td>634.944000</td>\n",
       "      <td>83.07628</td>\n",
       "      <td>125.99608</td>\n",
       "      <td>11.02</td>\n",
       "      <td>3.051</td>\n",
       "      <td>-7.349</td>\n",
       "      <td>24.93</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20171201/20171201075000_12_UE.jpg</td>\n",
       "      <td>Images/20171201/20171201075000_1112_BRBG.png</td>\n",
       "      <td>Images/20171201/20171201075000_1112_CDOC.png</td>\n",
       "      <td>0750</td>\n",
       "      <td>20171201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.878124</td>\n",
       "      <td>0.567782</td>\n",
       "      <td>-2.383301</td>\n",
       "      <td>131.095973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97457</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>15:50</td>\n",
       "      <td>95.93110</td>\n",
       "      <td>625.967000</td>\n",
       "      <td>83.14403</td>\n",
       "      <td>233.99678</td>\n",
       "      <td>20.41</td>\n",
       "      <td>8.315</td>\n",
       "      <td>-3.985</td>\n",
       "      <td>18.25</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201155000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201155000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201155000_1112_CDOC.png</td>\n",
       "      <td>1550</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.270873</td>\n",
       "      <td>-2.936815</td>\n",
       "      <td>129.828019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97458</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:00</td>\n",
       "      <td>70.30890</td>\n",
       "      <td>554.892000</td>\n",
       "      <td>84.69147</td>\n",
       "      <td>235.70981</td>\n",
       "      <td>20.19</td>\n",
       "      <td>8.261</td>\n",
       "      <td>-4.029</td>\n",
       "      <td>18.43</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201160000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201160000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201160000_1112_CDOC.png</td>\n",
       "      <td>1600</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.916700</td>\n",
       "      <td>-3.164848</td>\n",
       "      <td>100.775266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97459</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:10</td>\n",
       "      <td>15.40180</td>\n",
       "      <td>2.712680</td>\n",
       "      <td>86.25671</td>\n",
       "      <td>237.38831</td>\n",
       "      <td>19.45</td>\n",
       "      <td>7.935</td>\n",
       "      <td>-3.965</td>\n",
       "      <td>19.40</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201161000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201161000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201161000_1112_CDOC.png</td>\n",
       "      <td>1610</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>0.919554</td>\n",
       "      <td>-3.065032</td>\n",
       "      <td>71.222927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97460</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:20</td>\n",
       "      <td>10.41260</td>\n",
       "      <td>-0.732237</td>\n",
       "      <td>87.82324</td>\n",
       "      <td>239.03447</td>\n",
       "      <td>18.47</td>\n",
       "      <td>7.521</td>\n",
       "      <td>-3.979</td>\n",
       "      <td>20.60</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201162000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201162000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201162000_1112_CDOC.png</td>\n",
       "      <td>1620</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>2.107806</td>\n",
       "      <td>-2.407728</td>\n",
       "      <td>41.500880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97461</th>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16:30</td>\n",
       "      <td>5.13126</td>\n",
       "      <td>-0.565152</td>\n",
       "      <td>89.35451</td>\n",
       "      <td>240.65056</td>\n",
       "      <td>18.01</td>\n",
       "      <td>7.275</td>\n",
       "      <td>-4.025</td>\n",
       "      <td>21.12</td>\n",
       "      <td>...</td>\n",
       "      <td>Images/20211201/20211201163000_12_UE.jpg</td>\n",
       "      <td>Images/20211201/20211201163000_1112_BRBG.png</td>\n",
       "      <td>Images/20211201/20211201163000_1112_CDOC.png</td>\n",
       "      <td>1630</td>\n",
       "      <td>20211201</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>1.409960</td>\n",
       "      <td>-3.420820</td>\n",
       "      <td>12.328009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97462 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    MST        GHI         DNI  Zenith Angle  Azimuth Angle  \\\n",
       "0      12/1/2017  07:10   13.30970  212.480000      89.28871      119.33135   \n",
       "1      12/1/2017  07:20   30.88390  361.561000      87.75468      120.95016   \n",
       "2      12/1/2017  07:30   52.38490  475.751000      86.18760      122.59905   \n",
       "3      12/1/2017  07:40   25.40700   14.517500      84.62281      124.28029   \n",
       "4      12/1/2017  07:50  106.54600  634.944000      83.07628      125.99608   \n",
       "...          ...    ...        ...         ...           ...            ...   \n",
       "97457  12/1/2021  15:50   95.93110  625.967000      83.14403      233.99678   \n",
       "97458  12/1/2021  16:00   70.30890  554.892000      84.69147      235.70981   \n",
       "97459  12/1/2021  16:10   15.40180    2.712680      86.25671      237.38831   \n",
       "97460  12/1/2021  16:20   10.41260   -0.732237      87.82324      239.03447   \n",
       "97461  12/1/2021  16:30    5.13126   -0.565152      89.35451      240.65056   \n",
       "\n",
       "       Dry Temp  Wet Temp  Dew Temp     RH  ...  \\\n",
       "0         10.21     2.528    -7.772  25.36  ...   \n",
       "1         11.07     2.992    -7.408  24.72  ...   \n",
       "2         11.32     3.279    -7.111  24.95  ...   \n",
       "3         10.99     3.106    -7.094  25.54  ...   \n",
       "4         11.02     3.051    -7.349  24.93  ...   \n",
       "...         ...       ...       ...    ...  ...   \n",
       "97457     20.41     8.315    -3.985  18.25  ...   \n",
       "97458     20.19     8.261    -4.029  18.43  ...   \n",
       "97459     19.45     7.935    -3.965  19.40  ...   \n",
       "97460     18.47     7.521    -3.979  20.60  ...   \n",
       "97461     18.01     7.275    -4.025  21.12  ...   \n",
       "\n",
       "                                   Proj imgs UE  \\\n",
       "0      Images/20171201/20171201071000_12_UE.jpg   \n",
       "1      Images/20171201/20171201072000_12_UE.jpg   \n",
       "2      Images/20171201/20171201073000_12_UE.jpg   \n",
       "3      Images/20171201/20171201074000_12_UE.jpg   \n",
       "4      Images/20171201/20171201075000_12_UE.jpg   \n",
       "...                                         ...   \n",
       "97457  Images/20211201/20211201155000_12_UE.jpg   \n",
       "97458  Images/20211201/20211201160000_12_UE.jpg   \n",
       "97459  Images/20211201/20211201161000_12_UE.jpg   \n",
       "97460  Images/20211201/20211201162000_12_UE.jpg   \n",
       "97461  Images/20211201/20211201163000_12_UE.jpg   \n",
       "\n",
       "                                          BRBG imgs  \\\n",
       "0      Images/20171201/20171201071000_1112_BRBG.png   \n",
       "1      Images/20171201/20171201072000_1112_BRBG.png   \n",
       "2      Images/20171201/20171201073000_1112_BRBG.png   \n",
       "3      Images/20171201/20171201074000_1112_BRBG.png   \n",
       "4      Images/20171201/20171201075000_1112_BRBG.png   \n",
       "...                                             ...   \n",
       "97457  Images/20211201/20211201155000_1112_BRBG.png   \n",
       "97458  Images/20211201/20211201160000_1112_BRBG.png   \n",
       "97459  Images/20211201/20211201161000_1112_BRBG.png   \n",
       "97460  Images/20211201/20211201162000_1112_BRBG.png   \n",
       "97461  Images/20211201/20211201163000_1112_BRBG.png   \n",
       "\n",
       "                                          CDOC imgs  MST_img  Date_img  \\\n",
       "0      Images/20171201/20171201071000_1112_CDOC.png     0710  20171201   \n",
       "1      Images/20171201/20171201072000_1112_CDOC.png     0720  20171201   \n",
       "2      Images/20171201/20171201073000_1112_CDOC.png     0730  20171201   \n",
       "3      Images/20171201/20171201074000_1112_CDOC.png     0740  20171201   \n",
       "4      Images/20171201/20171201075000_1112_CDOC.png     0750  20171201   \n",
       "...                                             ...      ...       ...   \n",
       "97457  Images/20211201/20211201155000_1112_CDOC.png     1550  20211201   \n",
       "97458  Images/20211201/20211201160000_1112_CDOC.png     1600  20211201   \n",
       "97459  Images/20211201/20211201161000_1112_CDOC.png     1610  20211201   \n",
       "97460  Images/20211201/20211201162000_1112_CDOC.png     1620  20211201   \n",
       "97461  Images/20211201/20211201163000_1112_CDOC.png     1630  20211201   \n",
       "\n",
       "       Declination Angle  distance factor    Wind_x    Wind_y Clear Sky GHI  \n",
       "0              -0.409105         0.878124  1.419725 -3.144341     13.583751  \n",
       "1              -0.409105         0.878124  2.028488 -3.389356     42.804430  \n",
       "2              -0.409105         0.878124  1.115431 -2.999302     72.530971  \n",
       "3              -0.409105         0.878124 -0.034556 -2.199729    102.067937  \n",
       "4              -0.409105         0.878124  0.567782 -2.383301    131.095973  \n",
       "...                  ...              ...       ...       ...           ...  \n",
       "97457          -0.409105         0.869764  1.270873 -2.936815    129.828019  \n",
       "97458          -0.409105         0.869764  1.916700 -3.164848    100.775266  \n",
       "97459          -0.409105         0.869764  0.919554 -3.065032     71.222927  \n",
       "97460          -0.409105         0.869764  2.107806 -2.407728     41.500880  \n",
       "97461          -0.409105         0.869764  1.409960 -3.420820     12.328009  \n",
       "\n",
       "[97462 rows x 31 columns]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for day in imputed_imgs_df.day.unique():\n",
    "        for col in list(imputed_imgs_df.columns[18:24]):\n",
    "            imputed_imgs_df.loc[(imputed_imgs_df[imputed_imgs_df['day']==day][col].index).astype('int64'), (col)] = imputed_imgs_df[imputed_imgs_df['day']==day][col].ffill()\n",
    "            imputed_imgs_df.loc[(imputed_imgs_df[imputed_imgs_df['day']==day][col].index).astype('int64'), (col)] = imputed_imgs_df[imputed_imgs_df['day']==day][col].bfill()\n",
    "imputed_imgs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GHI</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>400.589730</td>\n",
       "      <td>300.266060</td>\n",
       "      <td>-1.534390</td>\n",
       "      <td>136.107500</td>\n",
       "      <td>345.849000</td>\n",
       "      <td>621.723250</td>\n",
       "      <td>1411.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNI</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>481.057297</td>\n",
       "      <td>403.096551</td>\n",
       "      <td>-12.969200</td>\n",
       "      <td>4.827405</td>\n",
       "      <td>541.346000</td>\n",
       "      <td>889.020500</td>\n",
       "      <td>1085.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zenith Angle</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>58.201427</td>\n",
       "      <td>18.820924</td>\n",
       "      <td>16.310560</td>\n",
       "      <td>44.560172</td>\n",
       "      <td>60.649935</td>\n",
       "      <td>72.847273</td>\n",
       "      <td>89.998350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azimuth Angle</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>176.508422</td>\n",
       "      <td>64.043393</td>\n",
       "      <td>59.056390</td>\n",
       "      <td>120.931928</td>\n",
       "      <td>175.034000</td>\n",
       "      <td>232.640600</td>\n",
       "      <td>301.584670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dry Temp</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>14.546617</td>\n",
       "      <td>10.747169</td>\n",
       "      <td>-22.650000</td>\n",
       "      <td>6.492000</td>\n",
       "      <td>15.210000</td>\n",
       "      <td>23.230000</td>\n",
       "      <td>37.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wet Temp</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>6.447131</td>\n",
       "      <td>7.058162</td>\n",
       "      <td>-22.976000</td>\n",
       "      <td>1.097000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>12.659000</td>\n",
       "      <td>19.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dew Temp</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>-1.657406</td>\n",
       "      <td>8.102873</td>\n",
       "      <td>-33.533000</td>\n",
       "      <td>-7.790000</td>\n",
       "      <td>-1.910000</td>\n",
       "      <td>4.811750</td>\n",
       "      <td>18.629000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>38.503783</td>\n",
       "      <td>23.738887</td>\n",
       "      <td>2.129000</td>\n",
       "      <td>20.240000</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>51.570000</td>\n",
       "      <td>100.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCC</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>48.529853</td>\n",
       "      <td>34.876651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>816.482699</td>\n",
       "      <td>5.552193</td>\n",
       "      <td>742.540000</td>\n",
       "      <td>813.434000</td>\n",
       "      <td>817.090000</td>\n",
       "      <td>820.293000</td>\n",
       "      <td>847.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>0.495471</td>\n",
       "      <td>2.375712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Depth</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>0.963794</td>\n",
       "      <td>2.804360</td>\n",
       "      <td>-22.950000</td>\n",
       "      <td>-0.034000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>30.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moisture</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>0.061474</td>\n",
       "      <td>0.237236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albedo</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>0.253159</td>\n",
       "      <td>0.170540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>708.059354</td>\n",
       "      <td>210.130777</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>710.000000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>1170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>1577.481854</td>\n",
       "      <td>854.881956</td>\n",
       "      <td>-29.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>1765.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2776.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Declination Angle</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.409105</td>\n",
       "      <td>-0.409071</td>\n",
       "      <td>-0.408981</td>\n",
       "      <td>-0.408887</td>\n",
       "      <td>-0.408849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance factor</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>-0.098586</td>\n",
       "      <td>0.710794</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.810531</td>\n",
       "      <td>-0.187043</td>\n",
       "      <td>0.602130</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind_x</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>0.449066</td>\n",
       "      <td>1.808562</td>\n",
       "      <td>-9.441006</td>\n",
       "      <td>-0.711257</td>\n",
       "      <td>0.310330</td>\n",
       "      <td>1.585781</td>\n",
       "      <td>10.531591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind_y</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>0.164382</td>\n",
       "      <td>3.062178</td>\n",
       "      <td>-22.931511</td>\n",
       "      <td>-1.183107</td>\n",
       "      <td>0.908849</td>\n",
       "      <td>2.157768</td>\n",
       "      <td>10.897740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clear Sky GHI</th>\n",
       "      <td>93742.0</td>\n",
       "      <td>525.410672</td>\n",
       "      <td>270.498320</td>\n",
       "      <td>0.031534</td>\n",
       "      <td>317.553829</td>\n",
       "      <td>521.920842</td>\n",
       "      <td>749.151001</td>\n",
       "      <td>994.982293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count         mean         std         min         25%  \\\n",
       "GHI                93742.0   400.589730  300.266060   -1.534390  136.107500   \n",
       "DNI                93742.0   481.057297  403.096551  -12.969200    4.827405   \n",
       "Zenith Angle       93742.0    58.201427   18.820924   16.310560   44.560172   \n",
       "Azimuth Angle      93742.0   176.508422   64.043393   59.056390  120.931928   \n",
       "Dry Temp           93742.0    14.546617   10.747169  -22.650000    6.492000   \n",
       "Wet Temp           93742.0     6.447131    7.058162  -22.976000    1.097000   \n",
       "Dew Temp           93742.0    -1.657406    8.102873  -33.533000   -7.790000   \n",
       "RH                 93742.0    38.503783   23.738887    2.129000   20.240000   \n",
       "TCC                93742.0    48.529853   34.876651    0.000000   15.000000   \n",
       "Pressure           93742.0   816.482699    5.552193  742.540000  813.434000   \n",
       "Precipitation      93742.0     0.495471    2.375712    0.000000    0.000000   \n",
       "Snow Depth         93742.0     0.963794    2.804360  -22.950000   -0.034000   \n",
       "Moisture           93742.0     0.061474    0.237236    0.000000    0.000000   \n",
       "Albedo             93742.0     0.253159    0.170540    0.000000    0.176500   \n",
       "Time               93742.0   708.059354  210.130777  280.000000  530.000000   \n",
       "day                93742.0  1577.481854  854.881956  -29.000000  728.000000   \n",
       "Declination Angle  93742.0    -0.408979    0.000091   -0.409105   -0.409071   \n",
       "distance factor    93742.0    -0.098586    0.710794   -0.999998   -0.810531   \n",
       "Wind_x             93742.0     0.449066    1.808562   -9.441006   -0.711257   \n",
       "Wind_y             93742.0     0.164382    3.062178  -22.931511   -1.183107   \n",
       "Clear Sky GHI      93742.0   525.410672  270.498320    0.031534  317.553829   \n",
       "\n",
       "                           50%          75%          max  \n",
       "GHI                 345.849000   621.723250  1411.010000  \n",
       "DNI                 541.346000   889.020500  1085.240000  \n",
       "Zenith Angle         60.649935    72.847273    89.998350  \n",
       "Azimuth Angle       175.034000   232.640600   301.584670  \n",
       "Dry Temp             15.210000    23.230000    37.680000  \n",
       "Wet Temp              6.950000    12.659000    19.849000  \n",
       "Dew Temp             -1.910000     4.811750    18.629000  \n",
       "RH                   31.700000    51.570000   100.100000  \n",
       "TCC                  38.000000    88.000000   100.000000  \n",
       "Pressure            817.090000   820.293000   847.963000  \n",
       "Precipitation         0.000000     0.000000    42.160000  \n",
       "Snow Depth            0.224000     0.644000    30.260000  \n",
       "Moisture              0.000000     0.000000     1.000000  \n",
       "Albedo                0.200700     0.242000     1.000000  \n",
       "Time                710.000000   880.000000  1170.000000  \n",
       "day                1765.000000  2335.000000  2776.000000  \n",
       "Declination Angle    -0.408981    -0.408887    -0.408849  \n",
       "distance factor      -0.187043     0.602130     1.000000  \n",
       "Wind_x                0.310330     1.585781    10.531591  \n",
       "Wind_y                0.908849     2.157768    10.897740  \n",
       "Clear Sky GHI       521.920842   749.151001   994.982293  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_imgs_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_imgs_df['TCC'].replace(-7999, np.NaN, inplace  = True)\n",
    "cleaned_imgs_df['TCC'].replace(-6999, np.NaN, inplace  = True)\n",
    "cleaned_imgs_df['TCC'].interpolate(method='linear', inplace=True)\n",
    "cleaned_imgs_df['TCC'].replace(-1, np.NaN, inplace  = True)\n",
    "cleaned_imgs_df['TCC'].ffill(inplace = True)\n",
    "cleaned_imgs_df['TCC'].bfill(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_imgs_df['TCC'].replace(-7999, np.NaN, inplace  = True)\n",
    "imputed_imgs_df['TCC'].replace(-6999, np.NaN, inplace  = True)\n",
    "imputed_imgs_df['TCC'].interpolate(method='linear', inplace=True)\n",
    "imputed_imgs_df['TCC'].replace(-1, np.NaN, inplace  = True)\n",
    "imputed_imgs_df['TCC'].ffill(inplace = True)\n",
    "imputed_imgs_df['TCC'].bfill(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_imgs_df.to_csv('cleaned_imgs_df.csv',index = False)\n",
    "imputed_imgs_df.to_csv('imputed_imgs_df.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "aRsmaOkCKNgB",
    "outputId": "763a9657-c879-4246-9ef6-efa76e1eb2b5"
   },
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['day'], sort = False, as_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvIBloFNN98a"
   },
   "outputs": [],
   "source": [
    "indexes = np.array([])\n",
    "for name,group in grouped_df:\n",
    "  a = group['TCC']\n",
    "  indexes = np.append(indexes,list(range(group[a>0].index[0],group[a>0].index[-1] + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ1hno6Ni2en"
   },
   "outputs": [],
   "source": [
    "cleaned_df = df.loc[indexes.astype('int64')]\n",
    "cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['TCC'].replace(-7999, np.NaN, inplace  = True)\n",
    "cleaned_df['TCC'].replace(-6999, np.NaN, inplace  = True)\n",
    "cleaned_df['TCC'].replace(-1, np.NaN, inplace  = True)\n",
    "cleaned_df['TCC'].interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cleaned_df.groupby(['Zenith Angle'], sort = False, as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Zenith Angle'], sort = True, as_index = False).size().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['day'], sort = False, as_index = False).first()['Time'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputed df\n",
    "x = df.loc[indexes.astype('int64')]\n",
    "x['TCC'].replace(-7999, np.NaN, inplace  = True)\n",
    "x['TCC'].replace(-6999, np.NaN, inplace  = True)\n",
    "x['TCC'].replace(-1, np.NaN, inplace  = True)\n",
    "x['TCC'].interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = df.copy(deep=False)\n",
    "imputed_df['TCC'].loc[indexes.astype('int64')] = x['TCC']\n",
    "imputed_df['TCC'].replace(-1, np.NaN, inplace  = True)\n",
    "grouped_imputed_df = imputed_df.groupby(['day'], sort = False, as_index = False)\n",
    "for day in grouped_imputed_df.groups.keys():\n",
    "    imputed_df.loc[(imputed_df[imputed_df['day']==day]['TCC'].index).astype('int64'), ('TCC')] = imputed_df[imputed_df['day']==day]['TCC'].fillna(method=\"ffill\")\n",
    "    imputed_df.loc[(imputed_df[imputed_df['day']==day]['TCC'].index).astype('int64'), ('TCC')] = imputed_df[imputed_df['day']==day]['TCC'].fillna(method='backfill')\n",
    "imputed_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing -ve TCC values and their frequencies\n",
    "x = df.loc[indexes.astype('int64')]['TCC']\n",
    "y =list( x[x<0].index)\n",
    "\n",
    "freqs = []\n",
    "freq = 1\n",
    "for i in range(len(y)-1):\n",
    "    if(y[i] == y[i+1]-1):\n",
    "        freq = freq + 1\n",
    "    else:\n",
    "        if freq == 25 or freq == 284:\n",
    "            freqs.append(i)\n",
    "            freq = 1\n",
    "        else:\n",
    "            freq = 1\n",
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rad(angle):\n",
    "    return angle*np.pi/180\n",
    "def to_degree(angle):\n",
    "    return angle*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(x):   \n",
    "#     x['day'] = x['day'] - 30\n",
    "    x['Declination Angle'] = np.arcsin(np.sin(to_rad(-23.44))*np.cos(to_rad((360/np.pi)*0.0167*np.sin(to_rad(360/365.24*(x['day'] - 2))) + np.cos(to_rad(360/365.24*(x['day'] + 10))))))\n",
    "    wv = x.pop('Wind Speed')\n",
    "    x['distance factor'] = np.cos(2*np.pi*x['day']/365.25)\n",
    "    # Convert to radians.\n",
    "    wd_rad = x.pop('Wind Direction')*np.pi / 180\n",
    "    # Calculate the wind x and y components.\n",
    "    x['Wind_x'] = wv*np.cos(wd_rad)\n",
    "    x['Wind_y'] = wv*np.sin(wd_rad)\n",
    "    x['Clear Sky GHI'] = 1095*np.cos(to_rad(x['Zenith Angle']))*np.exp(-0.057*np.cos(to_rad(x['Zenith Angle'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features(imputed_df)\n",
    "add_features(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(list(cleaned_df['GHI']), list(cleaned_df['Clear Sky GHI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_df[:1440*5].plot(subplots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = cleaned_df.groupby(['Time'], sort = True, as_index = False).mean()\n",
    "# x.plot(subplots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = imputed_df.groupby(['Time'], sort = True, as_index = False).mean()\n",
    "# x.plot(subplots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('cleaned_df.csv',index = False)\n",
    "imputed_df.to_csv('imputed_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "id": "t6zU_kU9t2Vh",
    "outputId": "67a02570-5835-494a-9d72-60d624d66e21"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting correlation between every pair of columns\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "sns.heatmap(imputed_df.corr(),annot = True,cmap = \"YlGnBu\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpl.rcParams['figure.figsize'] = (6, 6)\n",
    "# start_time.hist()\n",
    "# # Start time is from 4 30 am to 7 30 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time.hist()\n",
    "# # end time is 8am - 5pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_list[220][df_list[0].columns[2]]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 12)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('cleaned_df.csv')\n",
    "imputed_df = pd.read_csv('imputed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def calc_time(time):\n",
    "    return int(time.split(':')[0])*60 + int(time.split(':')[1])\n",
    "def calc_day(day):\n",
    "    x = date(int(day.split('/')[2]), int(day.split('/')[0]),int(day.split('/')[1]))\n",
    "    if(day.split('/')[2]=='2017'):\n",
    "        return x.timetuple().tm_yday-365+1\n",
    "    if(day.split('/')[2]=='2018'):\n",
    "        return x.timetuple().tm_yday\n",
    "    if(day.split('/')[2]=='2019'):\n",
    "        return x.timetuple().tm_yday+365\n",
    "    if(day.split('/')[2]=='2020'):\n",
    "        return x.timetuple().tm_yday+365*2\n",
    "    if(day.split('/')[2]=='2021'):\n",
    "        return x.timetuple().tm_yday+365*3+1\n",
    "def test_calc_day(day):\n",
    "    x = date(int(day.split('/')[0]), int(day.split('/')[1]),int(day.split('/')[2]))\n",
    "    if(day.split('/')[0]=='2017'):\n",
    "        return x.timetuple().tm_yday-365+1\n",
    "    if(day.split('/')[0]=='2018'):\n",
    "        return x.timetuple().tm_yday\n",
    "    if(day.split('/')[0]=='2019'):\n",
    "        return x.timetuple().tm_yday+365\n",
    "    if(day.split('/')[0]=='2020'):\n",
    "        return x.timetuple().tm_yday+365*2\n",
    "    if(day.split('/')[0]=='2021'):\n",
    "        return x.timetuple().tm_yday+365*3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[433, 1052]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_days_list = ['3/9/2019', '11/17/2020']\n",
    "del_days_list = [calc_day(i) for i in del_days_list]\n",
    "del_days_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [None]*300\n",
    "for i in range(1,301):\n",
    "    t_df = pd.read_csv('data_to_nvidia/Data_Test/{}/weather_data.csv'.format(i))\n",
    "    t_df['Time'] = [calc_time(j) for j in t_df['MST']]\n",
    "    t_df['day'] = [test_calc_day(j) for j in t_df['DATE (YYYY/MM/DD)']]\n",
    "    df_list[i-1] = t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = []\n",
    "end_time = []\n",
    "length = []\n",
    "test_days_list = []\n",
    "for t_df in df_list:\n",
    "    start_time.append(t_df['Time'][0])\n",
    "    length.append(len(t_df))\n",
    "    end_time.append(t_df['Time'][len(t_df)-1])\n",
    "    test_days_list.append(t_df['day'][0])\n",
    "start_time = pd.Series(start_time)\n",
    "end_time = pd.Series(end_time)\n",
    "length = pd.Series(length)\n",
    "\n",
    "test_days_list_unique = list(pd.Series(test_days_list).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(tup):\n",
    "    day,start_time,end_time = tup\n",
    "    df = imputed_df[imputed_df['day']==day]\n",
    "    return df.loc[(df['Time'] >= start_time) & (df['Time'] <= end_time)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "We_hLzsicIlU"
   },
   "outputs": [],
   "source": [
    "# Split into Train and Validation data\n",
    "\n",
    "X = imputed_df['day'].unique()\n",
    "from sklearn.utils import shuffle\n",
    "X = shuffle(X, random_state = 9)\n",
    "X = list(X)\n",
    "for i in test_days_list_unique:\n",
    "    X.remove(i)\n",
    "for i in del_days_list:\n",
    "    X.remove(i)\n",
    "train_days = X[0:int(len(X)*0.85)]\n",
    "val_days = X[int(len(X)*0.85):]\n",
    "test_days = test_days_list_unique\n",
    "\n",
    "def get_dataframe(dataf,days_list):\n",
    "  indexes_list = []\n",
    "  for day in days_list:\n",
    "    indexes_list = np.append(indexes_list, dataf[dataf['day'] == day].index)\n",
    "  return dataf.iloc[np.array(indexes_list).astype('int64')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IC4pTGMMzVnP"
   },
   "outputs": [],
   "source": [
    "train_df = get_dataframe(imputed_df, train_days).drop(['MST','Date'], axis = 1)\n",
    "val_df = get_dataframe(imputed_df, val_days).drop(['MST','Date'], axis = 1)\n",
    "test_df = get_dataframe(imputed_df, test_days).drop(['MST','Date'], axis = 1)\n",
    "\n",
    "a = train_df['day']\n",
    "b = val_df['day']\n",
    "c = test_df['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vgz7__YN3jaW"
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df- train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "train_df['day'] = a\n",
    "val_df['day'] = b\n",
    "test_df['day'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_dfs = [fetch(i).drop(['MST','Date'], axis = 1) for i in list(zip(test_days_list,start_time,end_time))]\n",
    "\n",
    "for i in range(len(full_test_dfs)):\n",
    "       full_test_dfs[i] = (full_test_dfs[i]- train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(x,path):\n",
    "  x.index = list(range(1,301))\n",
    "  x.to_csv(path,header=['10_min_horizon','20_min_horizon','30_min_horizon','40_min_horizon','50_min_horizon', '60_min_horizon','70_min_horizon','80_min_horizon','90_min_horizon','100_min_horizon','110_min_horizon','120_min_horizon'], index=True, index_label = 'scenario_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mean['GHI']*(30) /100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ebHsDJYBqPn0"
   },
   "outputs": [],
   "source": [
    "#Ensembling\n",
    "\n",
    "# df_nn = pd.read_csv('/content/sub.csv')\n",
    "# df_loocf = pd.read_csv('/content/sub3.csv')\n",
    "# x = (df_nn + df_loocf) / 2\n",
    "# create_submission(x.drop('scenario_set', axis = 1),'/content/sub1.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nygxuLs0VRP"
   },
   "source": [
    "### Using Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxITR-i3TNrU"
   },
   "outputs": [],
   "source": [
    "# # extract test data\n",
    "# import os\n",
    "# test_data = []*300\n",
    "# for i in range(1,301):\n",
    "#   t_df = pd.read_csv(os.path.join('/content/drive/MyDrive/Shell_ai/dataset/test', str(i), \"weather_data.csv\")) \n",
    "#   t_df['Total Cloud Cover [%]'].replace(-7999, np.NaN, inplace  = True)\n",
    "#   t_df['Total Cloud Cover [%]'].replace(-1, np.NaN, inplace  = True)\n",
    "#   t_df['Total Cloud Cover [%]'].replace(-6999, np.NaN, inplace  = True) \n",
    "#   t_df['Total Cloud Cover [%]'].fillna(method=\"ffill\", inplace=True)\n",
    "#   t_df['Total Cloud Cover [%]'].fillna(method='backfill', inplace=True)\n",
    "#   t_df.drop('Time [Mins]', axis = 1, inplace = True)\n",
    "#   wv = t_df.pop('Peak Wind Speed @ 6ft [m/s]')\n",
    "#   # Convert to radians.\n",
    "#   wd_rad = t_df.pop('Avg Wind Direction @ 6ft [deg from N]')*np.pi / 180\n",
    "#   # Calculate the wind x and y components.\n",
    "#   t_df['Wind_x'] = wv*np.cos(wd_rad)\n",
    "#   t_df['Wind_y'] = wv*np.sin(wd_rad)\n",
    "#   t_df = (t_df- train_mean.drop('day')) / train_std.drop('day')\n",
    "#   test_data.append(t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kgTYqBfHp3m"
   },
   "outputs": [],
   "source": [
    "# train_df['tcc_30'] = series.shift(-30)\n",
    "# train_df['tcc_60'] = series.shift(-60)\n",
    "# train_df['tcc_90'] = series.shift(-90)\n",
    "# train_df['tcc_120'] = series.shift(-120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oxMFqYnjHy__"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "form",
    "id": "LWIs0M0Huyam"
   },
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,label_shift,\n",
    "               train_df = train_df, val_df = val_df, test_df = test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "    self.label_shift = label_shift\n",
    "    self.total_window_size = input_width + shift + label_shift*(label_width - 1)\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.input_width + self.shift - 1\n",
    "    self.labels_slice = slice(self.label_start, None, label_shift)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window\n",
    "\n",
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=128)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset\n",
    "\n",
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example\n",
    "\n",
    "import random\n",
    "def chain(iterables):\n",
    "  while True:\n",
    "    random.shuffle(iterables)\n",
    "    for it in iterables:\n",
    "      lst = list(it)\n",
    "      random.shuffle(lst)\n",
    "      for element in lst:\n",
    "          yield element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "9kE9vBfz6ZA3"
   },
   "outputs": [],
   "source": [
    "for ws in [1]:\n",
    "  print(\"\\n\\nfor ws = {}\".format(ws))\n",
    "  grouped_df1 = train_df.groupby(['day'], sort = False, as_index = False)\n",
    "  iter_list_train = [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day).drop(['day','Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor','RH']], label_columns=['GHI']).train for day in train_df['day'].unique() ]\n",
    "  # train_generator = itertools.chain.from_iterable( iter_list )\n",
    "\n",
    "  grouped_df1 = val_df.groupby(['day'], sort = False, as_index = False)\n",
    "  iter_list_val = [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day).drop(['day','Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor','RH']], label_columns=['GHI']).train for day in val_df['day'].unique() ]\n",
    "  # val_generator = itertools.chain.from_iterable( iter_list )\n",
    "\n",
    "  grouped_df1 = test_df.groupby(['day'], sort = False, as_index = False)\n",
    "  iter_list_test = [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day).drop(['day','Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor','RH']], label_columns=['GHI']).train for day in test_df['day'].unique() ]\n",
    "  # test_generator = itertools.chain.from_iterable( iter_list )\n",
    "\n",
    "  train_batches = 0\n",
    "  for x in iter_list_train:\n",
    "    train_batches = train_batches + len(x)\n",
    "  print(train_batches)\n",
    "  val_batches = 0\n",
    "  for x in iter_list_val:\n",
    "    val_batches = val_batches + len(x)\n",
    "  print(val_batches)\n",
    "\n",
    "  test_batches = 0\n",
    "  for x in iter_list_test:\n",
    "    test_batches = test_batches + len(x)\n",
    "  print(test_batches)\n",
    "\n",
    "  train_gen = chain(iter_list_train)\n",
    "  val_gen = chain(iter_list_val)\n",
    "  test_gen = chain(iter_list_test)\n",
    "    \n",
    "  # Linear Model\n",
    "  linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(ws, 6)),\n",
    "    tf.keras.layers.Dense(units=12)\n",
    "])\n",
    "\n",
    "  callbacks = [\n",
    "      EarlyStopping(monitor='val_loss', patience=3,  mode='min',verbose=1),\n",
    "      ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-9, verbose=1),\n",
    "      ModelCheckpoint('linear_{}.h5'.format(ws), verbose=1, save_best_only=True, save_weights_only=True) ]\n",
    "\n",
    "  linear.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                optimizer=tf.optimizers.SGD(learning_rate=1e-2, momentum = 0.9),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = linear.fit(train_gen, steps_per_epoch = train_batches, epochs=1, validation_data = val_gen, validation_steps = val_batches, callbacks=callbacks)\n",
    "  linear.evaluate(test_gen, steps = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.58504530090028"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.388*train_std['GHI']\n",
    "# 112.49 is mae for linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.3746*train_std['GHI']\n",
    "# 112.96(imputed_df) is mae for linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(6),\n",
    "        height=linear.layers[1].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(6))\n",
    "_ = axis.set_xticklabels(['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor','RH'], rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XmVkQbw_q_07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makhila\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from tensorflow import keras\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = ['GHI',\n",
    " 'DNI',\n",
    " 'Azimuth Angle',\n",
    " 'Dry Temp',\n",
    " 'Dew Temp',\n",
    " 'RH',\n",
    " 'TCC',\n",
    " 'Pressure',\n",
    " 'Precipitation',\n",
    " 'Snow Depth',\n",
    " 'Moisture',\n",
    " 'Albedo',\n",
    " 'day',\n",
    " 'Declination Angle',\n",
    " 'distance factor',\n",
    " 'Wind_x',\n",
    " 'Wind_y',\n",
    " 'Clear Sky GHI']\n",
    "\n",
    "l2 = ['GHI',\n",
    " 'DNI',\n",
    " 'Azimuth Angle',\n",
    " 'Dry Temp',\n",
    " 'Dew Temp',\n",
    " 'RH',\n",
    " 'TCC',\n",
    " 'Pressure',\n",
    " 'Precipitation',\n",
    " 'Moisture',\n",
    " 'Wind_x',\n",
    " 'Wind_y',\n",
    " 'distance factor',\n",
    " 'Clear Sky GHI']\n",
    "\n",
    "l3 = ['GHI',\n",
    "       'DNI',\n",
    " 'Azimuth Angle',\n",
    " 'Dry Temp',\n",
    " 'RH',\n",
    " 'Pressure',\n",
    " 'TCC',\n",
    " 'Precipitation',\n",
    " 'distance factor',\n",
    " 'Clear Sky GHI']\n",
    "\n",
    "\n",
    "l4 = ['GHI',\n",
    " 'Azimuth Angle',\n",
    " 'TCC',\n",
    " 'distance factor',\n",
    " 'Clear Sky GHI']\n",
    "\n",
    "l = [l1,l2,l3,l4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHihunCFzcPC"
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xd8GpFudzEiU"
   },
   "outputs": [],
   "source": [
    "def Model(units_1,units_2):\n",
    "\n",
    "    mlp_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = units_1, activation='leaky_relu'),\n",
    "    tf.keras.layers.Dense(units = units_2, activation='leaky_relu'),\n",
    "    tf.keras.layers.Dense(units=12),\n",
    "  ])\n",
    "    return mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpl.rcParams['figure.figsize'] = (6,6)   \n",
    "# x = imputed_df.groupby(['day'], sort = False, as_index = False)\n",
    "# x.get_group(73)['GHI'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.get_group(73)[200:200+350]['GHI'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.get_group(73)[::5]['GHI'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI_JI2HBZs10"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  'method': 'grid', \n",
    "  'metric': {\n",
    "      'name': 'val_loss',\n",
    "      'goal': 'minimize'\n",
    "  },\n",
    "  'early_terminate':{\n",
    "      'type': 'hyperband',\n",
    "      'min_iter': 2,\n",
    "      'eta': 2\n",
    "    },\n",
    "\n",
    "  'parameters': {\n",
    "      'learning_rate':{\n",
    "          'values': [1e-2]\n",
    "      },\n",
    "      'sr_nd_ws':{\n",
    "          'values': [[10,12]]\n",
    "      },\n",
    "      'units_1':{\n",
    "          'values': [256]\n",
    "      },\n",
    "      'units_2':{\n",
    "          'values': [32]\n",
    "      },\n",
    "      'cols_list':{\n",
    "          'values': [2,3]\n",
    "      },\n",
    "      'optimizers':{\n",
    "          'values': [0]\n",
    "      },\n",
    "      'loss':{\n",
    "          'values': [0]\n",
    "      }\n",
    "    },\n",
    "                     \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98pkZByxC4Pl"
   },
   "outputs": [],
   "source": [
    "def sweep_train():\n",
    "    # Specify the hyperparameter to be tuned along with\n",
    "    # an initial value\n",
    "    config_defaults = {\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    "\n",
    "    # Initialize wandb with a sample project name\n",
    "    wandb.init(config=config_defaults)  # this gets over-written in the Sweep\n",
    "    cfg = wandb.config\n",
    "    # Specify the other hyperparameters to the configuration, if any\n",
    "#     cfg.epochs = 30\n",
    "#     cfg.architecture_name = \"Huber_MLP\"\n",
    "\n",
    "    grouped_df1 = train_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_train = [ WindowGenerator(input_width=cfg.sr_nd_ws[1], label_width = 12, shift=10//cfg.sr_nd_ws[0], label_shift = 10//cfg.sr_nd_ws[0],train_df = grouped_df1.get_group(day)[::cfg.sr_nd_ws[0]][l[cfg.cols_list]],label_columns=['GHI']).train for day in train_df['day'].unique() ]\n",
    "\n",
    "    grouped_df1 = val_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_val = [ WindowGenerator(input_width=cfg.sr_nd_ws[1], label_width = 12, shift=10//cfg.sr_nd_ws[0], label_shift = 10//cfg.sr_nd_ws[0],train_df = grouped_df1.get_group(day)[::cfg.sr_nd_ws[0]][l[cfg.cols_list]],label_columns=['GHI']).train for day in val_df['day'].unique() ]\n",
    "\n",
    "    grouped_df1 = test_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_test = [ WindowGenerator(input_width=cfg.sr_nd_ws[1], label_width = 12, shift=10//cfg.sr_nd_ws[0], label_shift = 10//cfg.sr_nd_ws[0],train_df = grouped_df1.get_group(day)[::cfg.sr_nd_ws[0]][l[cfg.cols_list]],label_columns=['GHI']).train for day in test_df['day'].unique() ]\n",
    "\n",
    "    train_batches = 0\n",
    "    for x in iter_list_train:\n",
    "      train_batches = train_batches + len(x)\n",
    "    print(train_batches)\n",
    "    val_batches = 0\n",
    "    for x in iter_list_val:\n",
    "      val_batches = val_batches + len(x)\n",
    "    print(val_batches)\n",
    "\n",
    "    test_batches = 0\n",
    "    for x in iter_list_test:\n",
    "      test_batches = test_batches + len(x)\n",
    "    print(test_batches)\n",
    "\n",
    "    train_gen = chain(iter_list_train)\n",
    "    val_gen = chain(iter_list_val)\n",
    "    test_gen = chain(iter_list_test)\n",
    "\n",
    "    # initialize model\n",
    "    model = Model(cfg.units_1,cfg.units_2)\n",
    "    \n",
    "#     sgd = tf.keras.optimizers.SGD(lr=cfg.learning_rate, momentum = 0.9)\n",
    "#     adam = tf.keras.optimizers.Adam(lr=cfg.learning_rate)\n",
    "#     opt = [sgd,adam]\n",
    "#     losses = ['mae','mse']\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=cfg.learning_rate, momentum = 0.9),loss=tf.keras.losses.Huber(),metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience = 3,  mode='min'),\n",
    "        ReduceLROnPlateau(factor=0.25, patience = 2, verbose=1),\n",
    "        ModelCheckpoint('MLP_l:{}_sr:{}_ws:{}_u1:{}_u2:{}_cols:{}.h5'.format(cfg.learning_rate, cfg.sr_nd_ws[0],cfg.sr_nd_ws[1], cfg.units_1, cfg.units_2,cfg.cols_list), verbose=1, save_best_only=True, save_weights_only=True) ]\n",
    "\n",
    "  \n",
    "    # train and validate\n",
    "    history = model.fit(train_gen, steps_per_epoch = train_batches, epochs=30, validation_data = val_gen, validation_steps = val_batches,callbacks = [WandbCallback(),callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWpCLwGqncdF",
    "outputId": "8a122696-2731-4bd9-e23c-38d56a3b2c92"
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"shell_hack-level-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "86e2cdab31b647d290a584f6918a83c4",
      "e3061569043f490495d74e393abdb9f8",
      "e74267d2d1f54f49b32e19a3cf808c75",
      "5db2fc6dcbac4dddbf1b2b1ba6a6bd6c",
      "794f1a24b1a54420822d889703eb0c19",
      "e6b4e84658924f7ba25bb022bb368518",
      "f50a779f9ff041dfbcd9115ea0f6e642",
      "0f0e9cac770c4a6cbcb6a6997f122172",
      "f7b5e399101846ff960d829bf2c755cc",
      "7fc3ecd03ea148838630b8db60efa6ae",
      "7c8a7ff03e2345338a82afa37c3ac555",
      "a7956a4026f84873bc3abe51e722ad29",
      "c045d8d7f9364616b9ed7a0ba8e3fa4e",
      "eedbcba6558b41129c236a83b27ae5c3",
      "947d2a9055b74d5b87384e7b2cb577f9",
      "e7108f591e8842a49ae5511e9399ec5d",
      "9e6214be8632432f92329c3d54dff024",
      "3dabbf9c470042a581871dce2c967d7d",
      "5ebdfb4a891c4c3faff659470f02e1dd",
      "f263347a6d644a63ac69030c646708c2",
      "2104c5d7d5b144609475047b6daec440",
      "c247e4c7a5f84ba68780408887f73af3",
      "74ac38af99934a218dd76d74e9e6cdd7",
      "7560642955e1432383796072be676982",
      "0bf70fe43b2240a1bee033b9fda143cd",
      "df1a1c1134564433a186bbf33ae62cbb",
      "6f855ac5607c4e5c92018cdbfe3cecc0",
      "a26caa069ddb462a852a785c7f4b0840",
      "89cddcdd40064e51a54196df03736ab1",
      "2a40454bcbfc4a019a000d5bb3a0bfa2",
      "74345e61a11e41a9bc2fb60364465304",
      "278102c12f394849977128345c2a28c0",
      "f50f674fb0294291ba39e6d7ec16b451",
      "72c99cba9a6344e8940dcd856348f274",
      "695976b7669a47e4af758a8d8350cffe",
      "635e1e101da34c91be92e9b515a054f0",
      "4f887930c5e44e2e800575338c04019a",
      "b44b6af2651e4d128f1bf55aeb98738d",
      "242a04ed75cd46e0aae901fdbc53c7b7",
      "a97830409b804e1585503d166bac24ca",
      "da45b09a651f45428eae1161e1fe7999",
      "4eb5761a48124709a0716b44285814d3",
      "1478577662ba4928ba83a9eb8332cfb9",
      "4abf93c146fb4673952105584434e2c6",
      "1fafe93962144217a46c80126d5ad82a",
      "9b65adcfbf2e4c7dba09cbfbd2bcd33c",
      "5e8c446d6e864fb38c74bb52ec16cab5",
      "8e61d852172e412e94c68b7a6b9c6e80",
      "c97220141bac4403bb5e56279ad709c3",
      "0eed21348b4c47c6b192881963c78f73",
      "6579264f45e3424eae1fd143177a6c7c",
      "1ccdfbbe581b4c48a918da52b607621f",
      "37084202f97b4db5ad431d8a77590592",
      "de7df4498eed4320a40221560a37c279",
      "33bc16ce15204387b9b505da1b2ecb31",
      "5e040893efb54cefa3c68dd4329b3137",
      "e14b7a5297054b7a90b4e1b8d550d411",
      "fa0931bf9d114af9a9adbc8802ebd574",
      "4fc2f17bff134d50bb9a539ed291b55b",
      "d0c54e06b63d447b8993ab5fe73550de",
      "b5be6a4c3b1545729e8ceb1283cb9c83",
      "63120f2fdb044a2eb4fdb316a5f0c947",
      "cbe55bbe1afd440ba09aad4f0337fa3b",
      "546e603f30b042f688df0028c216819b",
      "a628a7f24983465fb30ed5f399cd3f29",
      "f9b70791140547b99a7da740cf1c2034",
      "7cfab898694b4fc6ac79f44d5546acd8",
      "7daf6cc7f9bc4738ad12499f51e80b6b",
      "0507395ba6494600b656bcb13b61dceb",
      "bc9bb4d0ab8341138eed54bd1f89d4b1",
      "3fa486345e5c40faad46df7f043f7e8d",
      "29c73398e70a4868b93853984338b469",
      "77338b45c2f74396bb05a0e823b3987f",
      "3845531348a04d12af88a9ef9bf45505",
      "6e7396b0a3084b1782f85475b959249d",
      "ea1fe609106e413c860526a57f64b819",
      "537c17ed8c294889b95efbc4e3632fe2",
      "586a90972fea43d48d8f8a8998b6f7a9",
      "7100651797ce4f02b4b023ad3ba69b95",
      "a2a19740c992423f8d6089b01d2d7175",
      "e243812911094acf86dc2121819c5abb",
      "c1e14520dbdb48508b16067525a9989e",
      "9a36776134814451b54bc179968fa88d",
      "2bc29174cf7f4d5eabadc37875b59da4",
      "0e5b76fbc81446dea4a2ac75666f8729",
      "927959e6b0c943218d33cacb39c7b528",
      "1640cd5d2c4d4b9fbb938aa7177c7e95",
      "6e3413e0b1b6410dbca57678e3879007",
      "8c87c2f1b4c54cb68a43881feaea7f63",
      "1f7dd8be1619484fac63cb508d5ac1cc",
      "bb2ae577e4fb499b91cc0ca424071240",
      "fd184b956cac4641b7a72f653d52777b",
      "ac2fac0d32f24d30ba2713f50331b731",
      "b03d93244d6e47c6a3368278f9edb247",
      "0dbe139b07f0496db28bdcf90b628522",
      "5e3df02e97a54c42bee0f2c47b972ba1",
      "7f06230ee4c04349bd9ca871afd6142d",
      "bf8a1688cd404fc2b49c4b894815c68e",
      "30f594a42b244483971c95a4435d51f8",
      "c0893c3c5d9e463fa1ea0bb51899a50c",
      "1fc2a531107246edb4b22ae329e674ae",
      "197bd615b03644bebb914a3e6a8174dc",
      "d76601d62e2e4d90ba5db28866abe05a",
      "ecc0a0d33cf24f0b986931565df7631a",
      "af3a51df9ae04e45990c980a867fd313",
      "1d854a1940a24361a0cae5507ceb9678",
      "3d039dc1aca5489b87e434fe1c477dde",
      "0caf730847ac432884eebd39ba7574d6",
      "46a35a3e353d4bb2a767ea4528fc0b43",
      "2526534467684a5e9b9ccc7812e9a576",
      "fadb336a0f0d4cf8ba5d48d06c3e0bc9",
      "1a9ec71e0b904a9999962c16a369d41a",
      "a6863f77fe4d4107acd503e7e2b69a9f",
      "c5216dd9d6e54fd39b0bf96f35162520",
      "ef019bb83cc24dda9460c798aaa37272",
      "c98f3226699b42be9f2228c9b6cf4bab",
      "78a16ca307d349e2a3c5329a413445df",
      "3a3f2f85ac694526b48b77b637437339",
      "210c3748f1c54beba0410260b443c812",
      "8bc7b3942f3142459071cf04b9700d48",
      "08422021a53f4add8058ef6be1a74ba4",
      "30c0de69bad740d6a129bb5aa5e09021",
      "113fd116f16e492694a103113632224a",
      "02833e23c0be4b5dadd2934444a0ab34",
      "4c24657ff32c4072a536055c6219aec4",
      "a0267c89d3024f7c804c410ad28f1415",
      "2f18bf8a930d4d538c6924a440cfa128",
      "ff74237547ba41daa5b7abb345f790dc",
      "3e95deda17a34896804ce6a38b065947",
      "edccffdfd0684ff9962451dca5d7a19c",
      "4642c3e1758748ef84169d0e7b80a9d8",
      "6c2557b670044b51b333862e00071dbd",
      "4a76c8449dbb46f986d8c0dbd752082f",
      "fffbbf91eb1b459dbc8d9d00a215b76e",
      "d6992b88d0a04abb9d5aac6d0f0d955c",
      "32631a0460044317be710eec6ec17c5e",
      "e4ddd1306036405e818635540557ca0a",
      "8ea8fec13e304cf083e665ad501297e0",
      "4dc930979e4448038fa799ac9c0f32b5",
      "a05204edd9f24cb08622e46e61770ec4",
      "4e042720ef7645b18adc12bfc94573b7",
      "4f71d320dbac40e68ba2d697e6391937",
      "e091269edbea49c6a4c6fab6fb2c5ebe",
      "f3d8a575583c496ea32e91ad5084c441",
      "55de7cfafaf94f85af11ace74b183c54",
      "007e1ed246164ba3895bdb6e46176040",
      "62bdfee72cc64420aa74e9f78ff127c6",
      "e77b5c96f00a44b0aaf0a590d2abc8fd",
      "9370f75d6f5348e6988bc3e68bab9559",
      "541bbbde8ddd4d79917d965f8cc596bd",
      "939fc2fea7324833a1bff56c19655119",
      "f4ebe1bb92f64975bb18a2a5df338b92",
      "367b28e7499f4487994d132811544016",
      "baf620855d5c4165b5453d99e01f4406",
      "0a857b095ee64478b408a1f31e6feafc",
      "f80251552fa24112be683012ce6e3b86",
      "fd47e4a6863741a2b1e8f6848c41b2fb",
      "1e96dd130c3d4fd0b2af94fb9bc9ab1e",
      "dba318405fdc4ede84f4a67c902d4133",
      "09bca34ef164466bb07e8c3b7b25ce22",
      "c05f175f1fa04527a990f3c4b2a46b96",
      "eec394f69d074fc3821e265efc0c3591",
      "2ae2fd6da5734baa96080ea90d18bd25",
      "61309e0b10cb4ed692213ad171b08108",
      "c6918e297ef34efcac32b240cffecbba",
      "dee35b7bebd84430b4e1c0a0764dc4b8",
      "525d24d99c3c4447843b67cca0d34c4b",
      "d6cc4502391c4556bfb2804494a19996",
      "e430cbf1c9dc4cd8b9100f97ff4bfbb4",
      "73b389c06cf34fd690e3e6946e28c584",
      "7d0894f3b383486498606f37002af709",
      "8470e65ae6c1419dae1ef7e350ca7a79",
      "978d3dd3694844d7b163adf9cd6e9efc",
      "98069d6cf3b04488af564edc7132f904",
      "6142817c24d64c09aaefc51830d81ce8",
      "fbd2be1223c746b08c06b8da4f3643fb",
      "3ee8d0564ec8472283bfe8f1b91cc525",
      "fb20a880e3394f92ba079a19618e6bdd",
      "9e182c96d3054939a92ae926169fd7e9",
      "a0e4f149c5d74915a35f29f7f6d53546",
      "8e702687cb9249208f60707dced96d71",
      "957c397cfff34813a7545d7ab3ff2bc8",
      "4c3c124cf67e4140bf5a3b8a48279bf4",
      "d116473893194ce88227c2668671e1be"
     ]
    },
    "id": "goZ3Z7A8nbpn",
    "outputId": "3d2bcfd7-d4f2-467f-91b2-0c0a076cc53c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=sweep_train, count = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ws in [1]:\n",
    "  print(\"\\n\\nfor ws = {}\".format(ws))\n",
    "  grouped_df1 = train_df.groupby(['day'], sort = False, as_index = False)\n",
    "  iter_list_train = [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day)[120:].drop(['Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor']], label_columns=['GHI']).train for day in train_df['day'][:len(train_df['day'])//2].unique() ]\\\n",
    "  + [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day)[160:-160].drop(['Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor']], label_columns=['GHI']).train for day in train_df['day'][len(train_df['day'])//2:].unique() ]\n",
    "\n",
    "  # train_generator = itertools.chain.from_iterable( iter_list )\n",
    "\n",
    "  grouped_df1 = val_df.groupby(['day'], sort = False, as_index = False)\n",
    "  iter_list_val = [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day)[120:].drop(['Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor']], label_columns=['GHI']).train for day in val_df['day'][:len(val_df['day'])//2].unique() ]+ [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day)[160:-160].drop(['Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor']], label_columns=['GHI']).train for day in val_df['day'][len(val_df['day'])//2:].unique() ]\n",
    "\n",
    "  # val_generator = itertools.chain.from_iterable( iter_list )\n",
    "\n",
    "  grouped_df1 = test_df.groupby(['day'], sort = False, as_index = False)\n",
    "  iter_list_test = [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day)[120:].drop(['Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor']], label_columns=['GHI']).train for day in test_df['day'][:len(test_df['day'])//2].unique() ]+ [ WindowGenerator(input_width=ws, label_width = 12, shift=10, label_shift = 10,train_df = grouped_df1.get_group(day)[160:-160].drop(['Wet Temp','Time'] , axis = 1)[['GHI','Azimuth Angle','TCC','Clear Sky GHI','distance factor']], label_columns=['GHI']).train for day in test_df['day'][len(test_df['day'])//2:].unique() ]\n",
    "\n",
    "  # test_generator = itertools.chain.from_iterable( iter_list )\n",
    "\n",
    "  train_batches = 0\n",
    "  for x in iter_list_train:\n",
    "    train_batches = train_batches + len(x)\n",
    "  print(train_batches)\n",
    "  val_batches = 0\n",
    "  for x in iter_list_val:\n",
    "    val_batches = val_batches + len(x)\n",
    "  print(val_batches)\n",
    "\n",
    "  test_batches = 0\n",
    "  for x in iter_list_test:\n",
    "    test_batches = test_batches + len(x)\n",
    "  print(test_batches)\n",
    "\n",
    "  train_gen = chain(iter_list_train)\n",
    "  val_gen = chain(iter_list_val)\n",
    "  test_gen = chain(iter_list_test)\n",
    "    \n",
    "  # MLP Model\n",
    "  model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(inpuyt),\n",
    "tf.keras.layers.Dense(units = 256, activation='leaky_relu'),\n",
    "tf.keras.layers.Dense(units = 32, activation='leaky_relu'),\n",
    "tf.keras.layers.Dense(units=12),\n",
    "])\n",
    "\n",
    "\n",
    "  callbacks = [\n",
    "      EarlyStopping(monitor='val_loss', patience=3,  mode='min',verbose=1),\n",
    "      ReduceLROnPlateau(factor=0.15, patience=2, min_lr=1e-9, verbose=1),\n",
    "      ModelCheckpoint('MLP_{}_gaussian.h5'.format(ws), verbose=1, save_best_only=True, save_weights_only=True) ]\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.Huber(),\n",
    "                optimizer=tf.optimizers.SGD(learning_rate=1e-3, momentum = 0.9),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(train_gen, steps_per_epoch = train_batches, epochs=25, validation_data = val_gen, validation_steps = val_batches, callbacks=callbacks)\n",
    "  model.evaluate(test_gen, steps = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 03:38:56.169322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14659 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n",
      "179\n",
      "258\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 03:39:38.882856: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 466/1010 [============>.................] - ETA: 15s - loss: 0.5605 - mean_absolute_error: 0.9579"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60898/3566312968.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 metrics=[tf.metrics.MeanAbsoluteError()])\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sr = 10\n",
    "for ws in [12]:\n",
    "    grouped_df1 = train_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_train = [ WindowGenerator(input_width=ws, label_width = 12, shift=10//sr, label_shift = 10//sr,train_df = grouped_df1.get_group(day)[::sr][l[2]],label_columns=['GHI']).train for day in train_df['day'].unique() ]\n",
    "\n",
    "    grouped_df1 = val_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_val = [ WindowGenerator(input_width=ws, label_width = 12, shift=10//sr, label_shift = 10//sr,train_df = grouped_df1.get_group(day)[::sr][l[2]],label_columns=['GHI']).train for day in val_df['day'].unique() ]\n",
    "\n",
    "    grouped_df1 = test_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_test = [ WindowGenerator(input_width=ws, label_width = 12, shift=10//sr, label_shift = 10//sr,train_df = grouped_df1.get_group(day)[::sr][l[2]],label_columns=['GHI']).train for day in test_df['day'].unique() ]\n",
    "    # test_generator = itertools.chain.from_iterable( iter_list )\n",
    "\n",
    "    train_batches = 0\n",
    "    for x in iter_list_train:\n",
    "        train_batches = train_batches + len(x)\n",
    "    print(train_batches)\n",
    "    val_batches = 0\n",
    "    for x in iter_list_val:\n",
    "        val_batches = val_batches + len(x)\n",
    "    print(val_batches)\n",
    "\n",
    "    test_batches = 0\n",
    "    for x in iter_list_test:\n",
    "        test_batches = test_batches + len(x)\n",
    "    print(test_batches)\n",
    "\n",
    "    train_gen = chain(iter_list_train)\n",
    "    val_gen = chain(iter_list_val)\n",
    "    test_gen = chain(iter_list_test)\n",
    "    print('78')\n",
    "    # MLP Model\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 64, activation='leaky_relu'),\n",
    "    tf.keras.layers.Dense(units = 64, activation='leaky_relu'),\n",
    "    tf.keras.layers.Dense(units=12),\n",
    "    ])\n",
    "\n",
    "\n",
    "    callbacks = [\n",
    "      EarlyStopping(monitor='val_loss', patience=3,  mode='min',verbose=1),\n",
    "      ReduceLROnPlateau(factor=0.15, patience=2, min_lr=1e-9, verbose=1),\n",
    "      ModelCheckpoint('MLP_{}_gaussian.h5'.format(ws), verbose=1, save_best_only=True, save_weights_only=True) ]\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.Huber(),\n",
    "                optimizer=tf.optimizers.SGD(learning_rate=1e-4, momentum = 0.9),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(train_gen, steps_per_epoch = train_batches, epochs=25, validation_data = val_gen, validation_steps = val_batches, callbacks=callbacks)\n",
    "    model.evaluate(test_gen, steps = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " # MLP Model\n",
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape = (12,len(l[2]))),\n",
    "tf.keras.layers.Dense(units = 256, activation='leaky_relu'),\n",
    "tf.keras.layers.Dense(units = 32, activation='leaky_relu'),\n",
    "tf.keras.layers.Dense(units=12),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "                optimizer=tf.optimizers.SGD(learning_rate=1e-2, momentum = 0.9),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "d8ysd9aTS9Bd"
   },
   "outputs": [],
   "source": [
    "def get_test_predictions(model, ws,features_list,sr) :\n",
    "\n",
    "  X = np.zeros((300,ws,len(features_list)))\n",
    "  for i in range(300):  \n",
    "    X[i] = np.array(full_test_dfs[i][(len(full_test_dfs[i])-1)%sr::sr][-ws:][features_list])\n",
    "  output = model.predict(X)\n",
    "  output = output.reshape(300,12)\n",
    "  output = pd.DataFrame(output)\n",
    "#     print(output)\n",
    "  output = output*train_std.loc['GHI'] + train_mean.loc['GHI']\n",
    "  for i in range(300):\n",
    "    for j in range(4):\n",
    "      if(output.iloc[i][j] < -1):\n",
    "          output.iloc[i][j] = -0.8\n",
    "  create_submission(pd.DataFrame(np.array(output)),'predictions_ws_{}sr_{}cols_{}.csv'.format(ws,sr,len(features_list)))\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vi_b2d36YsVO",
    "outputId": "59245de0-c5bc-4d02-d6f7-2867bca4bb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/258 [==============================] - 8s 30ms/step - loss: 0.1358 - mean_absolute_error: 0.3468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13581611216068268, 0.3468441963195801]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.built = True\n",
    "model.load_weights('MLP_l:0.01_sr:10_ws:12_u1:256_u2:32_cols:2.h5')\n",
    "model.evaluate(test_gen, steps = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>571.692444</td>\n",
       "      <td>520.023804</td>\n",
       "      <td>477.577942</td>\n",
       "      <td>452.150085</td>\n",
       "      <td>409.350067</td>\n",
       "      <td>360.658722</td>\n",
       "      <td>331.591980</td>\n",
       "      <td>278.519073</td>\n",
       "      <td>277.890045</td>\n",
       "      <td>234.580368</td>\n",
       "      <td>183.274048</td>\n",
       "      <td>151.801605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>855.064758</td>\n",
       "      <td>850.486694</td>\n",
       "      <td>828.505066</td>\n",
       "      <td>840.300049</td>\n",
       "      <td>829.398987</td>\n",
       "      <td>816.367065</td>\n",
       "      <td>811.759888</td>\n",
       "      <td>782.214111</td>\n",
       "      <td>778.978943</td>\n",
       "      <td>770.515381</td>\n",
       "      <td>754.991211</td>\n",
       "      <td>745.570557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>344.270416</td>\n",
       "      <td>345.577087</td>\n",
       "      <td>326.850067</td>\n",
       "      <td>289.011139</td>\n",
       "      <td>270.104736</td>\n",
       "      <td>242.541077</td>\n",
       "      <td>240.598557</td>\n",
       "      <td>188.276581</td>\n",
       "      <td>173.957077</td>\n",
       "      <td>129.404510</td>\n",
       "      <td>145.929367</td>\n",
       "      <td>117.757812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569.413940</td>\n",
       "      <td>595.022705</td>\n",
       "      <td>624.385498</td>\n",
       "      <td>651.002930</td>\n",
       "      <td>664.455383</td>\n",
       "      <td>665.351379</td>\n",
       "      <td>663.403748</td>\n",
       "      <td>693.417358</td>\n",
       "      <td>712.448730</td>\n",
       "      <td>688.651550</td>\n",
       "      <td>713.611816</td>\n",
       "      <td>722.461304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>902.727783</td>\n",
       "      <td>882.399048</td>\n",
       "      <td>879.116394</td>\n",
       "      <td>859.115601</td>\n",
       "      <td>838.110107</td>\n",
       "      <td>837.037048</td>\n",
       "      <td>820.426270</td>\n",
       "      <td>800.034607</td>\n",
       "      <td>786.966431</td>\n",
       "      <td>778.664551</td>\n",
       "      <td>754.102722</td>\n",
       "      <td>734.170532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>876.701294</td>\n",
       "      <td>846.436401</td>\n",
       "      <td>828.460388</td>\n",
       "      <td>800.426514</td>\n",
       "      <td>797.417725</td>\n",
       "      <td>770.144104</td>\n",
       "      <td>734.473511</td>\n",
       "      <td>705.780212</td>\n",
       "      <td>714.031372</td>\n",
       "      <td>681.304077</td>\n",
       "      <td>655.753662</td>\n",
       "      <td>629.704224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>414.071472</td>\n",
       "      <td>450.689453</td>\n",
       "      <td>459.699829</td>\n",
       "      <td>491.601807</td>\n",
       "      <td>537.084351</td>\n",
       "      <td>525.165344</td>\n",
       "      <td>544.124512</td>\n",
       "      <td>557.633545</td>\n",
       "      <td>586.152710</td>\n",
       "      <td>606.387390</td>\n",
       "      <td>618.006714</td>\n",
       "      <td>618.921143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>673.488708</td>\n",
       "      <td>701.377747</td>\n",
       "      <td>731.072632</td>\n",
       "      <td>753.507019</td>\n",
       "      <td>762.875732</td>\n",
       "      <td>798.588989</td>\n",
       "      <td>802.470459</td>\n",
       "      <td>813.457886</td>\n",
       "      <td>833.104492</td>\n",
       "      <td>843.461304</td>\n",
       "      <td>846.483887</td>\n",
       "      <td>843.396729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>144.397064</td>\n",
       "      <td>170.748764</td>\n",
       "      <td>190.533142</td>\n",
       "      <td>180.715408</td>\n",
       "      <td>207.322464</td>\n",
       "      <td>196.496689</td>\n",
       "      <td>191.178589</td>\n",
       "      <td>190.939240</td>\n",
       "      <td>204.191940</td>\n",
       "      <td>214.645645</td>\n",
       "      <td>188.278702</td>\n",
       "      <td>187.434662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>647.443604</td>\n",
       "      <td>679.927368</td>\n",
       "      <td>688.330566</td>\n",
       "      <td>730.209900</td>\n",
       "      <td>759.177002</td>\n",
       "      <td>755.136230</td>\n",
       "      <td>776.366211</td>\n",
       "      <td>770.843262</td>\n",
       "      <td>798.907471</td>\n",
       "      <td>789.088989</td>\n",
       "      <td>806.502808</td>\n",
       "      <td>817.522888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1           2           3           4           5   \\\n",
       "0    571.692444  520.023804  477.577942  452.150085  409.350067  360.658722   \n",
       "1    855.064758  850.486694  828.505066  840.300049  829.398987  816.367065   \n",
       "2    344.270416  345.577087  326.850067  289.011139  270.104736  242.541077   \n",
       "3    569.413940  595.022705  624.385498  651.002930  664.455383  665.351379   \n",
       "4    902.727783  882.399048  879.116394  859.115601  838.110107  837.037048   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "295  876.701294  846.436401  828.460388  800.426514  797.417725  770.144104   \n",
       "296  414.071472  450.689453  459.699829  491.601807  537.084351  525.165344   \n",
       "297  673.488708  701.377747  731.072632  753.507019  762.875732  798.588989   \n",
       "298  144.397064  170.748764  190.533142  180.715408  207.322464  196.496689   \n",
       "299  647.443604  679.927368  688.330566  730.209900  759.177002  755.136230   \n",
       "\n",
       "             6           7           8           9           10          11  \n",
       "0    331.591980  278.519073  277.890045  234.580368  183.274048  151.801605  \n",
       "1    811.759888  782.214111  778.978943  770.515381  754.991211  745.570557  \n",
       "2    240.598557  188.276581  173.957077  129.404510  145.929367  117.757812  \n",
       "3    663.403748  693.417358  712.448730  688.651550  713.611816  722.461304  \n",
       "4    820.426270  800.034607  786.966431  778.664551  754.102722  734.170532  \n",
       "..          ...         ...         ...         ...         ...         ...  \n",
       "295  734.473511  705.780212  714.031372  681.304077  655.753662  629.704224  \n",
       "296  544.124512  557.633545  586.152710  606.387390  618.006714  618.921143  \n",
       "297  802.470459  813.457886  833.104492  843.461304  846.483887  843.396729  \n",
       "298  191.178589  190.939240  204.191940  214.645645  188.278702  187.434662  \n",
       "299  776.366211  770.843262  798.907471  789.088989  806.502808  817.522888  \n",
       "\n",
       "[300 rows x 12 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_predictions(model,12,l[2],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8,8)\n",
    "day = 100\n",
    "grouped_imputed_df = imputed_df.groupby(['day'], sort = False, as_index = False)\n",
    "def plot(i):\n",
    "    pd.Series(x.iloc[i].values , index=range(len(full_test_dfs[i])+10,len(full_test_dfs[i])+121,10)).plot()\n",
    "    (grouped_imputed_df.get_group(test_days_list[i])['GHI'].reset_index(drop = True)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(filters,kernel_size,ws,i,units_1):\n",
    "\n",
    "    model =   tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=filters,kernel_size=kernel_size,activation='relu'\n",
    "                               ,input_shape=(ws,len(l[i]))),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=units_1, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(units=12),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, activation= ' relu ' ,\n",
    "# input_shape=(n_timesteps,n_features)))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, activation= ' relu ' ))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Conv1D(filters=16, kernel_size=3, activation= ' relu ' ))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100, activation= ' relu ' ))\n",
    "# model.add(Dense(n_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "TI_JI2HBZs10"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  'method': 'random', \n",
    "  'metric': {\n",
    "      'name': 'val_loss',\n",
    "      'goal': 'minimize'\n",
    "  },\n",
    "\n",
    "  'parameters': {\n",
    "      'learning_rate':{\n",
    "          'values': [0.01,0.001,0.0001]\n",
    "      },\n",
    "      'sr_nd_ws':{\n",
    "          'values': [[10,12],[10,6],[10,4]]\n",
    "      },\n",
    "      'filters':{\n",
    "          'values': [8,16,32,64]\n",
    "      },\n",
    "      'kernel_size':{\n",
    "          'values': [2,3,3,3,4,5,6]\n",
    "      },\n",
    "      'cols_list':{\n",
    "          'values': [0,1,2,3,4]\n",
    "      },\n",
    "      'units':{\n",
    "          'values': [1,4,8,16,32]\n",
    "      },\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "98pkZByxC4Pl"
   },
   "outputs": [],
   "source": [
    "def sweep_train():\n",
    "    # Specify the hyperparameter to be tuned along with\n",
    "    # an initial value\n",
    "    config_defaults = {\n",
    "        'learning_rate': 0.001,\n",
    "        'sr nd ws': [10,3],\n",
    "      'filters':128,\n",
    "      'kernel_size': 64,\n",
    "      'cols_list': [0],\n",
    "        'units': 8\n",
    "    }\n",
    "\n",
    "    # Initialize wandb with a sample project name\n",
    "    wandb.init(config=config_defaults)  # this gets over-written in the Sweep\n",
    "    cfg = wandb.config\n",
    "    # Specify the other hyperparameters to the configuration, if any\n",
    "    cfg.epochs = 55\n",
    "    cfg.architecture_name = \"CNN\"\n",
    "\n",
    "    grouped_df1 = train_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_train = [ WindowGenerator(input_width=cfg.sr_nd_ws[1], label_width = 12, shift=10//cfg.sr_nd_ws[0], label_shift = 10//cfg.sr_nd_ws[0],train_df = grouped_df1.get_group(day)[::cfg.sr_nd_ws[0]][l[cfg.cols_list]],label_columns=['GHI']).train for day in train_df['day'].unique() ]\n",
    "\n",
    "    grouped_df1 = val_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_val = [ WindowGenerator(input_width=cfg.sr_nd_ws[1], label_width = 12, shift=10//cfg.sr_nd_ws[0], label_shift = 10//cfg.sr_nd_ws[0],train_df = grouped_df1.get_group(day)[::cfg.sr_nd_ws[0]][l[cfg.cols_list]],label_columns=['GHI']).train for day in val_df['day'].unique() ]\n",
    "\n",
    "    grouped_df1 = test_df.groupby(['day'], sort = False, as_index = False)\n",
    "    iter_list_test = [ WindowGenerator(input_width=cfg.sr_nd_ws[1], label_width = 12, shift=10//cfg.sr_nd_ws[0], label_shift = 10//cfg.sr_nd_ws[0],train_df = grouped_df1.get_group(day)[::cfg.sr_nd_ws[0]][l[cfg.cols_list]],label_columns=['GHI']).train for day in test_df['day'].unique() ]\n",
    "\n",
    "    train_batches = 0\n",
    "    for x in iter_list_train:\n",
    "      train_batches = train_batches + len(x)\n",
    "    print(train_batches)\n",
    "    val_batches = 0\n",
    "    for x in iter_list_val:\n",
    "      val_batches = val_batches + len(x)\n",
    "    print(val_batches)\n",
    "\n",
    "    test_batches = 0\n",
    "    for x in iter_list_test:\n",
    "      test_batches = test_batches + len(x)\n",
    "    print(test_batches)\n",
    "\n",
    "    train_gen = chain(iter_list_train)\n",
    "    val_gen = chain(iter_list_val)\n",
    "    test_gen = chain(iter_list_test)\n",
    "\n",
    "    # initialize model\n",
    "    model = Model(cfg.filters, cfg.kernel_size, cfg.sr_nd_ws[1],cfg.cols_list,cfg.units)\n",
    "    \n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate = cfg.learning_rate),loss=tf.keras.losses.MeanAbsoluteError())\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience = 5,  mode='min'),\n",
    "        ReduceLROnPlateau(factor=0.5, patience = 3, verbose=1),\n",
    "        ModelCheckpoint('MLP_l:{}_sr:{}_ws:{}_u1:{}_u2:{}_cols:{}units:{}.h5'.format(cfg.learning_rate, cfg.sr_nd_ws[0],cfg.sr_nd_ws[1], cfg.filters, cfg.kernel_size, cfg.cols_list,cfg.units), verbose=1, save_best_only=True, save_weights_only=True) ]\n",
    "\n",
    "  \n",
    "    # train and validate\n",
    "    history = model.fit(train_gen, steps_per_epoch = train_batches, epochs=cfg.epochs, validation_data = val_gen, validation_steps = val_batches,callbacks = [WandbCallback(),callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWpCLwGqncdF",
    "outputId": "8a122696-2731-4bd9-e23c-38d56a3b2c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 9a0mx58u\n",
      "Sweep URL: https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"shell_hack-level-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "86e2cdab31b647d290a584f6918a83c4",
      "e3061569043f490495d74e393abdb9f8",
      "e74267d2d1f54f49b32e19a3cf808c75",
      "5db2fc6dcbac4dddbf1b2b1ba6a6bd6c",
      "794f1a24b1a54420822d889703eb0c19",
      "e6b4e84658924f7ba25bb022bb368518",
      "f50a779f9ff041dfbcd9115ea0f6e642",
      "0f0e9cac770c4a6cbcb6a6997f122172",
      "f7b5e399101846ff960d829bf2c755cc",
      "7fc3ecd03ea148838630b8db60efa6ae",
      "7c8a7ff03e2345338a82afa37c3ac555",
      "a7956a4026f84873bc3abe51e722ad29",
      "c045d8d7f9364616b9ed7a0ba8e3fa4e",
      "eedbcba6558b41129c236a83b27ae5c3",
      "947d2a9055b74d5b87384e7b2cb577f9",
      "e7108f591e8842a49ae5511e9399ec5d",
      "9e6214be8632432f92329c3d54dff024",
      "3dabbf9c470042a581871dce2c967d7d",
      "5ebdfb4a891c4c3faff659470f02e1dd",
      "f263347a6d644a63ac69030c646708c2",
      "2104c5d7d5b144609475047b6daec440",
      "c247e4c7a5f84ba68780408887f73af3",
      "74ac38af99934a218dd76d74e9e6cdd7",
      "7560642955e1432383796072be676982",
      "0bf70fe43b2240a1bee033b9fda143cd",
      "df1a1c1134564433a186bbf33ae62cbb",
      "6f855ac5607c4e5c92018cdbfe3cecc0",
      "a26caa069ddb462a852a785c7f4b0840",
      "89cddcdd40064e51a54196df03736ab1",
      "2a40454bcbfc4a019a000d5bb3a0bfa2",
      "74345e61a11e41a9bc2fb60364465304",
      "278102c12f394849977128345c2a28c0",
      "f50f674fb0294291ba39e6d7ec16b451",
      "72c99cba9a6344e8940dcd856348f274",
      "695976b7669a47e4af758a8d8350cffe",
      "635e1e101da34c91be92e9b515a054f0",
      "4f887930c5e44e2e800575338c04019a",
      "b44b6af2651e4d128f1bf55aeb98738d",
      "242a04ed75cd46e0aae901fdbc53c7b7",
      "a97830409b804e1585503d166bac24ca",
      "da45b09a651f45428eae1161e1fe7999",
      "4eb5761a48124709a0716b44285814d3",
      "1478577662ba4928ba83a9eb8332cfb9",
      "4abf93c146fb4673952105584434e2c6",
      "1fafe93962144217a46c80126d5ad82a",
      "9b65adcfbf2e4c7dba09cbfbd2bcd33c",
      "5e8c446d6e864fb38c74bb52ec16cab5",
      "8e61d852172e412e94c68b7a6b9c6e80",
      "c97220141bac4403bb5e56279ad709c3",
      "0eed21348b4c47c6b192881963c78f73",
      "6579264f45e3424eae1fd143177a6c7c",
      "1ccdfbbe581b4c48a918da52b607621f",
      "37084202f97b4db5ad431d8a77590592",
      "de7df4498eed4320a40221560a37c279",
      "33bc16ce15204387b9b505da1b2ecb31",
      "5e040893efb54cefa3c68dd4329b3137",
      "e14b7a5297054b7a90b4e1b8d550d411",
      "fa0931bf9d114af9a9adbc8802ebd574",
      "4fc2f17bff134d50bb9a539ed291b55b",
      "d0c54e06b63d447b8993ab5fe73550de",
      "b5be6a4c3b1545729e8ceb1283cb9c83",
      "63120f2fdb044a2eb4fdb316a5f0c947",
      "cbe55bbe1afd440ba09aad4f0337fa3b",
      "546e603f30b042f688df0028c216819b",
      "a628a7f24983465fb30ed5f399cd3f29",
      "f9b70791140547b99a7da740cf1c2034",
      "7cfab898694b4fc6ac79f44d5546acd8",
      "7daf6cc7f9bc4738ad12499f51e80b6b",
      "0507395ba6494600b656bcb13b61dceb",
      "bc9bb4d0ab8341138eed54bd1f89d4b1",
      "3fa486345e5c40faad46df7f043f7e8d",
      "29c73398e70a4868b93853984338b469",
      "77338b45c2f74396bb05a0e823b3987f",
      "3845531348a04d12af88a9ef9bf45505",
      "6e7396b0a3084b1782f85475b959249d",
      "ea1fe609106e413c860526a57f64b819",
      "537c17ed8c294889b95efbc4e3632fe2",
      "586a90972fea43d48d8f8a8998b6f7a9",
      "7100651797ce4f02b4b023ad3ba69b95",
      "a2a19740c992423f8d6089b01d2d7175",
      "e243812911094acf86dc2121819c5abb",
      "c1e14520dbdb48508b16067525a9989e",
      "9a36776134814451b54bc179968fa88d",
      "2bc29174cf7f4d5eabadc37875b59da4",
      "0e5b76fbc81446dea4a2ac75666f8729",
      "927959e6b0c943218d33cacb39c7b528",
      "1640cd5d2c4d4b9fbb938aa7177c7e95",
      "6e3413e0b1b6410dbca57678e3879007",
      "8c87c2f1b4c54cb68a43881feaea7f63",
      "1f7dd8be1619484fac63cb508d5ac1cc",
      "bb2ae577e4fb499b91cc0ca424071240",
      "fd184b956cac4641b7a72f653d52777b",
      "ac2fac0d32f24d30ba2713f50331b731",
      "b03d93244d6e47c6a3368278f9edb247",
      "0dbe139b07f0496db28bdcf90b628522",
      "5e3df02e97a54c42bee0f2c47b972ba1",
      "7f06230ee4c04349bd9ca871afd6142d",
      "bf8a1688cd404fc2b49c4b894815c68e",
      "30f594a42b244483971c95a4435d51f8",
      "c0893c3c5d9e463fa1ea0bb51899a50c",
      "1fc2a531107246edb4b22ae329e674ae",
      "197bd615b03644bebb914a3e6a8174dc",
      "d76601d62e2e4d90ba5db28866abe05a",
      "ecc0a0d33cf24f0b986931565df7631a",
      "af3a51df9ae04e45990c980a867fd313",
      "1d854a1940a24361a0cae5507ceb9678",
      "3d039dc1aca5489b87e434fe1c477dde",
      "0caf730847ac432884eebd39ba7574d6",
      "46a35a3e353d4bb2a767ea4528fc0b43",
      "2526534467684a5e9b9ccc7812e9a576",
      "fadb336a0f0d4cf8ba5d48d06c3e0bc9",
      "1a9ec71e0b904a9999962c16a369d41a",
      "a6863f77fe4d4107acd503e7e2b69a9f",
      "c5216dd9d6e54fd39b0bf96f35162520",
      "ef019bb83cc24dda9460c798aaa37272",
      "c98f3226699b42be9f2228c9b6cf4bab",
      "78a16ca307d349e2a3c5329a413445df",
      "3a3f2f85ac694526b48b77b637437339",
      "210c3748f1c54beba0410260b443c812",
      "8bc7b3942f3142459071cf04b9700d48",
      "08422021a53f4add8058ef6be1a74ba4",
      "30c0de69bad740d6a129bb5aa5e09021",
      "113fd116f16e492694a103113632224a",
      "02833e23c0be4b5dadd2934444a0ab34",
      "4c24657ff32c4072a536055c6219aec4",
      "a0267c89d3024f7c804c410ad28f1415",
      "2f18bf8a930d4d538c6924a440cfa128",
      "ff74237547ba41daa5b7abb345f790dc",
      "3e95deda17a34896804ce6a38b065947",
      "edccffdfd0684ff9962451dca5d7a19c",
      "4642c3e1758748ef84169d0e7b80a9d8",
      "6c2557b670044b51b333862e00071dbd",
      "4a76c8449dbb46f986d8c0dbd752082f",
      "fffbbf91eb1b459dbc8d9d00a215b76e",
      "d6992b88d0a04abb9d5aac6d0f0d955c",
      "32631a0460044317be710eec6ec17c5e",
      "e4ddd1306036405e818635540557ca0a",
      "8ea8fec13e304cf083e665ad501297e0",
      "4dc930979e4448038fa799ac9c0f32b5",
      "a05204edd9f24cb08622e46e61770ec4",
      "4e042720ef7645b18adc12bfc94573b7",
      "4f71d320dbac40e68ba2d697e6391937",
      "e091269edbea49c6a4c6fab6fb2c5ebe",
      "f3d8a575583c496ea32e91ad5084c441",
      "55de7cfafaf94f85af11ace74b183c54",
      "007e1ed246164ba3895bdb6e46176040",
      "62bdfee72cc64420aa74e9f78ff127c6",
      "e77b5c96f00a44b0aaf0a590d2abc8fd",
      "9370f75d6f5348e6988bc3e68bab9559",
      "541bbbde8ddd4d79917d965f8cc596bd",
      "939fc2fea7324833a1bff56c19655119",
      "f4ebe1bb92f64975bb18a2a5df338b92",
      "367b28e7499f4487994d132811544016",
      "baf620855d5c4165b5453d99e01f4406",
      "0a857b095ee64478b408a1f31e6feafc",
      "f80251552fa24112be683012ce6e3b86",
      "fd47e4a6863741a2b1e8f6848c41b2fb",
      "1e96dd130c3d4fd0b2af94fb9bc9ab1e",
      "dba318405fdc4ede84f4a67c902d4133",
      "09bca34ef164466bb07e8c3b7b25ce22",
      "c05f175f1fa04527a990f3c4b2a46b96",
      "eec394f69d074fc3821e265efc0c3591",
      "2ae2fd6da5734baa96080ea90d18bd25",
      "61309e0b10cb4ed692213ad171b08108",
      "c6918e297ef34efcac32b240cffecbba",
      "dee35b7bebd84430b4e1c0a0764dc4b8",
      "525d24d99c3c4447843b67cca0d34c4b",
      "d6cc4502391c4556bfb2804494a19996",
      "e430cbf1c9dc4cd8b9100f97ff4bfbb4",
      "73b389c06cf34fd690e3e6946e28c584",
      "7d0894f3b383486498606f37002af709",
      "8470e65ae6c1419dae1ef7e350ca7a79",
      "978d3dd3694844d7b163adf9cd6e9efc",
      "98069d6cf3b04488af564edc7132f904",
      "6142817c24d64c09aaefc51830d81ce8",
      "fbd2be1223c746b08c06b8da4f3643fb",
      "3ee8d0564ec8472283bfe8f1b91cc525",
      "fb20a880e3394f92ba079a19618e6bdd",
      "9e182c96d3054939a92ae926169fd7e9",
      "a0e4f149c5d74915a35f29f7f6d53546",
      "8e702687cb9249208f60707dced96d71",
      "957c397cfff34813a7545d7ab3ff2bc8",
      "4c3c124cf67e4140bf5a3b8a48279bf4",
      "d116473893194ce88227c2668671e1be"
     ]
    },
    "id": "goZ3Z7A8nbpn",
    "outputId": "3d2bcfd7-d4f2-467f-91b2-0c0a076cc53c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2yeyl4vh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2yeyl4vh\" target=\"_blank\">glowing-sweep-1</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35195... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glowing-sweep-1</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2yeyl4vh\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/2yeyl4vh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_111319-2yeyl4vh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2yeyl4vh errored: ValueError('Negative dimension size caused by subtracting 5 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,18], [1,5,18,8].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bgw67jai with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/bgw67jai\" target=\"_blank\">olive-sweep-2</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 8)              344       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,028\n",
      "Trainable params: 1,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5594 - val_loss: 0.5605\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56047, saving model to MLP_l:0.01_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5397 - val_loss: 0.5273\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56047 to 0.52734, saving model to MLP_l:0.01_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5341 - val_loss: 0.5660\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.52734\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5421 - val_loss: 0.5731\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.52734\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5379 - val_loss: 0.5607\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52734\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5227 - val_loss: 0.5463\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52734\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5204 - val_loss: 0.5641\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.52734\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35275... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>loss</td><td>█▄▃▅▄▁▁</td></tr><tr><td>val_loss</td><td>▆▁▇█▆▄▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.52734</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>0.5204</td></tr><tr><td>val_loss</td><td>0.56407</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">olive-sweep-2</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/bgw67jai\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/bgw67jai</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_111415-bgw67jai/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2nii5xla with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2nii5xla\" target=\"_blank\">colorful-sweep-3</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 64)             3520      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 3,609\n",
      "Trainable params: 3,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8112 - val_loss: 0.8160\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81598, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:0units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8105 - val_loss: 0.8142\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81598 to 0.81419, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:0units:1.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8105 - val_loss: 0.8084\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81419 to 0.80841, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:0units:1.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.8106 - val_loss: 0.8074\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.80841 to 0.80745, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:0units:1.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8100 - val_loss: 0.8182\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.80745\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.8108 - val_loss: 0.8059\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.80745 to 0.80592, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:0units:1.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8103 - val_loss: 0.8164\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80592\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8100 - val_loss: 0.8056\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.80592 to 0.80562, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:0units:1.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.8095 - val_loss: 0.8180\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80562\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8101 - val_loss: 0.8055\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.80562 to 0.80554, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:0units:1.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.8104 - val_loss: 0.8172\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80554\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.8090 - val_loss: 0.8057\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80554\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8090 - val_loss: 0.8123\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80554\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8091 - val_loss: 0.8108\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80554\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8089 - val_loss: 0.8129\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80554\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13368... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.08MB of 0.08MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>█▆▆▆▄▇▅▄▃▅▆▁▂▂▁</td></tr><tr><td>val_loss</td><td>▇▆▃▂█▁▇▁█▁▇▁▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.80554</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>loss</td><td>0.80885</td></tr><tr><td>val_loss</td><td>0.81294</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">colorful-sweep-3</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2nii5xla\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/2nii5xla</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_111932-2nii5xla/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rykprfds with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/rykprfds\" target=\"_blank\">summer-sweep-4</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 16)             688       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 2,140\n",
      "Trainable params: 2,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5618 - val_loss: 0.6556\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65558, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.5301 - val_loss: 0.4866\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65558 to 0.48665, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5268 - val_loss: 0.4913\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.48665\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5393 - val_loss: 0.5022\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.48665\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5420 - val_loss: 0.4708\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48665 to 0.47082, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5387 - val_loss: 0.4722\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47082\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5363 - val_loss: 0.5039\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47082\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5339 - val_loss: 0.4575\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47082 to 0.45747, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5297 - val_loss: 0.5048\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45747\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5335 - val_loss: 0.4801\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45747\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5333 - val_loss: 0.4711\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45747\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5075 - val_loss: 0.4389\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.45747 to 0.43892, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5003 - val_loss: 0.4363\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43892 to 0.43626, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4914 - val_loss: 0.4249\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.43626 to 0.42489, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4951 - val_loss: 0.4340\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.42489\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4958 - val_loss: 0.4420\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.42489\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4924 - val_loss: 0.4643\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.42489\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4784 - val_loss: 0.4227\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.42489 to 0.42267, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 19/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4758 - val_loss: 0.4168\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.42267 to 0.41678, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 20/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4754 - val_loss: 0.4257\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.41678\n",
      "Epoch 21/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4729 - val_loss: 0.3926\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.41678 to 0.39262, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:1units:32.h5\n",
      "Epoch 22/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4749 - val_loss: 0.4093\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.39262\n",
      "Epoch 23/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4735 - val_loss: 0.4094\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.39262\n",
      "Epoch 24/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4698 - val_loss: 0.4242\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.39262\n",
      "Epoch 25/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4653 - val_loss: 0.4175\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.39262\n",
      "Epoch 26/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.4648 - val_loss: 0.3957\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.39262\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 58906... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▆▇▆▆▆▆▆▆▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▄▄▃▃▄▃▄▃▃▂▂▂▂▂▃▂▂▂▁▁▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>20</td></tr><tr><td>best_val_loss</td><td>0.39262</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>loss</td><td>0.46479</td></tr><tr><td>val_loss</td><td>0.39568</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">summer-sweep-4</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/rykprfds\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/rykprfds</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_112950-rykprfds/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 20g9cqcj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/20g9cqcj\" target=\"_blank\">gallant-sweep-5</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 9, 16)             464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 553\n",
      "Trainable params: 553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 35s 29ms/step - loss: 0.8823 - val_loss: 0.8652\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86524, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.8579 - val_loss: 0.8624\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86524 to 0.86239, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8515 - val_loss: 0.8592\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.86239 to 0.85922, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8392 - val_loss: 0.8274\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.85922 to 0.82736, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8187 - val_loss: 0.8047\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.82736 to 0.80471, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.7993 - val_loss: 0.7842\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.80471 to 0.78419, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.7804 - val_loss: 0.7565\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.78419 to 0.75645, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 35s 29ms/step - loss: 0.7615 - val_loss: 0.7346\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.75645 to 0.73457, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7416 - val_loss: 0.6959\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.73457 to 0.69590, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.7218 - val_loss: 0.6831\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.69590 to 0.68308, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 35s 29ms/step - loss: 0.7015 - val_loss: 0.6618\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.68308 to 0.66180, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6900 - val_loss: 0.6403\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.66180 to 0.64026, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6787 - val_loss: 0.6366\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.64026 to 0.63659, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6743 - val_loss: 0.6399\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.63659\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6667 - val_loss: 0.6202\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.63659 to 0.62016, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6614 - val_loss: 0.6243\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.62016\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6594 - val_loss: 0.6020\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.62016 to 0.60204, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6582 - val_loss: 0.6213\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.60204\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 35s 29ms/step - loss: 0.6526 - val_loss: 0.6065\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.60204\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6503 - val_loss: 0.6100\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.60204\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6505 - val_loss: 0.6013\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.60204 to 0.60132, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6519 - val_loss: 0.6020\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.60132\n",
      "Epoch 23/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6500 - val_loss: 0.6048\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.60132\n",
      "Epoch 24/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6499 - val_loss: 0.5967\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.60132 to 0.59672, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 25/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6472 - val_loss: 0.5984\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.59672\n",
      "Epoch 26/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6457 - val_loss: 0.5934\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.59672 to 0.59341, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 27/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6491 - val_loss: 0.6149\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.59341\n",
      "Epoch 28/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6459 - val_loss: 0.5864\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.59341 to 0.58638, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:4_cols:3units:1.h5\n",
      "Epoch 29/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.6440 - val_loss: 0.6008\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.58638\n",
      "Epoch 30/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6435 - val_loss: 0.5984\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.58638\n",
      "Epoch 31/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6444 - val_loss: 0.5882\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.58638\n",
      "Epoch 32/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6445 - val_loss: 0.6052\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.58638\n",
      "Epoch 33/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6419 - val_loss: 0.5893\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.58638\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35265... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▇▇▆▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>███▇▆▆▅▅▄▃▃▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>27</td></tr><tr><td>best_val_loss</td><td>0.58638</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>loss</td><td>0.64185</td></tr><tr><td>val_loss</td><td>0.58925</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">gallant-sweep-5</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/20g9cqcj\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/20g9cqcj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_114631-20g9cqcj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qmaoj8jy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/qmaoj8jy\" target=\"_blank\">chocolate-sweep-6</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             896       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 953\n",
      "Trainable params: 953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.8395 - val_loss: 0.8151\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81511, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8129 - val_loss: 0.8111\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81511 to 0.81115, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.7964 - val_loss: 0.7724\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81115 to 0.77236, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.7709 - val_loss: 0.7468\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.77236 to 0.74683, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.7469 - val_loss: 0.7181\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.74683 to 0.71813, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.7230 - val_loss: 0.6781\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.71813 to 0.67811, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.7010 - val_loss: 0.6619\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.67811 to 0.66192, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6823 - val_loss: 0.6407\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.66192 to 0.64068, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.6636 - val_loss: 0.6161\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.64068 to 0.61615, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6479 - val_loss: 0.5971\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61615 to 0.59710, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6363 - val_loss: 0.5941\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.59710 to 0.59410, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6296 - val_loss: 0.5830\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.59410 to 0.58305, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.6226 - val_loss: 0.5869\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.58305\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6234 - val_loss: 0.5713\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.58305 to 0.57135, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6216 - val_loss: 0.5773\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.57135\n",
      "Epoch 16/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6215 - val_loss: 0.5739\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.57135\n",
      "Epoch 17/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6150 - val_loss: 0.5640\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.57135 to 0.56399, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 18/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6169 - val_loss: 0.5654\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.56399\n",
      "Epoch 19/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6151 - val_loss: 0.5646\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.56399\n",
      "Epoch 20/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6142 - val_loss: 0.5638\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.56399 to 0.56382, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 21/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6131 - val_loss: 0.5569\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.56382 to 0.55687, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 22/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6132 - val_loss: 0.5784\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.55687\n",
      "Epoch 23/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.6123 - val_loss: 0.5547\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.55687 to 0.55466, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 24/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6134 - val_loss: 0.5647\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.55466\n",
      "Epoch 25/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6112 - val_loss: 0.5557\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.55466\n",
      "Epoch 26/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6098 - val_loss: 0.5556\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.55466\n",
      "Epoch 27/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6121 - val_loss: 0.5624\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.55466\n",
      "Epoch 28/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6102 - val_loss: 0.5504\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.55466 to 0.55038, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 29/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6099 - val_loss: 0.5537\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.55038\n",
      "Epoch 30/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6084 - val_loss: 0.5621\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.55038\n",
      "Epoch 31/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6077 - val_loss: 0.5540\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.55038\n",
      "Epoch 32/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6042 - val_loss: 0.5459\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.55038 to 0.54590, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:2units:1.h5\n",
      "Epoch 33/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6094 - val_loss: 0.5709\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.54590\n",
      "Epoch 34/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.6087 - val_loss: 0.5548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.54590\n",
      "Epoch 35/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6074 - val_loss: 0.5587\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.54590\n",
      "Epoch 36/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.6088 - val_loss: 0.5566\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.54590\n",
      "Epoch 37/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6076 - val_loss: 0.5517\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.54590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 70494... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▇▆▅▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▆▅▄▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>31</td></tr><tr><td>best_val_loss</td><td>0.5459</td></tr><tr><td>epoch</td><td>36</td></tr><tr><td>loss</td><td>0.60761</td></tr><tr><td>val_loss</td><td>0.55174</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">chocolate-sweep-6</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/qmaoj8jy\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/qmaoj8jy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_120622-qmaoj8jy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8cvi2ehq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/8cvi2ehq\" target=\"_blank\">vivid-sweep-7</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 8)              288       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "=================================================================\n",
      "Total params: 384\n",
      "Trainable params: 384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.8993 - val_loss: 0.8084\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80844, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8079 - val_loss: 0.7634\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80844 to 0.76339, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.7572 - val_loss: 0.6973\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76339 to 0.69729, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.7154 - val_loss: 0.6599\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69729 to 0.65992, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6868 - val_loss: 0.6225\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65992 to 0.62254, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.6676 - val_loss: 0.5912\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62254 to 0.59124, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.6497 - val_loss: 0.5833\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.59124 to 0.58330, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6395 - val_loss: 0.5655\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.58330 to 0.56552, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6278 - val_loss: 0.5491\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56552 to 0.54914, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.6215 - val_loss: 0.5522\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54914\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6153 - val_loss: 0.5437\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54914 to 0.54373, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.6093 - val_loss: 0.5376\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54373 to 0.53761, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.6051 - val_loss: 0.5240\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53761 to 0.52404, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.6025 - val_loss: 0.5267\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.52404\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.5982 - val_loss: 0.5330\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.52404\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5954 - val_loss: 0.5292\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.52404\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5925 - val_loss: 0.5174\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52404 to 0.51743, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5919 - val_loss: 0.5174\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.51743 to 0.51737, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 19/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5906 - val_loss: 0.5191\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.51737\n",
      "Epoch 20/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5903 - val_loss: 0.5252\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51737\n",
      "Epoch 21/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5888 - val_loss: 0.5138\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.51737 to 0.51383, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:5_cols:3units:4.h5\n",
      "Epoch 22/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5884 - val_loss: 0.5158\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.51383\n",
      "Epoch 23/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5889 - val_loss: 0.5195\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51383\n",
      "Epoch 24/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5849 - val_loss: 0.5160\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51383\n",
      "Epoch 25/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5858 - val_loss: 0.5219\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.51383\n",
      "Epoch 26/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5856 - val_loss: 0.5240\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.51383\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 58514... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>20</td></tr><tr><td>best_val_loss</td><td>0.51383</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>loss</td><td>0.58558</td></tr><tr><td>val_loss</td><td>0.52396</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vivid-sweep-7</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/8cvi2ehq\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/8cvi2ehq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_123005-8cvi2ehq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gpq7wxvu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/gpq7wxvu\" target=\"_blank\">eager-sweep-8</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 5, 8)              152       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,092\n",
      "Trainable params: 1,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.8673 - val_loss: 0.7344\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73439, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.7264 - val_loss: 0.6416\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73439 to 0.64164, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6459 - val_loss: 0.5716\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64164 to 0.57155, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5979 - val_loss: 0.5461\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57155 to 0.54614, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5687 - val_loss: 0.5346\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54614 to 0.53464, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5505 - val_loss: 0.5354\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53464\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5343 - val_loss: 0.5264\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.53464 to 0.52637, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5223 - val_loss: 0.5242\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.52637 to 0.52421, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5138 - val_loss: 0.5221\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52421 to 0.52209, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5070 - val_loss: 0.5156\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52209 to 0.51557, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5005 - val_loss: 0.5120\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.51557 to 0.51205, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4961 - val_loss: 0.5084\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.51205 to 0.50845, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4921 - val_loss: 0.5149\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.50845\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4884 - val_loss: 0.4987\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.50845 to 0.49873, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4846 - val_loss: 0.5081\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.49873\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4819 - val_loss: 0.4934\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.49873 to 0.49337, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4786 - val_loss: 0.4941\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.49337\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4768 - val_loss: 0.4956\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.49337\n",
      "Epoch 19/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4752 - val_loss: 0.4969\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.49337\n",
      "Epoch 20/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4728 - val_loss: 0.4836\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.49337 to 0.48356, saving model to MLP_l:0.0001_sr:10_ws:6_u1:8_u2:2_cols:2units:32.h5\n",
      "Epoch 21/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4736 - val_loss: 0.4932\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.48356\n",
      "Epoch 22/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4721 - val_loss: 0.4898\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.48356\n",
      "Epoch 23/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4710 - val_loss: 0.4874\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.48356\n",
      "Epoch 24/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4698 - val_loss: 0.4849\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.48356\n",
      "Epoch 25/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4693 - val_loss: 0.4890\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.48356\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35804... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>19</td></tr><tr><td>best_val_loss</td><td>0.48356</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.46933</td></tr><tr><td>val_loss</td><td>0.48904</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">eager-sweep-8</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/gpq7wxvu\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/gpq7wxvu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_124705-gpq7wxvu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nvkx6fg6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/nvkx6fg6\" target=\"_blank\">earnest-sweep-9</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             1472      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "=================================================================\n",
      "Total params: 1,664\n",
      "Trainable params: 1,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.6323 - val_loss: 0.5067\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50667, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:4.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.5474 - val_loss: 0.4728\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50667 to 0.47282, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:4.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5280 - val_loss: 0.4622\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.47282 to 0.46218, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:4.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5199 - val_loss: 0.4441\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46218 to 0.44408, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:4.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.5153 - val_loss: 0.4592\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44408\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.5119 - val_loss: 0.4608\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44408\n",
      "Epoch 7/55\n",
      " 734/1334 [===============>..............] - ETA: 15s - loss: 0.5133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5091 - val_loss: 0.4529\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44254\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.5074 - val_loss: 0.4477\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44254\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5045 - val_loss: 0.4414\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.44254 to 0.44138, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:4.h5\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.5060 - val_loss: 0.4418\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44138\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5062 - val_loss: 0.4469\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.44138\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5056 - val_loss: 0.4357\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.44138 to 0.43566, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:4.h5\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5062 - val_loss: 0.4432\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.43566\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5036 - val_loss: 0.4377\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.43566\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5039 - val_loss: 0.4235\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.43566 to 0.42353, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:4.h5\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5045 - val_loss: 0.4389\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.42353\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5049 - val_loss: 0.4488\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.42353\n",
      "Epoch 19/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5042 - val_loss: 0.4237\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.42353\n",
      "Epoch 20/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5021 - val_loss: 0.4412\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.42353\n",
      "Epoch 21/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.4990 - val_loss: 0.4261\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.42353\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3913... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▄▄▃▃▃▃▃▃▂▃▂▁▂▃▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>15</td></tr><tr><td>best_val_loss</td><td>0.42353</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>loss</td><td>0.49898</td></tr><tr><td>val_loss</td><td>0.42606</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">earnest-sweep-9</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/nvkx6fg6\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/nvkx6fg6</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_130323-nvkx6fg6/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oy5d8ysi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/oy5d8ysi\" target=\"_blank\">devout-sweep-10</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 8)              344       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,028\n",
      "Trainable params: 1,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.9005 - val_loss: 0.7800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78004, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.7584 - val_loss: 0.6737\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78004 to 0.67372, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6744 - val_loss: 0.6040\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67372 to 0.60401, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6303 - val_loss: 0.5711\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60401 to 0.57106, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6025 - val_loss: 0.5656\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57106 to 0.56563, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 39s 29ms/step - loss: 0.5822 - val_loss: 0.5624\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56563 to 0.56235, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.5654 - val_loss: 0.5607\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56235 to 0.56071, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:3_cols:1units:32.h5\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5519 - val_loss: 0.5651\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.56071\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5431 - val_loss: 0.5667\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56071\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5368 - val_loss: 0.5624\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56071\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5308 - val_loss: 0.5743\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.56071\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 39s 29ms/step - loss: 0.5284 - val_loss: 0.5645\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.56071\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19708... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.56071</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.52841</td></tr><tr><td>val_loss</td><td>0.56447</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">devout-sweep-10</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/oy5d8ysi\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/oy5d8ysi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_131752-oy5d8ysi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cyu4c8gw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/cyu4c8gw\" target=\"_blank\">restful-sweep-11</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 8, 64)             2304      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 2,585\n",
      "Trainable params: 2,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.8405 - val_loss: 0.8491\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84914, saving model to MLP_l:0.01_sr:10_ws:12_u1:64_u2:5_cols:3units:1.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8400 - val_loss: 0.8479\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.84914 to 0.84791, saving model to MLP_l:0.01_sr:10_ws:12_u1:64_u2:5_cols:3units:1.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8398 - val_loss: 0.8441\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.84791 to 0.84406, saving model to MLP_l:0.01_sr:10_ws:12_u1:64_u2:5_cols:3units:1.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8403 - val_loss: 0.8424\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.84406 to 0.84237, saving model to MLP_l:0.01_sr:10_ws:12_u1:64_u2:5_cols:3units:1.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8415 - val_loss: 0.8508\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.84237\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8397 - val_loss: 0.8473\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.84237\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8402 - val_loss: 0.8436\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.84237\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8390 - val_loss: 0.8528\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.84237\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8392 - val_loss: 0.8548\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.84237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39919... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>loss</td><td>▅▄▃▅█▃▄▁▂</td></tr><tr><td>val_loss</td><td>▅▄▂▁▆▄▂▇█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.84237</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>loss</td><td>0.83922</td></tr><tr><td>val_loss</td><td>0.85481</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">restful-sweep-11</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/cyu4c8gw\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/cyu4c8gw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_132627-cyu4c8gw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dh2df2t0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/dh2df2t0\" target=\"_blank\">stilted-sweep-12</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35078... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stilted-sweep-12</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/dh2df2t0\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/dh2df2t0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_133315-dh2df2t0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run dh2df2t0 errored: ValueError('Negative dimension size caused by subtracting 2 from 1 for \\'{{node max_pooling1d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d/ExpandDims)\\' with input shapes: [?,1,1,32].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d1gsst9w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/d1gsst9w\" target=\"_blank\">breezy-sweep-13</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 9, 8)              584       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 1,316\n",
      "Trainable params: 1,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 75.4731 - val_loss: 0.8795\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.87953, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:0units:16.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 10.8413 - val_loss: 0.8753\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.87953 to 0.87525, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:0units:16.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 2.5513 - val_loss: 0.8683\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.87525 to 0.86833, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:0units:16.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 1.2964 - val_loss: 0.8659\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.86833 to 0.86586, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:0units:16.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.9089 - val_loss: 0.8523\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.86586 to 0.85229, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:0units:16.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 0.8530 - val_loss: 0.8683\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.85229\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.8486 - val_loss: 0.8478\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85229 to 0.84781, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:0units:16.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.8462 - val_loss: 0.8486\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.84781\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.8445 - val_loss: 0.8506\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.84781\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 0.8429 - val_loss: 0.8510\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.84781\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.8421 - val_loss: 0.8525\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.84781\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.8415 - val_loss: 0.8518\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.84781\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35161... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▂▆▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.84781</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.84151</td></tr><tr><td>val_loss</td><td>0.85184</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">breezy-sweep-13</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/d1gsst9w\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/d1gsst9w</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_133413-d1gsst9w/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0ylnc3z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/a0ylnc3z\" target=\"_blank\">spring-sweep-14</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 9, 8)              296       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "=================================================================\n",
      "Total params: 668\n",
      "Trainable params: 668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.9312 - val_loss: 0.8467\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84668, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8437 - val_loss: 0.7876\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.84668 to 0.78759, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.7783 - val_loss: 0.7138\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.78759 to 0.71380, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.7249 - val_loss: 0.6633\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.71380 to 0.66332, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6835 - val_loss: 0.6167\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66332 to 0.61668, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6533 - val_loss: 0.5913\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.61668 to 0.59129, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6338 - val_loss: 0.5766\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.59129 to 0.57662, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6205 - val_loss: 0.5566\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.57662 to 0.55659, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.6090 - val_loss: 0.5572\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.55659\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.6014 - val_loss: 0.5661\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.55659\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5919 - val_loss: 0.5355\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.55659 to 0.53553, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5880 - val_loss: 0.5379\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53553\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5795 - val_loss: 0.5330\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53553 to 0.53300, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5731 - val_loss: 0.5264\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.53300 to 0.52639, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5678 - val_loss: 0.5237\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.52639 to 0.52369, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5667 - val_loss: 0.5138\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52369 to 0.51381, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5624 - val_loss: 0.5185\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51381\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5573 - val_loss: 0.5094\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.51381 to 0.50942, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5546 - val_loss: 0.5031\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.50942 to 0.50311, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5510 - val_loss: 0.5031\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.50311 to 0.50306, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5485 - val_loss: 0.4906\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.50306 to 0.49064, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5476 - val_loss: 0.5069\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.49064\n",
      "Epoch 23/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5422 - val_loss: 0.4843\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.49064 to 0.48432, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 24/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5402 - val_loss: 0.4890\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.48432\n",
      "Epoch 25/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5372 - val_loss: 0.4915\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.48432\n",
      "Epoch 26/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5356 - val_loss: 0.4777\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.48432 to 0.47774, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 27/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5327 - val_loss: 0.4834\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.47774\n",
      "Epoch 28/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5323 - val_loss: 0.4849\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.47774\n",
      "Epoch 29/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5308 - val_loss: 0.4614\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.47774 to 0.46145, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:4_cols:2units:8.h5\n",
      "Epoch 30/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5276 - val_loss: 0.4851\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.46145\n",
      "Epoch 31/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5274 - val_loss: 0.4658\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.46145\n",
      "Epoch 32/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5263 - val_loss: 0.4815\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.46145\n",
      "Epoch 33/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5239 - val_loss: 0.4643\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.46145\n",
      "Epoch 34/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5238 - val_loss: 0.4742\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.46145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 55551... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>28</td></tr><tr><td>best_val_loss</td><td>0.46145</td></tr><tr><td>epoch</td><td>33</td></tr><tr><td>loss</td><td>0.52384</td></tr><tr><td>val_loss</td><td>0.47423</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">spring-sweep-14</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/a0ylnc3z\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/a0ylnc3z</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_134254-a0ylnc3z/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lq6uglmw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/lq6uglmw\" target=\"_blank\">stellar-sweep-15</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 7, 8)              248       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 3, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                800       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,444\n",
      "Trainable params: 1,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8816 - val_loss: 0.7411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74109, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.7141 - val_loss: 0.6122\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74109 to 0.61222, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.6380 - val_loss: 0.5456\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61222 to 0.54561, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5981 - val_loss: 0.5140\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54561 to 0.51405, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5757 - val_loss: 0.4914\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51405 to 0.49141, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5610 - val_loss: 0.4809\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49141 to 0.48094, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5473 - val_loss: 0.4786\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.48094 to 0.47855, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5397 - val_loss: 0.4685\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47855 to 0.46845, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5320 - val_loss: 0.4647\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.46845 to 0.46475, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5257 - val_loss: 0.4670\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.46475\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5179 - val_loss: 0.4593\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.46475 to 0.45929, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5143 - val_loss: 0.4590\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.45929 to 0.45904, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5115 - val_loss: 0.4597\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45904\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5064 - val_loss: 0.4603\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45904\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5011 - val_loss: 0.4537\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.45904 to 0.45370, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4988 - val_loss: 0.4471\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.45370 to 0.44708, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:6_cols:4units:32.h5\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4963 - val_loss: 0.4588\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.44708\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4928 - val_loss: 0.4594\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.44708\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.4907 - val_loss: 0.4491\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.44708\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4890 - val_loss: 0.4484\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.44708\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.4850 - val_loss: 0.4603\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.44708\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18276... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>15</td></tr><tr><td>best_val_loss</td><td>0.44708</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>loss</td><td>0.48503</td></tr><tr><td>val_loss</td><td>0.46031</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stellar-sweep-15</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/lq6uglmw\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/lq6uglmw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_140434-lq6uglmw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 42dp6o1t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/42dp6o1t\" target=\"_blank\">glowing-sweep-16</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 32)             512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8115 - val_loss: 0.7786\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77862, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.7613 - val_loss: 0.7228\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77862 to 0.72276, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.7235 - val_loss: 0.6818\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.72276 to 0.68178, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6945 - val_loss: 0.6572\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68178 to 0.65723, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6727 - val_loss: 0.6331\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65723 to 0.63309, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6594 - val_loss: 0.6142\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.63309 to 0.61419, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6495 - val_loss: 0.6040\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61419 to 0.60402, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.6393 - val_loss: 0.5941\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.60402 to 0.59410, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.6314 - val_loss: 0.5929\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.59410 to 0.59293, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.6261 - val_loss: 0.5811\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.59293 to 0.58115, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.6236 - val_loss: 0.5913\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.58115\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6231 - val_loss: 0.5719\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58115 to 0.57192, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6202 - val_loss: 0.5816\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57192\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 39s 30ms/step - loss: 0.6187 - val_loss: 0.5632\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.57192 to 0.56323, saving model to MLP_l:0.0001_sr:10_ws:6_u1:32_u2:3_cols:4units:1.h5\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6159 - val_loss: 0.5741\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.56323\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6138 - val_loss: 0.5705\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.56323\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6125 - val_loss: 0.5717\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.56323\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6137 - val_loss: 0.5674\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.56323\n",
      "Epoch 19/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6100 - val_loss: 0.5664\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.56323\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 33653... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.56323</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>loss</td><td>0.60999</td></tr><tr><td>val_loss</td><td>0.56639</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glowing-sweep-16</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/42dp6o1t\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/42dp6o1t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_141847-42dp6o1t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 67xrz1ks with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/67xrz1ks\" target=\"_blank\">soft-sweep-17</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 11, 64)            960       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 321       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 1,305\n",
      "Trainable params: 1,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.7839 - val_loss: 0.6677\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66769, saving model to MLP_l:0.001_sr:10_ws:12_u1:64_u2:2_cols:3units:1.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.6849 - val_loss: 0.6235\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66769 to 0.62349, saving model to MLP_l:0.001_sr:10_ws:12_u1:64_u2:2_cols:3units:1.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6604 - val_loss: 0.6022\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62349 to 0.60216, saving model to MLP_l:0.001_sr:10_ws:12_u1:64_u2:2_cols:3units:1.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6561 - val_loss: 0.6035\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.60216\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6541 - val_loss: 0.6138\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.60216\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.6510 - val_loss: 0.6125\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.60216\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.6498 - val_loss: 0.5942\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60216 to 0.59419, saving model to MLP_l:0.001_sr:10_ws:12_u1:64_u2:2_cols:3units:1.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 0.6490 - val_loss: 0.5786\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59419 to 0.57859, saving model to MLP_l:0.001_sr:10_ws:12_u1:64_u2:2_cols:3units:1.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.6487 - val_loss: 0.5967\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.57859\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 0.6473 - val_loss: 0.5917\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57859\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.6481 - val_loss: 0.5857\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.57859\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.6445 - val_loss: 0.5888\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.57859\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.6461 - val_loss: 0.5902\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57859\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32062... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▃▄▄▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.57859</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>loss</td><td>0.64611</td></tr><tr><td>val_loss</td><td>0.59016</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">soft-sweep-17</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/67xrz1ks\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/67xrz1ks</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_143147-67xrz1ks/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kj80b6a9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/kj80b6a9\" target=\"_blank\">firm-sweep-18</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 16)             352       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 828\n",
      "Trainable params: 828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.8839 - val_loss: 0.7708\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77081, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.7429 - val_loss: 0.6481\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77081 to 0.64806, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6485 - val_loss: 0.5581\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64806 to 0.55814, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6010 - val_loss: 0.5294\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55814 to 0.52944, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5743 - val_loss: 0.5086\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52944 to 0.50860, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5589 - val_loss: 0.4952\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50860 to 0.49516, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5468 - val_loss: 0.4936\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49516 to 0.49358, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5376 - val_loss: 0.4976\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.49358\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5286 - val_loss: 0.4865\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.49358 to 0.48652, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5216 - val_loss: 0.4759\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48652 to 0.47587, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5159 - val_loss: 0.4917\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.47587\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5122 - val_loss: 0.4793\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.47587\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5070 - val_loss: 0.4800\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.47587\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5059 - val_loss: 0.4736\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.47587 to 0.47358, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5025 - val_loss: 0.4865\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47358\n",
      "Epoch 16/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5017 - val_loss: 0.4809\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.47358\n",
      "Epoch 17/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5011 - val_loss: 0.4781\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.47358\n",
      "Epoch 18/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.4984 - val_loss: 0.4858\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.47358\n",
      "Epoch 19/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.4976 - val_loss: 0.4913\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.47358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 60849... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.47358</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>loss</td><td>0.49755</td></tr><tr><td>val_loss</td><td>0.49125</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">firm-sweep-18</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/kj80b6a9\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/kj80b6a9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_144052-kj80b6a9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hkc6stwr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/hkc6stwr\" target=\"_blank\">treasured-sweep-19</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 59213... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">treasured-sweep-19</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/hkc6stwr\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/hkc6stwr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_145340-hkc6stwr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run hkc6stwr errored: ValueError('Negative dimension size caused by subtracting 5 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,14], [1,5,14,32].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g1kixbjo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/g1kixbjo\" target=\"_blank\">valiant-sweep-20</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 64)             3520      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 8,044\n",
      "Trainable params: 8,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 15.3757 - val_loss: 0.8300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82999, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 1.2617 - val_loss: 0.8216\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82999 to 0.82156, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.9344 - val_loss: 0.8179\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.82156 to 0.81785, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8698 - val_loss: 0.8175\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81785 to 0.81754, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8364 - val_loss: 0.8179\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.81754\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8253 - val_loss: 0.8174\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.81754 to 0.81745, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8194 - val_loss: 0.8199\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.81745\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8176 - val_loss: 0.8152\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.81745 to 0.81519, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8144 - val_loss: 0.8153\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.81519\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8146 - val_loss: 0.8173\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.81519\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8142 - val_loss: 0.8118\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.81519 to 0.81185, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8133 - val_loss: 0.8137\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.81185\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8118 - val_loss: 0.8177\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.81185\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8121 - val_loss: 0.8023\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.81185 to 0.80226, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:3_cols:0units:32.h5\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.8124 - val_loss: 0.8181\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80226\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8118 - val_loss: 0.8078\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.80226\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.8118 - val_loss: 0.8168\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.80226\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8110 - val_loss: 0.8162\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.80226\n",
      "Epoch 19/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8118 - val_loss: 0.8123\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.80226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 59251... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.13MB of 0.13MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▅▅▅▅▄▄▅▃▄▅▁▅▂▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.80226</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>loss</td><td>0.81177</td></tr><tr><td>val_loss</td><td>0.81233</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">valiant-sweep-20</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/g1kixbjo\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/g1kixbjo</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_145437-g1kixbjo/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ruk9xp6q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ruk9xp6q\" target=\"_blank\">decent-sweep-21</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             704       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.8036 - val_loss: 0.7744\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77438, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.7644 - val_loss: 0.7322\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77438 to 0.73222, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.7341 - val_loss: 0.6989\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73222 to 0.69888, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.7101 - val_loss: 0.6659\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69888 to 0.66590, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6850 - val_loss: 0.6481\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66590 to 0.64813, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6677 - val_loss: 0.6240\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.64813 to 0.62402, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6536 - val_loss: 0.6205\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62402 to 0.62051, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6473 - val_loss: 0.6044\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62051 to 0.60439, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6405 - val_loss: 0.5937\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60439 to 0.59372, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6357 - val_loss: 0.5863\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.59372 to 0.58625, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6312 - val_loss: 0.5841\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.58625 to 0.58414, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6272 - val_loss: 0.5853\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.58414\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6268 - val_loss: 0.5807\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.58414 to 0.58065, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6254 - val_loss: 0.5772\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.58065 to 0.57719, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6183 - val_loss: 0.5734\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.57719 to 0.57340, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 16/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6185 - val_loss: 0.5721\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.57340 to 0.57214, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 17/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6197 - val_loss: 0.5748\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57214\n",
      "Epoch 18/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6166 - val_loss: 0.5782\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.57214\n",
      "Epoch 19/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6175 - val_loss: 0.5573\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.57214 to 0.55732, saving model to MLP_l:0.0001_sr:10_ws:4_u1:32_u2:3_cols:3units:1.h5\n",
      "Epoch 20/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6132 - val_loss: 0.5733\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.55732\n",
      "Epoch 21/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6143 - val_loss: 0.5619\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.55732\n",
      "Epoch 22/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6145 - val_loss: 0.5706\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.55732\n",
      "Epoch 23/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6142 - val_loss: 0.5642\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.55732\n",
      "Epoch 24/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6141 - val_loss: 0.5621\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.55732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 57339... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▇▅▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▃▃▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>18</td></tr><tr><td>best_val_loss</td><td>0.55732</td></tr><tr><td>epoch</td><td>23</td></tr><tr><td>loss</td><td>0.61407</td></tr><tr><td>val_loss</td><td>0.56213</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">decent-sweep-21</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ruk9xp6q\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/ruk9xp6q</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_150718-ruk9xp6q/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8zjquc2w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/8zjquc2w\" target=\"_blank\">fragrant-sweep-22</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16831... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fragrant-sweep-22</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/8zjquc2w\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/8zjquc2w</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_152328-8zjquc2w/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 8zjquc2w errored: ValueError('Negative dimension size caused by subtracting 2 from 1 for \\'{{node max_pooling1d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d/ExpandDims)\\' with input shapes: [?,1,1,32].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r4t0scmo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/r4t0scmo\" target=\"_blank\">eager-sweep-23</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 9, 64)             2368      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "=================================================================\n",
      "Total params: 4,532\n",
      "Trainable params: 4,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8415 - val_loss: 0.7573\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75734, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.7483 - val_loss: 0.6916\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75734 to 0.69158, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7011 - val_loss: 0.6353\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69158 to 0.63529, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6492 - val_loss: 0.5647\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63529 to 0.56470, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6091 - val_loss: 0.5289\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56470 to 0.52885, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5833 - val_loss: 0.5090\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52885 to 0.50899, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5663 - val_loss: 0.4970\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.50899 to 0.49702, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5552 - val_loss: 0.4910\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.49702 to 0.49100, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5451 - val_loss: 0.4709\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.49100 to 0.47089, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5346 - val_loss: 0.4653\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47089 to 0.46527, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5270 - val_loss: 0.4576\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.46527 to 0.45755, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5196 - val_loss: 0.4680\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45755\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5164 - val_loss: 0.4440\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.45755 to 0.44398, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5116 - val_loss: 0.4601\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.44398\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5077 - val_loss: 0.4347\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.44398 to 0.43466, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5039 - val_loss: 0.4533\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.43466\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5029 - val_loss: 0.4360\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.43466\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5014 - val_loss: 0.4328\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.43466 to 0.43280, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5000 - val_loss: 0.4496\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.43280\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.4969 - val_loss: 0.4446\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.43280\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.4956 - val_loss: 0.4231\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.43280 to 0.42314, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:4_cols:2units:8.h5\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.4962 - val_loss: 0.4463\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.42314\n",
      "Epoch 23/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.4948 - val_loss: 0.4315\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.42314\n",
      "Epoch 24/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.4931 - val_loss: 0.4445\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.42314\n",
      "Epoch 25/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4895 - val_loss: 0.4251\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.42314\n",
      "Epoch 26/55\n",
      "1173/1173 [==============================] - 35s 29ms/step - loss: 0.4907 - val_loss: 0.4364\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.42314\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16869... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.09MB of 0.09MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▃▂▂▂▂▂▁▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>20</td></tr><tr><td>best_val_loss</td><td>0.42314</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>loss</td><td>0.49071</td></tr><tr><td>val_loss</td><td>0.43645</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">eager-sweep-23</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/r4t0scmo\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/r4t0scmo</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_152426-r4t0scmo/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 99mqwow2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/99mqwow2\" target=\"_blank\">deft-sweep-24</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 16)             576       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 617\n",
      "Trainable params: 617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.6938 - val_loss: 0.5976\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59757, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:5_cols:3units:1.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6670 - val_loss: 0.6096\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.59757\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.6662 - val_loss: 0.5902\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.59757 to 0.59017, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:5_cols:3units:1.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.6642 - val_loss: 0.6163\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59017\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.6623 - val_loss: 0.6415\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59017\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.6627 - val_loss: 0.6113\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59017\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6563 - val_loss: 0.5913\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59017\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.6517 - val_loss: 0.6137\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 74070... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>loss</td><td>█▄▃▃▃▃▂▁</td></tr><tr><td>val_loss</td><td>▂▄▁▅█▄▁▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.59017</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>0.65165</td></tr><tr><td>val_loss</td><td>0.61374</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deft-sweep-24</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/99mqwow2\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/99mqwow2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_154037-99mqwow2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pox5bs7d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/pox5bs7d\" target=\"_blank\">snowy-sweep-25</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 64)             5824      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "=================================================================\n",
      "Total params: 6,452\n",
      "Trainable params: 6,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 23.1449 - val_loss: 0.8283\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82833, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:5_cols:0units:8.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 1.6089 - val_loss: 0.8190\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82833 to 0.81898, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:5_cols:0units:8.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 1.0331 - val_loss: 0.8167\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81898 to 0.81668, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:5_cols:0units:8.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8857 - val_loss: 0.8216\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.81668\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8328 - val_loss: 0.8178\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.81668\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8159 - val_loss: 0.8111\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.81668 to 0.81115, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:5_cols:0units:8.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.8125 - val_loss: 0.8216\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.81115\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.8121 - val_loss: 0.8124\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.81115\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.8118 - val_loss: 0.8133\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.81115\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.8109 - val_loss: 0.8210\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.81115\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 35s 27ms/step - loss: 0.8086 - val_loss: 0.8012\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.81115 to 0.80122, saving model to MLP_l:0.0001_sr:10_ws:6_u1:64_u2:5_cols:0units:8.h5\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.8056 - val_loss: 0.8209\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80122\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.7992 - val_loss: 0.8187\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80122\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 35s 27ms/step - loss: 0.7950 - val_loss: 0.8085\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80122\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.7898 - val_loss: 0.8092\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80122\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 35s 27ms/step - loss: 0.7861 - val_loss: 0.8181\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.80122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 60588... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.11MB of 0.11MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▆▅▄▆▄▄▆▁▆▆▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.80122</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>loss</td><td>0.78611</td></tr><tr><td>val_loss</td><td>0.81808</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">snowy-sweep-25</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/pox5bs7d\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/pox5bs7d</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_154613-pox5bs7d/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i4v0jcc0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/i4v0jcc0\" target=\"_blank\">rare-sweep-26</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 7, 16)             880       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 196       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "=================================================================\n",
      "Total params: 1,136\n",
      "Trainable params: 1,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.9193 - val_loss: 0.8568\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.85682, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8513 - val_loss: 0.8386\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.85682 to 0.83856, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8298 - val_loss: 0.8179\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.83856 to 0.81787, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8081 - val_loss: 0.7917\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81787 to 0.79170, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7809 - val_loss: 0.7507\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.79170 to 0.75069, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7467 - val_loss: 0.6844\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.75069 to 0.68444, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7122 - val_loss: 0.6627\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68444 to 0.66271, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6805 - val_loss: 0.6164\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.66271 to 0.61643, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6540 - val_loss: 0.5817\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.61643 to 0.58175, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6300 - val_loss: 0.5647\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.58175 to 0.56475, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6122 - val_loss: 0.5526\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.56475 to 0.55263, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5970 - val_loss: 0.5328\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.55263 to 0.53283, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5884 - val_loss: 0.5268\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53283 to 0.52679, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5807 - val_loss: 0.5089\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52679 to 0.50891, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5729 - val_loss: 0.5190\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.50891\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5714 - val_loss: 0.5051\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.50891 to 0.50505, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5685 - val_loss: 0.5105\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.50505\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5646 - val_loss: 0.4986\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.50505 to 0.49855, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5631 - val_loss: 0.4956\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.49855 to 0.49561, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5585 - val_loss: 0.4963\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.49561\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5571 - val_loss: 0.5085\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.49561\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5567 - val_loss: 0.4900\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.49561 to 0.48997, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 23/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5552 - val_loss: 0.4928\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.48997\n",
      "Epoch 24/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5532 - val_loss: 0.4935\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.48997\n",
      "Epoch 25/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5504 - val_loss: 0.4872\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.48997 to 0.48720, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 26/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5516 - val_loss: 0.4975\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.48720\n",
      "Epoch 27/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5488 - val_loss: 0.4854\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.48720 to 0.48542, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 28/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5493 - val_loss: 0.4886\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.48542\n",
      "Epoch 29/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5461 - val_loss: 0.4937\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.48542\n",
      "Epoch 30/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 0.5475 - val_loss: 0.4828\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.48542 to 0.48283, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 31/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5442 - val_loss: 0.4855\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.48283\n",
      "Epoch 32/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5459 - val_loss: 0.4963\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.48283\n",
      "Epoch 33/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5448 - val_loss: 0.4925\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.48283\n",
      "Epoch 34/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5416 - val_loss: 0.4816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from 0.48283 to 0.48161, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:6_cols:2units:4.h5\n",
      "Epoch 35/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5448 - val_loss: 0.4857\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.48161\n",
      "Epoch 36/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5434 - val_loss: 0.4820\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.48161\n",
      "Epoch 37/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5406 - val_loss: 0.4857\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.48161\n",
      "Epoch 38/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5427 - val_loss: 0.4820\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.48161\n",
      "Epoch 39/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5415 - val_loss: 0.4882\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.48161\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 34012... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▆▆▅▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▆▅▄▄▃▃▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>33</td></tr><tr><td>best_val_loss</td><td>0.48161</td></tr><tr><td>epoch</td><td>38</td></tr><tr><td>loss</td><td>0.54148</td></tr><tr><td>val_loss</td><td>0.48822</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">rare-sweep-26</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/i4v0jcc0\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/i4v0jcc0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_155649-i4v0jcc0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4vmg5aij with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/4vmg5aij\" target=\"_blank\">legendary-sweep-27</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39366... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">legendary-sweep-27</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/4vmg5aij\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/4vmg5aij</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_162117-4vmg5aij/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 4vmg5aij errored: ValueError('Negative dimension size caused by subtracting 6 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,14], [1,6,14,16].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kiwwnsfd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/kiwwnsfd\" target=\"_blank\">quiet-sweep-28</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39442... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">quiet-sweep-28</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/kiwwnsfd\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/kiwwnsfd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_162258-kiwwnsfd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run kiwwnsfd errored: ValueError('Negative dimension size caused by subtracting 2 from 1 for \\'{{node max_pooling1d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d/ExpandDims)\\' with input shapes: [?,1,1,16].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ha4lr75y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ha4lr75y\" target=\"_blank\">trim-sweep-29</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             1376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "=================================================================\n",
      "Total params: 1,568\n",
      "Trainable params: 1,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6043 - val_loss: 0.5154\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51539, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5592 - val_loss: 0.4686\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51539 to 0.46864, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5504 - val_loss: 0.4685\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46864 to 0.46854, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5517 - val_loss: 0.5025\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46854\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5707 - val_loss: 0.4914\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.46854\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5360 - val_loss: 0.4678\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46854 to 0.46775, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5306 - val_loss: 0.4568\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46775 to 0.45680, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 35s 26ms/step - loss: 0.5271 - val_loss: 0.4658\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45680\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5278 - val_loss: 0.4780\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45680\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 35s 25ms/step - loss: 0.5254 - val_loss: 0.4417\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45680 to 0.44172, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5226 - val_loss: 0.4372\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44172 to 0.43723, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5228 - val_loss: 0.4472\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.43723\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5219 - val_loss: 0.4459\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.43723\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5243 - val_loss: 0.4470\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.43723\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 35s 26ms/step - loss: 0.5156 - val_loss: 0.4301\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.43723 to 0.43013, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 16/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5126 - val_loss: 0.4555\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.43013\n",
      "Epoch 17/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5118 - val_loss: 0.4406\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.43013\n",
      "Epoch 18/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5114 - val_loss: 0.4617\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.43013\n",
      "Epoch 19/55\n",
      "1379/1379 [==============================] - 35s 25ms/step - loss: 0.5069 - val_loss: 0.4464\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.43013\n",
      "Epoch 20/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5069 - val_loss: 0.4246\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.43013 to 0.42463, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 21/55\n",
      "1379/1379 [==============================] - 35s 26ms/step - loss: 0.5076 - val_loss: 0.4447\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.42463\n",
      "Epoch 22/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5039 - val_loss: 0.4253\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.42463\n",
      "Epoch 23/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5050 - val_loss: 0.4174\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.42463 to 0.41738, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:3_cols:1units:4.h5\n",
      "Epoch 24/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5055 - val_loss: 0.4392\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.41738\n",
      "Epoch 25/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5044 - val_loss: 0.4285\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.41738\n",
      "Epoch 26/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5056 - val_loss: 0.4382\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.41738\n",
      "Epoch 27/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5027 - val_loss: 0.4307\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.41738\n",
      "Epoch 28/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5022 - val_loss: 0.4390\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.41738\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39487... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▄▆▃▃▃▃▃▂▂▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▅▇▆▅▄▄▅▃▂▃▃▃▂▄▃▄▃▂▃▂▁▃▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>22</td></tr><tr><td>best_val_loss</td><td>0.41738</td></tr><tr><td>epoch</td><td>27</td></tr><tr><td>loss</td><td>0.50224</td></tr><tr><td>val_loss</td><td>0.439</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">trim-sweep-29</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ha4lr75y\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/ha4lr75y</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_162358-ha4lr75y/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4ck01gig with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/4ck01gig\" target=\"_blank\">zany-sweep-30</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 8)              344       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "=================================================================\n",
      "Total params: 524\n",
      "Trainable params: 524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.7016 - val_loss: 0.5628\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56279, saving model to MLP_l:0.001_sr:10_ws:4_u1:8_u2:3_cols:1units:8.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5722 - val_loss: 0.5449\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56279 to 0.54488, saving model to MLP_l:0.001_sr:10_ws:4_u1:8_u2:3_cols:1units:8.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.5481 - val_loss: 0.5301\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54488 to 0.53014, saving model to MLP_l:0.001_sr:10_ws:4_u1:8_u2:3_cols:1units:8.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.5358 - val_loss: 0.5325\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53014\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5341 - val_loss: 0.5178\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53014 to 0.51782, saving model to MLP_l:0.001_sr:10_ws:4_u1:8_u2:3_cols:1units:8.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5334 - val_loss: 0.5355\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51782\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5299 - val_loss: 0.5307\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.51782\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5291 - val_loss: 0.5096\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51782 to 0.50955, saving model to MLP_l:0.001_sr:10_ws:4_u1:8_u2:3_cols:1units:8.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5283 - val_loss: 0.5375\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.50955\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5270 - val_loss: 0.5287\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.50955\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5269 - val_loss: 0.5311\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.50955\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5243 - val_loss: 0.5173\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.50955\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5230 - val_loss: 0.5204\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.50955\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 33439... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▄▂▄▄▁▅▄▄▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.50955</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>loss</td><td>0.523</td></tr><tr><td>val_loss</td><td>0.52037</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">zany-sweep-30</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/4ck01gig\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/4ck01gig</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_164155-4ck01gig/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ooerozs4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ooerozs4\" target=\"_blank\">visionary-sweep-31</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 63060... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">visionary-sweep-31</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ooerozs4\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/ooerozs4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_165105-ooerozs4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ooerozs4 errored: ValueError('Negative dimension size caused by subtracting 6 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,9], [1,6,9,8].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2gz0ll10 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2gz0ll10\" target=\"_blank\">woven-sweep-32</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 10, 8)             128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 164       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "=================================================================\n",
      "Total params: 352\n",
      "Trainable params: 352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.9292 - val_loss: 0.8694\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86937, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8676 - val_loss: 0.8573\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86937 to 0.85727, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8547 - val_loss: 0.8593\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.85727\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8493 - val_loss: 0.8493\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.85727 to 0.84928, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8444 - val_loss: 0.8459\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.84928 to 0.84590, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8281 - val_loss: 0.8100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.84590 to 0.80997, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7836 - val_loss: 0.7347\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.80997 to 0.73468, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7376 - val_loss: 0.6793\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.73468 to 0.67932, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6971 - val_loss: 0.6334\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.67932 to 0.63340, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6669 - val_loss: 0.5978\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.63340 to 0.59785, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6418 - val_loss: 0.5792\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.59785 to 0.57924, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6263 - val_loss: 0.5607\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.57924 to 0.56070, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6164 - val_loss: 0.5528\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.56070 to 0.55276, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6099 - val_loss: 0.5387\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55276 to 0.53873, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.6047 - val_loss: 0.5463\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.53873\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6042 - val_loss: 0.5466\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.53873\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.6009 - val_loss: 0.5354\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.53873 to 0.53539, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5983 - val_loss: 0.5346\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.53539 to 0.53457, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5947 - val_loss: 0.5398\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.53457\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5949 - val_loss: 0.5376\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.53457\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5907 - val_loss: 0.5303\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.53457 to 0.53035, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5915 - val_loss: 0.5325\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.53035\n",
      "Epoch 23/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5879 - val_loss: 0.5294\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.53035 to 0.52942, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 24/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5861 - val_loss: 0.5404\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.52942\n",
      "Epoch 25/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5859 - val_loss: 0.5291\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.52942 to 0.52907, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 26/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5844 - val_loss: 0.5257\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.52907 to 0.52573, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 27/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5841 - val_loss: 0.5284\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.52573\n",
      "Epoch 28/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5821 - val_loss: 0.5261\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.52573\n",
      "Epoch 29/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5802 - val_loss: 0.5349\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.52573\n",
      "Epoch 30/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5806 - val_loss: 0.5297\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.52573\n",
      "Epoch 31/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5786 - val_loss: 0.5116\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.52573 to 0.51158, saving model to MLP_l:0.0001_sr:10_ws:12_u1:8_u2:3_cols:4units:4.h5\n",
      "Epoch 32/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5793 - val_loss: 0.5302\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.51158\n",
      "Epoch 33/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5779 - val_loss: 0.5287\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.51158\n",
      "Epoch 34/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5760 - val_loss: 0.5200\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.51158\n",
      "Epoch 35/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5740 - val_loss: 0.5161\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.51158\n",
      "Epoch 36/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5728 - val_loss: 0.5222\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.51158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 63112... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▇▆▆▆▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█████▇▅▄▃▃▂▂▂▂▂▂▁▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>30</td></tr><tr><td>best_val_loss</td><td>0.51158</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>loss</td><td>0.57278</td></tr><tr><td>val_loss</td><td>0.52224</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">woven-sweep-32</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2gz0ll10\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/2gz0ll10</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_165206-2gz0ll10/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: egi9b9sa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/egi9b9sa\" target=\"_blank\">firm-sweep-33</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 32)             1760      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "=================================================================\n",
      "Total params: 2,388\n",
      "Trainable params: 2,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 3.1149 - val_loss: 0.8151\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81508, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8211 - val_loss: 0.8138\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81508 to 0.81384, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8130 - val_loss: 0.8124\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81384 to 0.81245, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8127 - val_loss: 0.8123\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81245 to 0.81231, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.8121 - val_loss: 0.8168\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.81231\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8113 - val_loss: 0.8161\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.81231\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8108 - val_loss: 0.8081\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.81231 to 0.80810, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8105 - val_loss: 0.8193\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80810\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8101 - val_loss: 0.8045\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.80810 to 0.80447, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8091 - val_loss: 0.8074\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80447\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8085 - val_loss: 0.8140\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80447\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.8076 - val_loss: 0.8045\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80447\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8064 - val_loss: 0.8042\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.80447 to 0.80415, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8061 - val_loss: 0.8120\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80415\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8053 - val_loss: 0.8020\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.80415 to 0.80201, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.8048 - val_loss: 0.8166\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.80201\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.8037 - val_loss: 0.8052\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.80201\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.8018 - val_loss: 0.8008\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.80201 to 0.80078, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 19/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.7755 - val_loss: 0.6968\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.80078 to 0.69678, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 20/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.7167 - val_loss: 0.6651\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.69678 to 0.66509, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 21/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.7011 - val_loss: 0.6551\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.66509 to 0.65511, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 22/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.6825 - val_loss: 0.6242\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.65511 to 0.62424, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 23/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6751 - val_loss: 0.6235\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.62424 to 0.62352, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 24/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6614 - val_loss: 0.5951\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.62352 to 0.59515, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 25/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.6598 - val_loss: 0.6177\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.59515\n",
      "Epoch 26/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6462 - val_loss: 0.5673\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.59515 to 0.56735, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 27/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.6284 - val_loss: 0.6562\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.56735\n",
      "Epoch 28/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6006 - val_loss: 0.4978\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.56735 to 0.49781, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:0units:8.h5\n",
      "Epoch 29/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5857 - val_loss: 0.5132\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.49781\n",
      "Epoch 30/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5840 - val_loss: 0.5242\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.49781\n",
      "Epoch 31/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5808 - val_loss: 0.5056\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.49781\n",
      "Epoch 32/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5654 - val_loss: 0.4993\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.49781\n",
      "Epoch 33/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5597 - val_loss: 0.5168\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.49781\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 43432... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██████████████████▅▅▄▄▄▃▄▃▄▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>27</td></tr><tr><td>best_val_loss</td><td>0.49781</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>loss</td><td>0.55973</td></tr><tr><td>val_loss</td><td>0.51681</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">firm-sweep-33</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/egi9b9sa\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/egi9b9sa</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_171417-egi9b9sa/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5472vuad with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/5472vuad\" target=\"_blank\">solar-sweep-34</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 7, 64)             6976      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 193       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 7,193\n",
      "Trainable params: 7,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 2.1141 - val_loss: 0.8652\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86515, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8800 - val_loss: 0.8611\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86515 to 0.86105, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8604 - val_loss: 0.8596\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.86105 to 0.85955, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8508 - val_loss: 0.8543\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.85955 to 0.85429, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.8475 - val_loss: 0.8524\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.85429 to 0.85236, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8455 - val_loss: 0.8540\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.85236\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.8436 - val_loss: 0.8471\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85236 to 0.84709, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.8425 - val_loss: 0.8539\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.84709\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8419 - val_loss: 0.8451\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.84709 to 0.84512, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8410 - val_loss: 0.8528\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.84512\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8404 - val_loss: 0.8365\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.84512 to 0.83652, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8401 - val_loss: 0.8483\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.83652\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.8397 - val_loss: 0.8450\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.83652\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.8395 - val_loss: 0.8573\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.83652\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8394 - val_loss: 0.8319\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.83652 to 0.83192, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:6_cols:0units:1.h5\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8393 - val_loss: 0.8435\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.83192\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8395 - val_loss: 0.8635\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.83192\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8391 - val_loss: 0.8346\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.83192\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8391 - val_loss: 0.8493\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.83192\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.8390 - val_loss: 0.8451\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.83192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 78918... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.12MB of 0.12MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▅▆▄▆▄▅▂▄▄▆▁▃█▂▅▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.83192</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.83905</td></tr><tr><td>val_loss</td><td>0.84514</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">solar-sweep-34</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/5472vuad\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/5472vuad</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_173608-5472vuad/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wkxaunmo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/wkxaunmo\" target=\"_blank\">peachy-sweep-35</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 16)             256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 297\n",
      "Trainable params: 297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6808 - val_loss: 0.6167\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61674, saving model to MLP_l:0.01_sr:10_ws:4_u1:16_u2:3_cols:4units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6610 - val_loss: 0.5979\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61674 to 0.59789, saving model to MLP_l:0.01_sr:10_ws:4_u1:16_u2:3_cols:4units:1.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.6581 - val_loss: 0.6138\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59789\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.6593 - val_loss: 0.6123\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59789\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 39s 29ms/step - loss: 0.6578 - val_loss: 0.5858\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59789 to 0.58581, saving model to MLP_l:0.01_sr:10_ws:4_u1:16_u2:3_cols:4units:1.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6609 - val_loss: 0.5918\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.58581\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.6575 - val_loss: 0.5907\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.58581\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.6566 - val_loss: 0.6036\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.58581\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.6522 - val_loss: 0.5862\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.58581\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6499 - val_loss: 0.5809\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.58581 to 0.58093, saving model to MLP_l:0.01_sr:10_ws:4_u1:16_u2:3_cols:4units:1.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6504 - val_loss: 0.5872\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.58093\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6502 - val_loss: 0.5783\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58093 to 0.57825, saving model to MLP_l:0.01_sr:10_ws:4_u1:16_u2:3_cols:4units:1.h5\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6499 - val_loss: 0.6052\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57825\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6481 - val_loss: 0.5762\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.57825 to 0.57621, saving model to MLP_l:0.01_sr:10_ws:4_u1:16_u2:3_cols:4units:1.h5\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6508 - val_loss: 0.5639\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.57621 to 0.56388, saving model to MLP_l:0.01_sr:10_ws:4_u1:16_u2:3_cols:4units:1.h5\n",
      "Epoch 16/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6530 - val_loss: 0.5770\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.56388\n",
      "Epoch 17/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6524 - val_loss: 0.5849\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.56388\n",
      "Epoch 18/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6502 - val_loss: 0.5757\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.56388\n",
      "Epoch 19/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6470 - val_loss: 0.5788\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.56388\n",
      "Epoch 20/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6501 - val_loss: 0.5956\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.56388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4420... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▃▄▃▄▃▃▂▂▂▂▂▁▂▂▂▂▁▂</td></tr><tr><td>val_loss</td><td>█▆█▇▄▅▅▆▄▃▄▃▆▃▁▃▄▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.56388</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.65014</td></tr><tr><td>val_loss</td><td>0.59563</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">peachy-sweep-35</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/wkxaunmo\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/wkxaunmo</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_174902-wkxaunmo/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e92dxz5c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/e92dxz5c\" target=\"_blank\">pretty-sweep-36</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11711... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">pretty-sweep-36</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/e92dxz5c\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/e92dxz5c</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_180256-e92dxz5c/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run e92dxz5c errored: ValueError('Negative dimension size caused by subtracting 6 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,5], [1,6,5,16].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qgya4q0a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/qgya4q0a\" target=\"_blank\">dashing-sweep-37</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3, 32)             352       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "=================================================================\n",
      "Total params: 724\n",
      "Trainable params: 724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5589 - val_loss: 0.4859\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48592, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:2_cols:4units:8.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5306 - val_loss: 0.4693\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48592 to 0.46926, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:2_cols:4units:8.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5274 - val_loss: 0.4701\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.46926\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.5223 - val_loss: 0.4745\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46926\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5240 - val_loss: 0.4540\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.46926 to 0.45399, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:2_cols:4units:8.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.5192 - val_loss: 0.4957\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45399\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5199 - val_loss: 0.5016\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45399\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5196 - val_loss: 0.4291\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.45399 to 0.42912, saving model to MLP_l:0.01_sr:10_ws:4_u1:32_u2:2_cols:4units:8.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.5167 - val_loss: 0.4654\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42912\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 39s 29ms/step - loss: 0.5154 - val_loss: 0.5391\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42912\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5207 - val_loss: 0.4613\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42912\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5022 - val_loss: 0.4822\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.42912\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.4986 - val_loss: 0.4571\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42912\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11753... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▅▄▄▄▃▃▃▃▃▄▁▁</td></tr><tr><td>val_loss</td><td>▅▄▄▄▃▅▆▁▃█▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.42912</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>loss</td><td>0.49862</td></tr><tr><td>val_loss</td><td>0.45708</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dashing-sweep-37</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/qgya4q0a\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/qgya4q0a</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_180358-qgya4q0a/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ghk60rco with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ghk60rco\" target=\"_blank\">peachy-sweep-38</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 40486... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">peachy-sweep-38</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ghk60rco\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/ghk60rco</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_181254-ghk60rco/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ghk60rco errored: ValueError('Negative dimension size caused by subtracting 5 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,9], [1,5,9,8].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0qkgvz8l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/0qkgvz8l\" target=\"_blank\">swift-sweep-39</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 32)             896       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 3,372\n",
      "Trainable params: 3,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.5556 - val_loss: 0.3988\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39876, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:2units:32.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.4456 - val_loss: 0.3730\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39876 to 0.37297, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:2units:32.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4268 - val_loss: 0.3758\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37297\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4173 - val_loss: 0.3575\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37297 to 0.35755, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:2units:32.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4133 - val_loss: 0.3753\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35755\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.4093 - val_loss: 0.3672\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35755\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4075 - val_loss: 0.3858\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35755\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.4010 - val_loss: 0.3635\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35755\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.3988 - val_loss: 0.3617\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 40536... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.07MB of 0.07MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▄▁▄▃▆▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.35755</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>loss</td><td>0.39876</td></tr><tr><td>val_loss</td><td>0.36169</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">swift-sweep-39</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/0qkgvz8l\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/0qkgvz8l</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_181357-0qkgvz8l/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ggrq138a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ggrq138a\" target=\"_blank\">warm-sweep-40</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 7, 16)             688       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 2,652\n",
      "Trainable params: 2,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.6137 - val_loss: 0.4731\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47313, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5058 - val_loss: 0.4558\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.47313 to 0.45585, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4822 - val_loss: 0.4769\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45585\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4747 - val_loss: 0.4406\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45585 to 0.44062, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.4630 - val_loss: 0.4428\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44062\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.4565 - val_loss: 0.4329\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44062 to 0.43291, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4531 - val_loss: 0.4113\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43291 to 0.41128, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4474 - val_loss: 0.4186\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41128\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4478 - val_loss: 0.4109\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41128 to 0.41090, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4462 - val_loss: 0.4056\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.41090 to 0.40563, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4431 - val_loss: 0.3991\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.40563 to 0.39913, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:6_cols:3units:32.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.4420 - val_loss: 0.4117\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.39913\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4420 - val_loss: 0.4388\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.39913\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.4409 - val_loss: 0.4238\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.39913\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4356 - val_loss: 0.4132\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.39913\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4327 - val_loss: 0.4087\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.39913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35580... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.07MB of 0.07MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆█▅▅▄▂▃▂▂▁▂▅▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.39913</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>loss</td><td>0.43269</td></tr><tr><td>val_loss</td><td>0.40872</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">warm-sweep-40</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/ggrq138a\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/ggrq138a</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_182014-ggrq138a/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5bahwg7a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/5bahwg7a\" target=\"_blank\">charmed-sweep-41</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8625... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">charmed-sweep-41</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/5bahwg7a\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/5bahwg7a</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_183106-5bahwg7a/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5bahwg7a errored: ValueError('Negative dimension size caused by subtracting 6 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,5], [1,6,5,64].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5d40cimf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/5d40cimf\" target=\"_blank\">crimson-sweep-42</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8749... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">crimson-sweep-42</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/5d40cimf\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/5d40cimf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_183213-5d40cimf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5d40cimf errored: ValueError('Negative dimension size caused by subtracting 6 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,7], [1,6,7,64].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pzfa7yse with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/pzfa7yse\" target=\"_blank\">faithful-sweep-43</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 64)             2752      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 2,841\n",
      "Trainable params: 2,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6589 - val_loss: 0.5933\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59327, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:1units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6277 - val_loss: 0.5518\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59327 to 0.55177, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:1units:1.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6289 - val_loss: 0.6336\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.55177\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6243 - val_loss: 0.5847\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.55177\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6243 - val_loss: 0.5574\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.55177\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6165 - val_loss: 0.5605\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55177\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6103 - val_loss: 0.5625\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.55177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8805... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.07MB of 0.07MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>loss</td><td>█▄▄▃▃▂▁</td></tr><tr><td>val_loss</td><td>▅▁█▄▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.55177</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>0.61028</td></tr><tr><td>val_loss</td><td>0.5625</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">faithful-sweep-43</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/pzfa7yse\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/pzfa7yse</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_183304-pzfa7yse/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gmcfbylq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/gmcfbylq\" target=\"_blank\">jumping-sweep-44</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 16)             352       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 1,084\n",
      "Trainable params: 1,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5470 - val_loss: 0.4232\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42315, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.5086 - val_loss: 0.4261\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.42315\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5152 - val_loss: 0.4708\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.42315\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5119 - val_loss: 0.4650\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42315\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4839 - val_loss: 0.3983\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42315 to 0.39829, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4794 - val_loss: 0.4212\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.39829\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4754 - val_loss: 0.4124\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.39829\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4725 - val_loss: 0.4131\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.39829\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4602 - val_loss: 0.3889\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39829 to 0.38886, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4565 - val_loss: 0.3967\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38886\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4576 - val_loss: 0.3978\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38886\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4545 - val_loss: 0.3737\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.38886 to 0.37374, saving model to MLP_l:0.01_sr:10_ws:6_u1:16_u2:3_cols:3units:16.h5\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4550 - val_loss: 0.3827\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.37374\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4532 - val_loss: 0.4010\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.37374\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4546 - val_loss: 0.4087\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.37374\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4482 - val_loss: 0.3871\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37374\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 39s 30ms/step - loss: 0.4479 - val_loss: 0.3896\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 67806... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>loss</td><td>█▅▆▆▄▃▃▃▂▂▂▁▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>▅▅██▃▄▄▄▂▃▃▁▂▃▄▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.37374</td></tr><tr><td>epoch</td><td>16</td></tr><tr><td>loss</td><td>0.44788</td></tr><tr><td>val_loss</td><td>0.38959</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">jumping-sweep-44</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/gmcfbylq\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/gmcfbylq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_183828-gmcfbylq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 03cxq72s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/03cxq72s\" target=\"_blank\">snowy-sweep-45</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 32)             1376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 1,465\n",
      "Trainable params: 1,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.7600 - val_loss: 0.6501\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65012, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:1units:1.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6731 - val_loss: 0.6076\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65012 to 0.60761, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:1units:1.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6563 - val_loss: 0.5838\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60761 to 0.58378, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:1units:1.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6499 - val_loss: 0.5738\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58378 to 0.57381, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:1units:1.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6462 - val_loss: 0.5783\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.57381\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 35s 27ms/step - loss: 0.6440 - val_loss: 0.5915\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.57381\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6395 - val_loss: 0.5734\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.57381 to 0.57343, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:1units:1.h5\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6404 - val_loss: 0.5914\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57343\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6408 - val_loss: 0.5793\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.57343\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 35s 27ms/step - loss: 0.6394 - val_loss: 0.5798\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57343\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.6337 - val_loss: 0.5759\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.57343\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 35s 27ms/step - loss: 0.6374 - val_loss: 0.5866\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.57343\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 49381... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▃▁▃▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.57343</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.63736</td></tr><tr><td>val_loss</td><td>0.58656</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">snowy-sweep-45</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/03cxq72s\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/03cxq72s</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_185018-03cxq72s/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mhlkpw9y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/mhlkpw9y\" target=\"_blank\">winter-sweep-46</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 69574... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">winter-sweep-46</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/mhlkpw9y\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/mhlkpw9y</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_185818-mhlkpw9y/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run mhlkpw9y errored: ValueError('Negative dimension size caused by subtracting 2 from 1 for \\'{{node max_pooling1d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d/ExpandDims)\\' with input shapes: [?,1,1,8].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vwu2qac4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/vwu2qac4\" target=\"_blank\">silver-sweep-47</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3, 8)              88        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 436\n",
      "Trainable params: 436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8674 - val_loss: 0.8050\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80500, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.8005 - val_loss: 0.7739\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80500 to 0.77391, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.7616 - val_loss: 0.7337\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77391 to 0.73369, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.7328 - val_loss: 0.7072\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73369 to 0.70725, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.7078 - val_loss: 0.6826\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.70725 to 0.68255, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6773 - val_loss: 0.6361\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68255 to 0.63615, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6347 - val_loss: 0.5968\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.63615 to 0.59683, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6087 - val_loss: 0.5767\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59683 to 0.57667, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5966 - val_loss: 0.5698\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.57667 to 0.56977, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5875 - val_loss: 0.5674\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56977 to 0.56744, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5807 - val_loss: 0.5669\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.56744 to 0.56693, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5743 - val_loss: 0.5674\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.56693\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5697 - val_loss: 0.5636\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.56693 to 0.56363, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5662 - val_loss: 0.5631\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.56363 to 0.56307, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5621 - val_loss: 0.5626\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.56307 to 0.56265, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 16/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.5589 - val_loss: 0.5671\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.56265\n",
      "Epoch 17/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5565 - val_loss: 0.5581\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.56265 to 0.55808, saving model to MLP_l:0.0001_sr:10_ws:4_u1:8_u2:2_cols:4units:16.h5\n",
      "Epoch 18/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5542 - val_loss: 0.5661\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.55808\n",
      "Epoch 19/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5516 - val_loss: 0.5696\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.55808\n",
      "Epoch 20/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5513 - val_loss: 0.5816\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.55808\n",
      "Epoch 21/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.5502 - val_loss: 0.5698\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.55808\n",
      "Epoch 22/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.5482 - val_loss: 0.5630\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.55808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 69637... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▇▆▅▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_loss</td><td>0.55808</td></tr><tr><td>epoch</td><td>21</td></tr><tr><td>loss</td><td>0.54823</td></tr><tr><td>val_loss</td><td>0.56296</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">silver-sweep-47</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/vwu2qac4\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/vwu2qac4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_185926-vwu2qac4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hoeop26p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/hoeop26p\" target=\"_blank\">hearty-sweep-48</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3, 8)              168       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 852\n",
      "Trainable params: 852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.5576 - val_loss: 0.5625\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56248, saving model to MLP_l:0.01_sr:10_ws:6_u1:8_u2:4_cols:4units:32.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 35s 27ms/step - loss: 0.5410 - val_loss: 0.5381\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56248 to 0.53809, saving model to MLP_l:0.01_sr:10_ws:6_u1:8_u2:4_cols:4units:32.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.5404 - val_loss: 0.5501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53809\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.5352 - val_loss: 0.5196\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.53809 to 0.51959, saving model to MLP_l:0.01_sr:10_ws:6_u1:8_u2:4_cols:4units:32.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.5350 - val_loss: 0.5299\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51959\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.5361 - val_loss: 0.5385\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51959\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5409 - val_loss: 0.5930\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.51959\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5209 - val_loss: 0.5569\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51959\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 35s 26ms/step - loss: 0.5128 - val_loss: 0.5314\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.51959\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12320... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>loss</td><td>█▅▅▅▄▅▅▂▁</td></tr><tr><td>val_loss</td><td>▅▃▄▁▂▃█▅▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.51959</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>loss</td><td>0.51278</td></tr><tr><td>val_loss</td><td>0.5314</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">hearty-sweep-48</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/hoeop26p\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/hoeop26p</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_191338-hoeop26p/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6lw1zhcg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/6lw1zhcg\" target=\"_blank\">smooth-sweep-49</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 11, 16)            240       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2592      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 3,228\n",
      "Trainable params: 3,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.5693 - val_loss: 0.4587\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45870, saving model to MLP_l:0.01_sr:10_ws:12_u1:16_u2:2_cols:3units:32.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.5373 - val_loss: 0.4600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45870\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5227 - val_loss: 0.4832\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45870\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5301 - val_loss: 0.4610\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45870\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4918 - val_loss: 0.4349\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.45870 to 0.43488, saving model to MLP_l:0.01_sr:10_ws:12_u1:16_u2:2_cols:3units:32.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4886 - val_loss: 0.4294\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43488 to 0.42942, saving model to MLP_l:0.01_sr:10_ws:12_u1:16_u2:2_cols:3units:32.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4865 - val_loss: 0.4879\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42942\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4866 - val_loss: 0.4260\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42942 to 0.42596, saving model to MLP_l:0.01_sr:10_ws:12_u1:16_u2:2_cols:3units:32.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4791 - val_loss: 0.4317\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42596\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4806 - val_loss: 0.4574\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42596\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4777 - val_loss: 0.4320\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42596\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4671 - val_loss: 0.4190\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42596 to 0.41905, saving model to MLP_l:0.01_sr:10_ws:12_u1:16_u2:2_cols:3units:32.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4625 - val_loss: 0.4294\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.41905\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4612 - val_loss: 0.4192\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.41905\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.4597 - val_loss: 0.4270\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.41905\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4544 - val_loss: 0.4241\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.41905\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4527 - val_loss: 0.3945\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.41905 to 0.39452, saving model to MLP_l:0.01_sr:10_ws:12_u1:16_u2:2_cols:3units:32.h5\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4530 - val_loss: 0.4262\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.39452\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4504 - val_loss: 0.4175\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.39452\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4507 - val_loss: 0.4244\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.39452\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4461 - val_loss: 0.4034\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.39452\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.4456 - val_loss: 0.3962\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.39452\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7385... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.07MB of 0.07MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▆▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆▆█▆▄▄█▃▄▆▄▃▄▃▃▃▁▃▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_loss</td><td>0.39452</td></tr><tr><td>epoch</td><td>21</td></tr><tr><td>loss</td><td>0.44562</td></tr><tr><td>val_loss</td><td>0.39619</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">smooth-sweep-49</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/6lw1zhcg\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/6lw1zhcg</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_192000-6lw1zhcg/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7dlq1xci with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/7dlq1xci\" target=\"_blank\">golden-sweep-50</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 9, 16)             592       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.8176 - val_loss: 0.6934\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69337, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7073 - val_loss: 0.6583\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69337 to 0.65825, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6782 - val_loss: 0.6365\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65825 to 0.63653, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6687 - val_loss: 0.6071\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63653 to 0.60713, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6652 - val_loss: 0.6099\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.60713\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6604 - val_loss: 0.6106\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.60713\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6594 - val_loss: 0.6145\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.60713\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6536 - val_loss: 0.6059\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.60713 to 0.60595, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.6545 - val_loss: 0.5980\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60595 to 0.59801, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6525 - val_loss: 0.6082\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59801\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6536 - val_loss: 0.6146\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59801\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6513 - val_loss: 0.5975\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.59801 to 0.59747, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6514 - val_loss: 0.6031\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59747\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6474 - val_loss: 0.5956\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.59747 to 0.59559, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6476 - val_loss: 0.5892\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.59559 to 0.58915, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:4_cols:2units:1.h5\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6510 - val_loss: 0.6060\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.58915\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6505 - val_loss: 0.5945\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.58915\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6497 - val_loss: 0.5927\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.58915\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6473 - val_loss: 0.6058\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.58915\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.6475 - val_loss: 0.5911\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.58915\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31078... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▂▂▂▃▂▂▂▃▂▂▁▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.58915</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.64752</td></tr><tr><td>val_loss</td><td>0.59108</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">golden-sweep-50</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/7dlq1xci\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/7dlq1xci</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_193422-7dlq1xci/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3s9o2bhn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/3s9o2bhn\" target=\"_blank\">brisk-sweep-51</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 37766... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">brisk-sweep-51</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/3s9o2bhn\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/3s9o2bhn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_194650-3s9o2bhn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 3s9o2bhn errored: ValueError('Negative dimension size caused by subtracting 5 from 4 for \\'{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)\\' with input shapes: [?,1,4,7], [1,5,7,16].')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xaady2a0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/xaady2a0\" target=\"_blank\">leafy-sweep-52</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 10, 16)            688       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 324       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "=================================================================\n",
      "Total params: 1,072\n",
      "Trainable params: 1,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.9521 - val_loss: 0.8595\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.85949, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.8551 - val_loss: 0.8386\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.85949 to 0.83858, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.8209 - val_loss: 0.7936\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.83858 to 0.79355, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7893 - val_loss: 0.7501\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.79355 to 0.75011, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.7511 - val_loss: 0.6906\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75011 to 0.69063, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.7108 - val_loss: 0.6443\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69063 to 0.64432, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 35s 29ms/step - loss: 0.6741 - val_loss: 0.5985\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.64432 to 0.59853, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6449 - val_loss: 0.5699\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59853 to 0.56994, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.6224 - val_loss: 0.5427\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56994 to 0.54266, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6093 - val_loss: 0.5482\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54266\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.6033 - val_loss: 0.5317\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54266 to 0.53170, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5926 - val_loss: 0.5285\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.53170 to 0.52847, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5911 - val_loss: 0.5333\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.52847\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5862 - val_loss: 0.5170\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52847 to 0.51699, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5831 - val_loss: 0.5233\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.51699\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 36s 30ms/step - loss: 0.5793 - val_loss: 0.5191\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51699\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5766 - val_loss: 0.5156\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.51699 to 0.51558, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5728 - val_loss: 0.5220\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51558\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5711 - val_loss: 0.5073\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51558 to 0.50734, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5645 - val_loss: 0.5088\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50734\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5636 - val_loss: 0.5154\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.50734\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5591 - val_loss: 0.4943\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.50734 to 0.49427, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 23/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5580 - val_loss: 0.4942\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.49427 to 0.49421, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 24/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5558 - val_loss: 0.5101\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.49421\n",
      "Epoch 25/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5531 - val_loss: 0.4913\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.49421 to 0.49132, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 26/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5509 - val_loss: 0.4701\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.49132 to 0.47006, saving model to MLP_l:0.0001_sr:10_ws:12_u1:16_u2:3_cols:1units:4.h5\n",
      "Epoch 27/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5448 - val_loss: 0.4851\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.47006\n",
      "Epoch 28/55\n",
      "1173/1173 [==============================] - 35s 30ms/step - loss: 0.5428 - val_loss: 0.4790\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.47006\n",
      "Epoch 29/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5421 - val_loss: 0.4808\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.47006\n",
      "Epoch 30/55\n",
      "1173/1173 [==============================] - 35s 29ms/step - loss: 0.5361 - val_loss: 0.4731\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.47006\n",
      "Epoch 31/55\n",
      "1173/1173 [==============================] - 34s 29ms/step - loss: 0.5403 - val_loss: 0.4792\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.47006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 37805... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▆▅▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▆▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>25</td></tr><tr><td>best_val_loss</td><td>0.47006</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>loss</td><td>0.54025</td></tr><tr><td>val_loss</td><td>0.47921</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">leafy-sweep-52</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/xaady2a0\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/xaady2a0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_194741-xaady2a0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wdezyabd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/wdezyabd\" target=\"_blank\">wise-sweep-53</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3, 16)             240       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 281\n",
      "Trainable params: 281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 37s 26ms/step - loss: 0.8153 - val_loss: 0.8138\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81383, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.8077 - val_loss: 0.8040\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81383 to 0.80399, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.7978 - val_loss: 0.7893\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80399 to 0.78929, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.7862 - val_loss: 0.7682\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.78929 to 0.76824, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.7711 - val_loss: 0.7517\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.76824 to 0.75171, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.7546 - val_loss: 0.7239\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.75171 to 0.72391, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.7389 - val_loss: 0.7093\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72391 to 0.70930, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.7254 - val_loss: 0.6842\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.70930 to 0.68423, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.7163 - val_loss: 0.6859\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68423\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.7090 - val_loss: 0.6689\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.68423 to 0.66890, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.7013 - val_loss: 0.6586\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.66890 to 0.65864, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6970 - val_loss: 0.6608\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.65864\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6922 - val_loss: 0.6558\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.65864 to 0.65581, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 14/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6870 - val_loss: 0.6446\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.65581 to 0.64460, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 15/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.6862 - val_loss: 0.6411\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.64460 to 0.64111, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 16/55\n",
      "1379/1379 [==============================] - 37s 27ms/step - loss: 0.6847 - val_loss: 0.6425\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.64111\n",
      "Epoch 17/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6805 - val_loss: 0.6302\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.64111 to 0.63017, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 18/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6776 - val_loss: 0.6388\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.63017\n",
      "Epoch 19/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6756 - val_loss: 0.6317\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.63017\n",
      "Epoch 20/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6757 - val_loss: 0.6216\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.63017 to 0.62163, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 21/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6733 - val_loss: 0.6247\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.62163\n",
      "Epoch 22/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.6714 - val_loss: 0.6275\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.62163\n",
      "Epoch 23/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6701 - val_loss: 0.6152\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.62163 to 0.61525, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 24/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6688 - val_loss: 0.6218\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.61525\n",
      "Epoch 25/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6675 - val_loss: 0.6230\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.61525\n",
      "Epoch 26/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6671 - val_loss: 0.6035\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.61525 to 0.60354, saving model to MLP_l:0.0001_sr:10_ws:4_u1:16_u2:2_cols:3units:1.h5\n",
      "Epoch 27/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6657 - val_loss: 0.6187\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.60354\n",
      "Epoch 28/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6632 - val_loss: 0.6134\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.60354\n",
      "Epoch 29/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6630 - val_loss: 0.6189\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.60354\n",
      "Epoch 30/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6619 - val_loss: 0.6037\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.60354\n",
      "Epoch 31/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6620 - val_loss: 0.6163\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.60354\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 56782... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>██▇▇▆▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>25</td></tr><tr><td>best_val_loss</td><td>0.60354</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>loss</td><td>0.662</td></tr><tr><td>val_loss</td><td>0.61628</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">wise-sweep-53</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/wdezyabd\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/wdezyabd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_200706-wdezyabd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dka09734 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/dka09734\" target=\"_blank\">denim-sweep-54</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 64)             1408      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 1,497\n",
      "Trainable params: 1,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6454 - val_loss: 0.5937\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59372, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:3units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6178 - val_loss: 0.5444\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59372 to 0.54444, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:3units:1.h5\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6141 - val_loss: 0.5271\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54444 to 0.52708, saving model to MLP_l:0.01_sr:10_ws:4_u1:64_u2:3_cols:3units:1.h5\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6118 - val_loss: 0.5681\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.52708\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6137 - val_loss: 0.5736\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52708\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6131 - val_loss: 0.5698\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52708\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 38s 28ms/step - loss: 0.6052 - val_loss: 0.5673\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.52708\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.6025 - val_loss: 0.5379\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.52708\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 75316... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>loss</td><td>█▃▃▃▃▃▁▁</td></tr><tr><td>val_loss</td><td>█▃▁▅▆▅▅▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.52708</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>0.60246</td></tr><tr><td>val_loss</td><td>0.53793</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">denim-sweep-54</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/dka09734\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/dka09734</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_202713-dka09734/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u46m6fta with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/u46m6fta\" target=\"_blank\">classic-sweep-55</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 10, 16)            352       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 648       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "=================================================================\n",
      "Total params: 1,108\n",
      "Trainable params: 1,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.7586 - val_loss: 0.5294\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52940, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5562 - val_loss: 0.4965\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52940 to 0.49646, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5388 - val_loss: 0.4525\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.49646 to 0.45245, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5193 - val_loss: 0.4569\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45245\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.5116 - val_loss: 0.4547\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45245\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.5053 - val_loss: 0.4375\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45245 to 0.43745, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4981 - val_loss: 0.4353\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43745 to 0.43532, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4936 - val_loss: 0.4247\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.43532 to 0.42473, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 0.4870 - val_loss: 0.4301\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42473\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.4824 - val_loss: 0.4392\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42473\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 0.4826 - val_loss: 0.4425\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42473\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4787 - val_loss: 0.4234\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42473 to 0.42343, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4780 - val_loss: 0.4190\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.42343 to 0.41901, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4775 - val_loss: 0.4071\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.41901 to 0.40714, saving model to MLP_l:0.001_sr:10_ws:12_u1:16_u2:3_cols:3units:8.h5\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4765 - val_loss: 0.4169\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.40714\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4756 - val_loss: 0.4289\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.40714\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4748 - val_loss: 0.4247\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.40714\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 37s 31ms/step - loss: 0.4741 - val_loss: 0.4167\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.40714\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 36s 31ms/step - loss: 0.4717 - val_loss: 0.4289\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.40714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 61867... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▄▄▃▃▂▂▃▃▂▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.40714</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>loss</td><td>0.47168</td></tr><tr><td>val_loss</td><td>0.42888</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">classic-sweep-55</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/u46m6fta\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/u46m6fta</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_203315-u46m6fta/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6xrxcfwx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/6xrxcfwx\" target=\"_blank\">playful-sweep-56</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             1472      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 2,204\n",
      "Trainable params: 2,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5945 - val_loss: 0.4325\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43254, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:16.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4864 - val_loss: 0.3983\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43254 to 0.39831, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:16.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4670 - val_loss: 0.3904\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39831 to 0.39041, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:16.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4596 - val_loss: 0.3934\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39041\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4539 - val_loss: 0.3997\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.39041\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4505 - val_loss: 0.3826\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39041 to 0.38258, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:16.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.4479 - val_loss: 0.3875\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38258\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.4470 - val_loss: 0.3741\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38258 to 0.37414, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:16.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4458 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.37414 to 0.37253, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:16.h5\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4444 - val_loss: 0.3823\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37253\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.4415 - val_loss: 0.3829\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.37253\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4422 - val_loss: 0.3979\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.37253\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4370 - val_loss: 0.3542\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.37253 to 0.35421, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:5_cols:2units:16.h5\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4355 - val_loss: 0.3751\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.35421\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 38s 28ms/step - loss: 0.4350 - val_loss: 0.3566\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.35421\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.4346 - val_loss: 0.3602\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.35421\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4321 - val_loss: 0.3817\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.35421\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4320 - val_loss: 0.3716\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.35421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 60151... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▅▅▄▄▃▃▄▄▅▁▃▁▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>0.35421</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>loss</td><td>0.43203</td></tr><tr><td>val_loss</td><td>0.37159</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">playful-sweep-56</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/6xrxcfwx\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/6xrxcfwx</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_204607-6xrxcfwx/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d3wim140 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/d3wim140\" target=\"_blank\">legendary-sweep-57</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 16)             416       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,356\n",
      "Trainable params: 1,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 40s 29ms/step - loss: 0.5842 - val_loss: 0.4511\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45110, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:5_cols:4units:32.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4737 - val_loss: 0.4662\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45110\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.4553 - val_loss: 0.4681\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45110\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4476 - val_loss: 0.4960\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45110\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4416 - val_loss: 0.4744\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45110\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 39s 30ms/step - loss: 0.4383 - val_loss: 0.4791\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 50042... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▃▂▁▁▁</td></tr><tr><td>val_loss</td><td>▁▃▄█▅▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.4511</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.43834</td></tr><tr><td>val_loss</td><td>0.47908</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">legendary-sweep-57</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/d3wim140\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/d3wim140</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_205831-d3wim140/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2qoa940f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2qoa940f\" target=\"_blank\">ancient-sweep-58</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 10, 32)            1760      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                5152      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 7,308\n",
      "Trainable params: 7,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 23.8500 - val_loss: 0.8700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86996, saving model to MLP_l:0.0001_sr:10_ws:12_u1:32_u2:3_cols:0units:32.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 1.6184 - val_loss: 0.8580\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86996 to 0.85802, saving model to MLP_l:0.0001_sr:10_ws:12_u1:32_u2:3_cols:0units:32.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 1.0075 - val_loss: 0.8593\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.85802\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.9084 - val_loss: 0.8457\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.85802 to 0.84567, saving model to MLP_l:0.0001_sr:10_ws:12_u1:32_u2:3_cols:0units:32.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.8741 - val_loss: 0.8578\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.84567\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.8621 - val_loss: 0.8418\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.84567 to 0.84180, saving model to MLP_l:0.0001_sr:10_ws:12_u1:32_u2:3_cols:0units:32.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.8526 - val_loss: 0.8485\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.84180\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.8476 - val_loss: 0.8549\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.84180\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 38s 33ms/step - loss: 0.8446 - val_loss: 0.8438\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.84180\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.8444 - val_loss: 0.8515\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.84180\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8428 - val_loss: 0.8466\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.84180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19752... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.12MB of 0.12MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▅▂▅▁▃▄▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.8418</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.84279</td></tr><tr><td>val_loss</td><td>0.84657</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">ancient-sweep-58</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/2qoa940f\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/2qoa940f</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_210317-2qoa940f/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: doh3sd73 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/doh3sd73\" target=\"_blank\">vivid-sweep-59</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 32)             704       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 1,948\n",
      "Trainable params: 1,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.5682 - val_loss: 0.4156\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41562, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:3units:16.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.4663 - val_loss: 0.3808\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41562 to 0.38081, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:3units:16.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4517 - val_loss: 0.3856\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38081\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.4461 - val_loss: 0.3866\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38081\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4397 - val_loss: 0.3737\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.38081 to 0.37373, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:3units:16.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.4357 - val_loss: 0.3769\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37373\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.4315 - val_loss: 0.3551\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37373 to 0.35511, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:3units:16.h5\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 41s 31ms/step - loss: 0.4317 - val_loss: 0.3532\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35511 to 0.35316, saving model to MLP_l:0.001_sr:10_ws:6_u1:32_u2:3_cols:3units:16.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 41s 31ms/step - loss: 0.4291 - val_loss: 0.3669\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35316\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4285 - val_loss: 0.3765\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35316\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.4264 - val_loss: 0.3632\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.35316\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.4230 - val_loss: 0.3596\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.35316\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.4216 - val_loss: 0.3644\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.35316\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31610... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▅▅▃▄▁▁▃▄▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.35316</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>loss</td><td>0.42158</td></tr><tr><td>val_loss</td><td>0.36437</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">vivid-sweep-59</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/doh3sd73\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/doh3sd73</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_211141-doh3sd73/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h6sp03g2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/h6sp03g2\" target=\"_blank\">worldly-sweep-60</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 5, 16)             304       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "=================================================================\n",
      "Total params: 496\n",
      "Trainable params: 496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 40s 30ms/step - loss: 0.8607 - val_loss: 0.7890\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78897, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.7858 - val_loss: 0.7341\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78897 to 0.73411, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.7331 - val_loss: 0.6747\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73411 to 0.67472, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6887 - val_loss: 0.6204\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.67472 to 0.62044, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.6527 - val_loss: 0.5809\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.62044 to 0.58091, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6286 - val_loss: 0.5622\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.58091 to 0.56221, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6073 - val_loss: 0.5388\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56221 to 0.53881, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5960 - val_loss: 0.5341\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.53881 to 0.53406, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5853 - val_loss: 0.5113\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53406 to 0.51131, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5748 - val_loss: 0.5192\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.51131\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5700 - val_loss: 0.5031\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.51131 to 0.50314, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 36s 27ms/step - loss: 0.5645 - val_loss: 0.5096\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.50314\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5621 - val_loss: 0.4898\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.50314 to 0.48975, saving model to MLP_l:0.0001_sr:10_ws:6_u1:16_u2:2_cols:2units:4.h5\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 37s 27ms/step - loss: 0.5584 - val_loss: 0.4995\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48975\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5559 - val_loss: 0.5016\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48975\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5544 - val_loss: 0.4961\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.48975\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 37s 28ms/step - loss: 0.5537 - val_loss: 0.4950\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.48975\n",
      "Epoch 18/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5509 - val_loss: 0.4963\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.48975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 60366... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>0.48975</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>loss</td><td>0.55086</td></tr><tr><td>val_loss</td><td>0.49629</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">worldly-sweep-60</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/h6sp03g2\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/h6sp03g2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_212111-h6sp03g2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1j9c8wnf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/1j9c8wnf\" target=\"_blank\">tough-sweep-61</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 64)             5824      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 7,068\n",
      "Trainable params: 7,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.9865 - val_loss: 0.8150\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81501, saving model to MLP_l:0.01_sr:10_ws:6_u1:64_u2:5_cols:0units:16.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.8128 - val_loss: 0.8170\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.81501\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.8128 - val_loss: 0.8142\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81501 to 0.81420, saving model to MLP_l:0.01_sr:10_ws:6_u1:64_u2:5_cols:0units:16.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 42s 31ms/step - loss: 0.8132 - val_loss: 0.8142\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.81420\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 42s 31ms/step - loss: 0.8125 - val_loss: 0.8205\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.81420\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 41s 31ms/step - loss: 0.8126 - val_loss: 0.8085\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.81420 to 0.80846, saving model to MLP_l:0.01_sr:10_ws:6_u1:64_u2:5_cols:0units:16.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 42s 31ms/step - loss: 0.8127 - val_loss: 0.8229\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80846\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 42s 32ms/step - loss: 0.8142 - val_loss: 0.8163\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80846\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 43s 32ms/step - loss: 0.8170 - val_loss: 0.8199\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80846\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 44s 33ms/step - loss: 0.8127 - val_loss: 0.8105\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80846\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 42s 32ms/step - loss: 0.8121 - val_loss: 0.8144\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80846\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 50322... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.12MB of 0.12MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▄▅▄▄▇▁█▅▇▂▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.80846</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.8121</td></tr><tr><td>val_loss</td><td>0.81441</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">tough-sweep-61</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/1j9c8wnf\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/1j9c8wnf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_213324-1j9c8wnf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0y6b0a1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 4]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/a0y6b0a1\" target=\"_blank\">golden-sweep-62</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "248\n",
      "360\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3, 64)             2368      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1379/1379 [==============================] - 41s 30ms/step - loss: 4.5046 - val_loss: 0.8160\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81600, saving model to MLP_l:0.0001_sr:10_ws:4_u1:64_u2:2_cols:0units:1.h5\n",
      "Epoch 2/55\n",
      "1379/1379 [==============================] - 41s 30ms/step - loss: 0.9511 - val_loss: 0.8168\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.81600\n",
      "Epoch 3/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.8499 - val_loss: 0.8161\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.81600\n",
      "Epoch 4/55\n",
      "1379/1379 [==============================] - 41s 30ms/step - loss: 0.8263 - val_loss: 0.8102\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81600 to 0.81021, saving model to MLP_l:0.0001_sr:10_ws:4_u1:64_u2:2_cols:0units:1.h5\n",
      "Epoch 5/55\n",
      "1379/1379 [==============================] - 41s 30ms/step - loss: 0.8161 - val_loss: 0.8132\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.81021\n",
      "Epoch 6/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.8134 - val_loss: 0.8134\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.81021\n",
      "Epoch 7/55\n",
      "1379/1379 [==============================] - 40s 29ms/step - loss: 0.8099 - val_loss: 0.8117\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.81021\n",
      "Epoch 8/55\n",
      "1379/1379 [==============================] - 39s 28ms/step - loss: 0.8119 - val_loss: 0.8043\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.81021 to 0.80434, saving model to MLP_l:0.0001_sr:10_ws:4_u1:64_u2:2_cols:0units:1.h5\n",
      "Epoch 9/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.8101 - val_loss: 0.8106\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80434\n",
      "Epoch 10/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.8091 - val_loss: 0.8112\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80434\n",
      "Epoch 11/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.8095 - val_loss: 0.8056\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80434\n",
      "Epoch 12/55\n",
      "1379/1379 [==============================] - 36s 26ms/step - loss: 0.8088 - val_loss: 0.8116\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80434\n",
      "Epoch 13/55\n",
      "1379/1379 [==============================] - 38s 27ms/step - loss: 0.8093 - val_loss: 0.8132\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 62212... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>███▄▆▆▅▁▅▅▂▅▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.80434</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>loss</td><td>0.80929</td></tr><tr><td>val_loss</td><td>0.81316</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">golden-sweep-62</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/a0y6b0a1\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/a0y6b0a1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_214211-a0y6b0a1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z4dlz7nc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 6]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/z4dlz7nc\" target=\"_blank\">crisp-sweep-63</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "236\n",
      "350\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4, 16)             880       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 2,332\n",
      "Trainable params: 2,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1334/1334 [==============================] - 41s 31ms/step - loss: 4.1791 - val_loss: 0.8142\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81418, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 2/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.8012 - val_loss: 0.8012\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81418 to 0.80120, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 3/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.7967 - val_loss: 0.7883\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80120 to 0.78825, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 4/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.7796 - val_loss: 0.8070\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.78825\n",
      "Epoch 5/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.7530 - val_loss: 0.7528\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.78825 to 0.75276, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 6/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6782 - val_loss: 0.6262\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.75276 to 0.62616, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 7/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6487 - val_loss: 0.6463\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.62616\n",
      "Epoch 8/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6393 - val_loss: 0.6197\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62616 to 0.61966, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 9/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6394 - val_loss: 0.6721\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61966\n",
      "Epoch 10/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6351 - val_loss: 0.6854\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.61966\n",
      "Epoch 11/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.6276 - val_loss: 0.6152\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61966 to 0.61519, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 12/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6319 - val_loss: 0.6011\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.61519 to 0.60114, saving model to MLP_l:0.001_sr:10_ws:6_u1:16_u2:3_cols:0units:32.h5\n",
      "Epoch 13/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6176 - val_loss: 0.6136\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.60114\n",
      "Epoch 14/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6220 - val_loss: 0.6119\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.60114\n",
      "Epoch 15/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.6117 - val_loss: 0.7352\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.60114\n",
      "Epoch 16/55\n",
      "1334/1334 [==============================] - 39s 29ms/step - loss: 0.5844 - val_loss: 0.6199\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60114\n",
      "Epoch 17/55\n",
      "1334/1334 [==============================] - 38s 29ms/step - loss: 0.5879 - val_loss: 0.6161\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10336... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇█▆▂▂▂▃▄▁▁▁▁▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.60114</td></tr><tr><td>epoch</td><td>16</td></tr><tr><td>loss</td><td>0.58786</td></tr><tr><td>val_loss</td><td>0.61611</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">crisp-sweep-63</strong>: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/z4dlz7nc\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/runs/z4dlz7nc</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211125_215134-z4dlz7nc/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t6u78cu5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcols_list: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsr_nd_ws: [10, 12]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/akhila/shell_hack-level-2/runs/t6u78cu5\" target=\"_blank\">pleasant-sweep-64</a></strong> to <a href=\"https://wandb.ai/akhila/shell_hack-level-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u\" target=\"_blank\">https://wandb.ai/akhila/shell_hack-level-2/sweeps/9a0mx58u</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "206\n",
      "304\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 10, 64)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 321       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                24        \n",
      "=================================================================\n",
      "Total params: 1,369\n",
      "Trainable params: 1,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.8316 - val_loss: 0.8018\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80177, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 2/55\n",
      "1173/1173 [==============================] - 37s 32ms/step - loss: 0.7963 - val_loss: 0.7710\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80177 to 0.77105, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 3/55\n",
      "1173/1173 [==============================] - 38s 32ms/step - loss: 0.7718 - val_loss: 0.7435\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77105 to 0.74354, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 4/55\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 0.7493 - val_loss: 0.7183\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74354 to 0.71829, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 5/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.7302 - val_loss: 0.7009\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71829 to 0.70090, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 6/55\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 0.7141 - val_loss: 0.6930\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.70090 to 0.69298, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 7/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6972 - val_loss: 0.6615\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.69298 to 0.66149, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 8/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6859 - val_loss: 0.6498\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.66149 to 0.64981, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 9/55\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.6755 - val_loss: 0.6346\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.64981 to 0.63460, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 10/55\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.6624 - val_loss: 0.6255\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.63460 to 0.62547, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 11/55\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.6548 - val_loss: 0.6256\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.62547\n",
      "Epoch 12/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6465 - val_loss: 0.6041\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.62547 to 0.60407, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 13/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6389 - val_loss: 0.5953\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.60407 to 0.59534, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 14/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6309 - val_loss: 0.6061\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59534\n",
      "Epoch 15/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.6301 - val_loss: 0.5867\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.59534 to 0.58675, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 16/55\n",
      "1173/1173 [==============================] - 41s 35ms/step - loss: 0.6283 - val_loss: 0.5733\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.58675 to 0.57332, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 17/55\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 0.6226 - val_loss: 0.5910\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57332\n",
      "Epoch 18/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6219 - val_loss: 0.5768\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.57332\n",
      "Epoch 19/55\n",
      "1173/1173 [==============================] - 40s 34ms/step - loss: 0.6216 - val_loss: 0.5915\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.57332\n",
      "Epoch 20/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6183 - val_loss: 0.5621\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.57332 to 0.56208, saving model to MLP_l:0.0001_sr:10_ws:12_u1:64_u2:3_cols:4units:1.h5\n",
      "Epoch 21/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.6191 - val_loss: 0.5754\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.56208\n",
      "Epoch 22/55\n",
      "1173/1173 [==============================] - 39s 34ms/step - loss: 0.6168 - val_loss: 0.5723\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.56208\n",
      "Epoch 23/55\n",
      "1173/1173 [==============================] - 39s 33ms/step - loss: 0.6187 - val_loss: 0.5746\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.56208\n",
      "Epoch 24/55\n",
      " 607/1173 [==============>...............] - ETA: 16s - loss: 0.6194"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=sweep_train, count = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(filters,kernel_size,ws,i,units_1):\n",
    "\n",
    "    model =   tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=filters,kernel_size=ws,activation='relu'\n",
    "                               ,input_shape=(ws,len(l[i]))),\n",
    "#         tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "#         tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
    "#         tf.keras.layers.Conv1D(filters=filters//2, kernel_size=kernel_size, activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=units_1, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(units=12),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, activation= ' relu ' ,\n",
    "# input_shape=(n_timesteps,n_features)))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, activation= ' relu ' ))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Conv1D(filters=16, kernel_size=3, activation= ' relu ' ))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100, activation= ' relu ' ))\n",
    "# model.add(Dense(n_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171201071000.txt            \u001b[0m\u001b[01;35m20171201115000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201071000_11.jpg\u001b[0m         \u001b[01;35m20171201115000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201071000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201115000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201071000_1112_CDOC.png\u001b[0m  20171201120000.txt\n",
      "\u001b[01;35m20171201071000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201120000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201071000_12.jpg\u001b[0m         \u001b[01;35m20171201120000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201071000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201120000_1112_CDOC.png\u001b[0m\n",
      "20171201072000.txt            \u001b[01;35m20171201120000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201072000_11.jpg\u001b[0m         \u001b[01;35m20171201120000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201072000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201120000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201072000_1112_CDOC.png\u001b[0m  20171201121000.txt\n",
      "\u001b[01;35m20171201072000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201121000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201072000_12.jpg\u001b[0m         \u001b[01;35m20171201121000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201072000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201121000_1112_CDOC.png\u001b[0m\n",
      "20171201073000.txt            \u001b[01;35m20171201121000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201073000_11.jpg\u001b[0m         \u001b[01;35m20171201121000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201073000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201121000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201073000_1112_CDOC.png\u001b[0m  20171201122000.txt\n",
      "\u001b[01;35m20171201073000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201122000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201073000_12.jpg\u001b[0m         \u001b[01;35m20171201122000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201073000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201122000_1112_CDOC.png\u001b[0m\n",
      "20171201074000.txt            \u001b[01;35m20171201122000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201074000_11.jpg\u001b[0m         \u001b[01;35m20171201122000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201074000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201122000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201074000_1112_CDOC.png\u001b[0m  20171201123000.txt\n",
      "\u001b[01;35m20171201074000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201123000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201074000_12.jpg\u001b[0m         \u001b[01;35m20171201123000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201074000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201123000_1112_CDOC.png\u001b[0m\n",
      "20171201075000.txt            \u001b[01;35m20171201123000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201075000_11.jpg\u001b[0m         \u001b[01;35m20171201123000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201075000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201123000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201075000_1112_CDOC.png\u001b[0m  20171201124000.txt\n",
      "\u001b[01;35m20171201075000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201124000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201075000_12.jpg\u001b[0m         \u001b[01;35m20171201124000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201075000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201124000_1112_CDOC.png\u001b[0m\n",
      "20171201080000.txt            \u001b[01;35m20171201124000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201080000_11.jpg\u001b[0m         \u001b[01;35m20171201124000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201080000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201124000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201080000_1112_CDOC.png\u001b[0m  20171201125000.txt\n",
      "\u001b[01;35m20171201080000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201125000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201080000_12.jpg\u001b[0m         \u001b[01;35m20171201125000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201080000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201125000_1112_CDOC.png\u001b[0m\n",
      "20171201081000.txt            \u001b[01;35m20171201125000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201081000_11.jpg\u001b[0m         \u001b[01;35m20171201125000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201081000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201125000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201081000_1112_CDOC.png\u001b[0m  20171201130000.txt\n",
      "\u001b[01;35m20171201081000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201130000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201081000_12.jpg\u001b[0m         \u001b[01;35m20171201130000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201081000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201130000_1112_CDOC.png\u001b[0m\n",
      "20171201082000.txt            \u001b[01;35m20171201130000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201082000_11.jpg\u001b[0m         \u001b[01;35m20171201130000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201082000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201130000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201082000_1112_CDOC.png\u001b[0m  20171201131000.txt\n",
      "\u001b[01;35m20171201082000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201131000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201082000_12.jpg\u001b[0m         \u001b[01;35m20171201131000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201082000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201131000_1112_CDOC.png\u001b[0m\n",
      "20171201083000.txt            \u001b[01;35m20171201131000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201083000_11.jpg\u001b[0m         \u001b[01;35m20171201131000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201083000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201131000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201083000_1112_CDOC.png\u001b[0m  20171201132000.txt\n",
      "\u001b[01;35m20171201083000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201132000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201083000_12.jpg\u001b[0m         \u001b[01;35m20171201132000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201083000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201132000_1112_CDOC.png\u001b[0m\n",
      "20171201084000.txt            \u001b[01;35m20171201132000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201084000_11.jpg\u001b[0m         \u001b[01;35m20171201132000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201084000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201132000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201084000_1112_CDOC.png\u001b[0m  20171201133000.txt\n",
      "\u001b[01;35m20171201084000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201133000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201084000_12.jpg\u001b[0m         \u001b[01;35m20171201133000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201084000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201133000_1112_CDOC.png\u001b[0m\n",
      "20171201085000.txt            \u001b[01;35m20171201133000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201085000_11.jpg\u001b[0m         \u001b[01;35m20171201133000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201085000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201133000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201085000_1112_CDOC.png\u001b[0m  20171201134000.txt\n",
      "\u001b[01;35m20171201085000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201134000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201085000_12.jpg\u001b[0m         \u001b[01;35m20171201134000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201085000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201134000_1112_CDOC.png\u001b[0m\n",
      "20171201090000.txt            \u001b[01;35m20171201134000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201090000_11.jpg\u001b[0m         \u001b[01;35m20171201134000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201090000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201134000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201090000_1112_CDOC.png\u001b[0m  20171201135000.txt\n",
      "\u001b[01;35m20171201090000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201135000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201090000_12.jpg\u001b[0m         \u001b[01;35m20171201135000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201090000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201135000_1112_CDOC.png\u001b[0m\n",
      "20171201091000.txt            \u001b[01;35m20171201135000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201091000_11.jpg\u001b[0m         \u001b[01;35m20171201135000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201091000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201135000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201091000_1112_CDOC.png\u001b[0m  20171201140000.txt\n",
      "\u001b[01;35m20171201091000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201140000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201091000_12.jpg\u001b[0m         \u001b[01;35m20171201140000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201091000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201140000_1112_CDOC.png\u001b[0m\n",
      "20171201092000.txt            \u001b[01;35m20171201140000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201092000_11.jpg\u001b[0m         \u001b[01;35m20171201140000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201092000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201140000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201092000_1112_CDOC.png\u001b[0m  20171201141000.txt\n",
      "\u001b[01;35m20171201092000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201141000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201092000_12.jpg\u001b[0m         \u001b[01;35m20171201141000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201092000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201141000_1112_CDOC.png\u001b[0m\n",
      "20171201093000.txt            \u001b[01;35m20171201141000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201093000_11.jpg\u001b[0m         \u001b[01;35m20171201141000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201093000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201141000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201093000_1112_CDOC.png\u001b[0m  20171201142000.txt\n",
      "\u001b[01;35m20171201093000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201142000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201093000_12.jpg\u001b[0m         \u001b[01;35m20171201142000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201093000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201142000_1112_CDOC.png\u001b[0m\n",
      "20171201094000.txt            \u001b[01;35m20171201142000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201094000_11.jpg\u001b[0m         \u001b[01;35m20171201142000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201094000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201142000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201094000_1112_CDOC.png\u001b[0m  20171201143000.txt\n",
      "\u001b[01;35m20171201094000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201143000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201094000_12.jpg\u001b[0m         \u001b[01;35m20171201143000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201094000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201143000_1112_CDOC.png\u001b[0m\n",
      "20171201095000.txt            \u001b[01;35m20171201143000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201095000_11.jpg\u001b[0m         \u001b[01;35m20171201143000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201095000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201143000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201095000_1112_CDOC.png\u001b[0m  20171201144000.txt\n",
      "\u001b[01;35m20171201095000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201144000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201095000_12.jpg\u001b[0m         \u001b[01;35m20171201144000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201095000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201144000_1112_CDOC.png\u001b[0m\n",
      "20171201100000.txt            \u001b[01;35m20171201144000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201100000_11.jpg\u001b[0m         \u001b[01;35m20171201144000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201100000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201144000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201100000_1112_CDOC.png\u001b[0m  20171201145000.txt\n",
      "\u001b[01;35m20171201100000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201145000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201100000_12.jpg\u001b[0m         \u001b[01;35m20171201145000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201100000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201145000_1112_CDOC.png\u001b[0m\n",
      "20171201101000.txt            \u001b[01;35m20171201145000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201101000_11.jpg\u001b[0m         \u001b[01;35m20171201145000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201101000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201145000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201101000_1112_CDOC.png\u001b[0m  20171201150000.txt\n",
      "\u001b[01;35m20171201101000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201150000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201101000_12.jpg\u001b[0m         \u001b[01;35m20171201150000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201101000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201150000_1112_CDOC.png\u001b[0m\n",
      "20171201102000.txt            \u001b[01;35m20171201150000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201102000_11.jpg\u001b[0m         \u001b[01;35m20171201150000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201102000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201150000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201102000_1112_CDOC.png\u001b[0m  20171201151000.txt\n",
      "\u001b[01;35m20171201102000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201151000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201102000_12.jpg\u001b[0m         \u001b[01;35m20171201151000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201102000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201151000_1112_CDOC.png\u001b[0m\n",
      "20171201103000.txt            \u001b[01;35m20171201151000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201103000_11.jpg\u001b[0m         \u001b[01;35m20171201151000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201103000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201151000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201103000_1112_CDOC.png\u001b[0m  20171201152000.txt\n",
      "\u001b[01;35m20171201103000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201152000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201103000_12.jpg\u001b[0m         \u001b[01;35m20171201152000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201103000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201152000_1112_CDOC.png\u001b[0m\n",
      "20171201104000.txt            \u001b[01;35m20171201152000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201104000_11.jpg\u001b[0m         \u001b[01;35m20171201152000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201104000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201152000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201104000_1112_CDOC.png\u001b[0m  20171201153000.txt\n",
      "\u001b[01;35m20171201104000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201153000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201104000_12.jpg\u001b[0m         \u001b[01;35m20171201153000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201104000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201153000_1112_CDOC.png\u001b[0m\n",
      "20171201105000.txt            \u001b[01;35m20171201153000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201105000_11.jpg\u001b[0m         \u001b[01;35m20171201153000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201105000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201153000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201105000_1112_CDOC.png\u001b[0m  20171201154000.txt\n",
      "\u001b[01;35m20171201105000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201154000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201105000_12.jpg\u001b[0m         \u001b[01;35m20171201154000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201105000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201154000_1112_CDOC.png\u001b[0m\n",
      "20171201110000.txt            \u001b[01;35m20171201154000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201110000_11.jpg\u001b[0m         \u001b[01;35m20171201154000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201110000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201154000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201110000_1112_CDOC.png\u001b[0m  20171201155000.txt\n",
      "\u001b[01;35m20171201110000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201155000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201110000_12.jpg\u001b[0m         \u001b[01;35m20171201155000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201110000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201155000_1112_CDOC.png\u001b[0m\n",
      "20171201111000.txt            \u001b[01;35m20171201155000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201111000_11.jpg\u001b[0m         \u001b[01;35m20171201155000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201111000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201155000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201111000_1112_CDOC.png\u001b[0m  20171201160000.txt\n",
      "\u001b[01;35m20171201111000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201160000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201111000_12.jpg\u001b[0m         \u001b[01;35m20171201160000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201111000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201160000_1112_CDOC.png\u001b[0m\n",
      "20171201112000.txt            \u001b[01;35m20171201160000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201112000_11.jpg\u001b[0m         \u001b[01;35m20171201160000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201112000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201160000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201112000_1112_CDOC.png\u001b[0m  20171201161000.txt\n",
      "\u001b[01;35m20171201112000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201161000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201112000_12.jpg\u001b[0m         \u001b[01;35m20171201161000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201112000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201161000_1112_CDOC.png\u001b[0m\n",
      "20171201113000.txt            \u001b[01;35m20171201161000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201113000_11.jpg\u001b[0m         \u001b[01;35m20171201161000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201113000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201161000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201113000_1112_CDOC.png\u001b[0m  20171201162000.txt\n",
      "\u001b[01;35m20171201113000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201162000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201113000_12.jpg\u001b[0m         \u001b[01;35m20171201162000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201113000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201162000_1112_CDOC.png\u001b[0m\n",
      "20171201114000.txt            \u001b[01;35m20171201162000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201114000_11.jpg\u001b[0m         \u001b[01;35m20171201162000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201114000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201162000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201114000_1112_CDOC.png\u001b[0m  20171201163000.txt\n",
      "\u001b[01;35m20171201114000_11_NE.jpg\u001b[0m      \u001b[01;35m20171201163000_11.jpg\u001b[0m\n",
      "\u001b[01;35m20171201114000_12.jpg\u001b[0m         \u001b[01;35m20171201163000_1112_BRBG.png\u001b[0m\n",
      "\u001b[01;35m20171201114000_12_UE.jpg\u001b[0m      \u001b[01;35m20171201163000_1112_CDOC.png\u001b[0m\n",
      "20171201115000.txt            \u001b[01;35m20171201163000_11_NE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201115000_11.jpg\u001b[0m         \u001b[01;35m20171201163000_12.jpg\u001b[0m\n",
      "\u001b[01;35m20171201115000_1112_BRBG.png\u001b[0m  \u001b[01;35m20171201163000_12_UE.jpg\u001b[0m\n",
      "\u001b[01;35m20171201115000_1112_CDOC.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls Images/20171201/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP_final(2)_(1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007e1ed246164ba3895bdb6e46176040": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02833e23c0be4b5dadd2934444a0ab34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff74237547ba41daa5b7abb345f790dc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f18bf8a930d4d538c6924a440cfa128",
      "value": 1
     }
    },
    "0507395ba6494600b656bcb13b61dceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08422021a53f4add8058ef6be1a74ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_113fd116f16e492694a103113632224a",
       "IPY_MODEL_02833e23c0be4b5dadd2934444a0ab34"
      ],
      "layout": "IPY_MODEL_30c0de69bad740d6a129bb5aa5e09021"
     }
    },
    "09bca34ef164466bb07e8c3b7b25ce22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a857b095ee64478b408a1f31e6feafc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e96dd130c3d4fd0b2af94fb9bc9ab1e",
      "placeholder": "​",
      "style": "IPY_MODEL_fd47e4a6863741a2b1e8f6848c41b2fb",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "0bf70fe43b2240a1bee033b9fda143cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f855ac5607c4e5c92018cdbfe3cecc0",
       "IPY_MODEL_a26caa069ddb462a852a785c7f4b0840"
      ],
      "layout": "IPY_MODEL_df1a1c1134564433a186bbf33ae62cbb"
     }
    },
    "0caf730847ac432884eebd39ba7574d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a9ec71e0b904a9999962c16a369d41a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fadb336a0f0d4cf8ba5d48d06c3e0bc9",
      "value": 1
     }
    },
    "0dbe139b07f0496db28bdcf90b628522": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e5b76fbc81446dea4a2ac75666f8729": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eed21348b4c47c6b192881963c78f73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f0e9cac770c4a6cbcb6a6997f122172": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "113fd116f16e492694a103113632224a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0267c89d3024f7c804c410ad28f1415",
      "placeholder": "​",
      "style": "IPY_MODEL_4c24657ff32c4072a536055c6219aec4",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "1478577662ba4928ba83a9eb8332cfb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b65adcfbf2e4c7dba09cbfbd2bcd33c",
      "placeholder": "​",
      "style": "IPY_MODEL_1fafe93962144217a46c80126d5ad82a",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "1640cd5d2c4d4b9fbb938aa7177c7e95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "197bd615b03644bebb914a3e6a8174dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a9ec71e0b904a9999962c16a369d41a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ccdfbbe581b4c48a918da52b607621f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e040893efb54cefa3c68dd4329b3137",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33bc16ce15204387b9b505da1b2ecb31",
      "value": 1
     }
    },
    "1d854a1940a24361a0cae5507ceb9678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e96dd130c3d4fd0b2af94fb9bc9ab1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f7dd8be1619484fac63cb508d5ac1cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fafe93962144217a46c80126d5ad82a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc2a531107246edb4b22ae329e674ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2104c5d7d5b144609475047b6daec440": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "210c3748f1c54beba0410260b443c812": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "242a04ed75cd46e0aae901fdbc53c7b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2526534467684a5e9b9ccc7812e9a576": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "278102c12f394849977128345c2a28c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29c73398e70a4868b93853984338b469": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a40454bcbfc4a019a000d5bb3a0bfa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ae2fd6da5734baa96080ea90d18bd25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dee35b7bebd84430b4e1c0a0764dc4b8",
      "placeholder": "​",
      "style": "IPY_MODEL_c6918e297ef34efcac32b240cffecbba",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "2bc29174cf7f4d5eabadc37875b59da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e3413e0b1b6410dbca57678e3879007",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1640cd5d2c4d4b9fbb938aa7177c7e95",
      "value": 1
     }
    },
    "2f18bf8a930d4d538c6924a440cfa128": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30c0de69bad740d6a129bb5aa5e09021": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f594a42b244483971c95a4435d51f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_197bd615b03644bebb914a3e6a8174dc",
      "placeholder": "​",
      "style": "IPY_MODEL_1fc2a531107246edb4b22ae329e674ae",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "32631a0460044317be710eec6ec17c5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33bc16ce15204387b9b505da1b2ecb31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "367b28e7499f4487994d132811544016": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a857b095ee64478b408a1f31e6feafc",
       "IPY_MODEL_f80251552fa24112be683012ce6e3b86"
      ],
      "layout": "IPY_MODEL_baf620855d5c4165b5453d99e01f4406"
     }
    },
    "37084202f97b4db5ad431d8a77590592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3845531348a04d12af88a9ef9bf45505": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a3f2f85ac694526b48b77b637437339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d039dc1aca5489b87e434fe1c477dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2526534467684a5e9b9ccc7812e9a576",
      "placeholder": "​",
      "style": "IPY_MODEL_46a35a3e353d4bb2a767ea4528fc0b43",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "3dabbf9c470042a581871dce2c967d7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e95deda17a34896804ce6a38b065947": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4642c3e1758748ef84169d0e7b80a9d8",
       "IPY_MODEL_6c2557b670044b51b333862e00071dbd"
      ],
      "layout": "IPY_MODEL_edccffdfd0684ff9962451dca5d7a19c"
     }
    },
    "3ee8d0564ec8472283bfe8f1b91cc525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e182c96d3054939a92ae926169fd7e9",
       "IPY_MODEL_a0e4f149c5d74915a35f29f7f6d53546"
      ],
      "layout": "IPY_MODEL_fb20a880e3394f92ba079a19618e6bdd"
     }
    },
    "3fa486345e5c40faad46df7f043f7e8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4642c3e1758748ef84169d0e7b80a9d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fffbbf91eb1b459dbc8d9d00a215b76e",
      "placeholder": "​",
      "style": "IPY_MODEL_4a76c8449dbb46f986d8c0dbd752082f",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "46a35a3e353d4bb2a767ea4528fc0b43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a76c8449dbb46f986d8c0dbd752082f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4abf93c146fb4673952105584434e2c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e61d852172e412e94c68b7a6b9c6e80",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e8c446d6e864fb38c74bb52ec16cab5",
      "value": 1
     }
    },
    "4c24657ff32c4072a536055c6219aec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c3c124cf67e4140bf5a3b8a48279bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4dc930979e4448038fa799ac9c0f32b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f71d320dbac40e68ba2d697e6391937",
      "placeholder": "​",
      "style": "IPY_MODEL_4e042720ef7645b18adc12bfc94573b7",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "4e042720ef7645b18adc12bfc94573b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4eb5761a48124709a0716b44285814d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f71d320dbac40e68ba2d697e6391937": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f887930c5e44e2e800575338c04019a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fc2f17bff134d50bb9a539ed291b55b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63120f2fdb044a2eb4fdb316a5f0c947",
      "placeholder": "​",
      "style": "IPY_MODEL_b5be6a4c3b1545729e8ceb1283cb9c83",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "525d24d99c3c4447843b67cca0d34c4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "537c17ed8c294889b95efbc4e3632fe2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "541bbbde8ddd4d79917d965f8cc596bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "546e603f30b042f688df0028c216819b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55de7cfafaf94f85af11ace74b183c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62bdfee72cc64420aa74e9f78ff127c6",
       "IPY_MODEL_e77b5c96f00a44b0aaf0a590d2abc8fd"
      ],
      "layout": "IPY_MODEL_007e1ed246164ba3895bdb6e46176040"
     }
    },
    "586a90972fea43d48d8f8a8998b6f7a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5db2fc6dcbac4dddbf1b2b1ba6a6bd6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f0e9cac770c4a6cbcb6a6997f122172",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f50a779f9ff041dfbcd9115ea0f6e642",
      "value": 1
     }
    },
    "5e040893efb54cefa3c68dd4329b3137": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e3df02e97a54c42bee0f2c47b972ba1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e8c446d6e864fb38c74bb52ec16cab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ebdfb4a891c4c3faff659470f02e1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c247e4c7a5f84ba68780408887f73af3",
      "placeholder": "​",
      "style": "IPY_MODEL_2104c5d7d5b144609475047b6daec440",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "61309e0b10cb4ed692213ad171b08108": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6cc4502391c4556bfb2804494a19996",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_525d24d99c3c4447843b67cca0d34c4b",
      "value": 1
     }
    },
    "6142817c24d64c09aaefc51830d81ce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "62bdfee72cc64420aa74e9f78ff127c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_541bbbde8ddd4d79917d965f8cc596bd",
      "placeholder": "​",
      "style": "IPY_MODEL_9370f75d6f5348e6988bc3e68bab9559",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "63120f2fdb044a2eb4fdb316a5f0c947": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "635e1e101da34c91be92e9b515a054f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a97830409b804e1585503d166bac24ca",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_242a04ed75cd46e0aae901fdbc53c7b7",
      "value": 1
     }
    },
    "6579264f45e3424eae1fd143177a6c7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de7df4498eed4320a40221560a37c279",
      "placeholder": "​",
      "style": "IPY_MODEL_37084202f97b4db5ad431d8a77590592",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "695976b7669a47e4af758a8d8350cffe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b44b6af2651e4d128f1bf55aeb98738d",
      "placeholder": "​",
      "style": "IPY_MODEL_4f887930c5e44e2e800575338c04019a",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "6c2557b670044b51b333862e00071dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32631a0460044317be710eec6ec17c5e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6992b88d0a04abb9d5aac6d0f0d955c",
      "value": 1
     }
    },
    "6e3413e0b1b6410dbca57678e3879007": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e7396b0a3084b1782f85475b959249d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_586a90972fea43d48d8f8a8998b6f7a9",
      "placeholder": "​",
      "style": "IPY_MODEL_537c17ed8c294889b95efbc4e3632fe2",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "6f855ac5607c4e5c92018cdbfe3cecc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a40454bcbfc4a019a000d5bb3a0bfa2",
      "placeholder": "​",
      "style": "IPY_MODEL_89cddcdd40064e51a54196df03736ab1",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "7100651797ce4f02b4b023ad3ba69b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72c99cba9a6344e8940dcd856348f274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73b389c06cf34fd690e3e6946e28c584": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74345e61a11e41a9bc2fb60364465304": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74ac38af99934a218dd76d74e9e6cdd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7560642955e1432383796072be676982": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77338b45c2f74396bb05a0e823b3987f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e7396b0a3084b1782f85475b959249d",
       "IPY_MODEL_ea1fe609106e413c860526a57f64b819"
      ],
      "layout": "IPY_MODEL_3845531348a04d12af88a9ef9bf45505"
     }
    },
    "78a16ca307d349e2a3c5329a413445df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "794f1a24b1a54420822d889703eb0c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c8a7ff03e2345338a82afa37c3ac555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eedbcba6558b41129c236a83b27ae5c3",
      "placeholder": "​",
      "style": "IPY_MODEL_c045d8d7f9364616b9ed7a0ba8e3fa4e",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "7cfab898694b4fc6ac79f44d5546acd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc9bb4d0ab8341138eed54bd1f89d4b1",
      "placeholder": "​",
      "style": "IPY_MODEL_0507395ba6494600b656bcb13b61dceb",
      "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
     }
    },
    "7d0894f3b383486498606f37002af709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98069d6cf3b04488af564edc7132f904",
      "placeholder": "​",
      "style": "IPY_MODEL_978d3dd3694844d7b163adf9cd6e9efc",
      "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
     }
    },
    "7daf6cc7f9bc4738ad12499f51e80b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29c73398e70a4868b93853984338b469",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fa486345e5c40faad46df7f043f7e8d",
      "value": 1
     }
    },
    "7f06230ee4c04349bd9ca871afd6142d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30f594a42b244483971c95a4435d51f8",
       "IPY_MODEL_c0893c3c5d9e463fa1ea0bb51899a50c"
      ],
      "layout": "IPY_MODEL_bf8a1688cd404fc2b49c4b894815c68e"
     }
    },
    "7fc3ecd03ea148838630b8db60efa6ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8470e65ae6c1419dae1ef7e350ca7a79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbd2be1223c746b08c06b8da4f3643fb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6142817c24d64c09aaefc51830d81ce8",
      "value": 1
     }
    },
    "86e2cdab31b647d290a584f6918a83c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e74267d2d1f54f49b32e19a3cf808c75",
       "IPY_MODEL_5db2fc6dcbac4dddbf1b2b1ba6a6bd6c"
      ],
      "layout": "IPY_MODEL_e3061569043f490495d74e393abdb9f8"
     }
    },
    "89cddcdd40064e51a54196df03736ab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bc7b3942f3142459071cf04b9700d48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c87c2f1b4c54cb68a43881feaea7f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb2ae577e4fb499b91cc0ca424071240",
       "IPY_MODEL_fd184b956cac4641b7a72f653d52777b"
      ],
      "layout": "IPY_MODEL_1f7dd8be1619484fac63cb508d5ac1cc"
     }
    },
    "8e61d852172e412e94c68b7a6b9c6e80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e702687cb9249208f60707dced96d71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ea8fec13e304cf083e665ad501297e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "927959e6b0c943218d33cacb39c7b528": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9370f75d6f5348e6988bc3e68bab9559": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "939fc2fea7324833a1bff56c19655119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "947d2a9055b74d5b87384e7b2cb577f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "957c397cfff34813a7545d7ab3ff2bc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "978d3dd3694844d7b163adf9cd6e9efc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98069d6cf3b04488af564edc7132f904": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a36776134814451b54bc179968fa88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_927959e6b0c943218d33cacb39c7b528",
      "placeholder": "​",
      "style": "IPY_MODEL_0e5b76fbc81446dea4a2ac75666f8729",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "9b65adcfbf2e4c7dba09cbfbd2bcd33c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e182c96d3054939a92ae926169fd7e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_957c397cfff34813a7545d7ab3ff2bc8",
      "placeholder": "​",
      "style": "IPY_MODEL_8e702687cb9249208f60707dced96d71",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "9e6214be8632432f92329c3d54dff024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ebdfb4a891c4c3faff659470f02e1dd",
       "IPY_MODEL_f263347a6d644a63ac69030c646708c2"
      ],
      "layout": "IPY_MODEL_3dabbf9c470042a581871dce2c967d7d"
     }
    },
    "a0267c89d3024f7c804c410ad28f1415": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a05204edd9f24cb08622e46e61770ec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3d8a575583c496ea32e91ad5084c441",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e091269edbea49c6a4c6fab6fb2c5ebe",
      "value": 1
     }
    },
    "a0e4f149c5d74915a35f29f7f6d53546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d116473893194ce88227c2668671e1be",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c3c124cf67e4140bf5a3b8a48279bf4",
      "value": 1
     }
    },
    "a26caa069ddb462a852a785c7f4b0840": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_278102c12f394849977128345c2a28c0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74345e61a11e41a9bc2fb60364465304",
      "value": 1
     }
    },
    "a2a19740c992423f8d6089b01d2d7175": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a628a7f24983465fb30ed5f399cd3f29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7cfab898694b4fc6ac79f44d5546acd8",
       "IPY_MODEL_7daf6cc7f9bc4738ad12499f51e80b6b"
      ],
      "layout": "IPY_MODEL_f9b70791140547b99a7da740cf1c2034"
     }
    },
    "a6863f77fe4d4107acd503e7e2b69a9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef019bb83cc24dda9460c798aaa37272",
       "IPY_MODEL_c98f3226699b42be9f2228c9b6cf4bab"
      ],
      "layout": "IPY_MODEL_c5216dd9d6e54fd39b0bf96f35162520"
     }
    },
    "a7956a4026f84873bc3abe51e722ad29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7108f591e8842a49ae5511e9399ec5d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_947d2a9055b74d5b87384e7b2cb577f9",
      "value": 1
     }
    },
    "a97830409b804e1585503d166bac24ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac2fac0d32f24d30ba2713f50331b731": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af3a51df9ae04e45990c980a867fd313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d039dc1aca5489b87e434fe1c477dde",
       "IPY_MODEL_0caf730847ac432884eebd39ba7574d6"
      ],
      "layout": "IPY_MODEL_1d854a1940a24361a0cae5507ceb9678"
     }
    },
    "b03d93244d6e47c6a3368278f9edb247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44b6af2651e4d128f1bf55aeb98738d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5be6a4c3b1545729e8ceb1283cb9c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "baf620855d5c4165b5453d99e01f4406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb2ae577e4fb499b91cc0ca424071240": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b03d93244d6e47c6a3368278f9edb247",
      "placeholder": "​",
      "style": "IPY_MODEL_ac2fac0d32f24d30ba2713f50331b731",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "bc9bb4d0ab8341138eed54bd1f89d4b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf8a1688cd404fc2b49c4b894815c68e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c045d8d7f9364616b9ed7a0ba8e3fa4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c05f175f1fa04527a990f3c4b2a46b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ae2fd6da5734baa96080ea90d18bd25",
       "IPY_MODEL_61309e0b10cb4ed692213ad171b08108"
      ],
      "layout": "IPY_MODEL_eec394f69d074fc3821e265efc0c3591"
     }
    },
    "c0893c3c5d9e463fa1ea0bb51899a50c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecc0a0d33cf24f0b986931565df7631a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d76601d62e2e4d90ba5db28866abe05a",
      "value": 1
     }
    },
    "c1e14520dbdb48508b16067525a9989e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c247e4c7a5f84ba68780408887f73af3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5216dd9d6e54fd39b0bf96f35162520": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6918e297ef34efcac32b240cffecbba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c97220141bac4403bb5e56279ad709c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6579264f45e3424eae1fd143177a6c7c",
       "IPY_MODEL_1ccdfbbe581b4c48a918da52b607621f"
      ],
      "layout": "IPY_MODEL_0eed21348b4c47c6b192881963c78f73"
     }
    },
    "c98f3226699b42be9f2228c9b6cf4bab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bc7b3942f3142459071cf04b9700d48",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_210c3748f1c54beba0410260b443c812",
      "value": 1
     }
    },
    "cbe55bbe1afd440ba09aad4f0337fa3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d0c54e06b63d447b8993ab5fe73550de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_546e603f30b042f688df0028c216819b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cbe55bbe1afd440ba09aad4f0337fa3b",
      "value": 1
     }
    },
    "d116473893194ce88227c2668671e1be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6992b88d0a04abb9d5aac6d0f0d955c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6cc4502391c4556bfb2804494a19996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d76601d62e2e4d90ba5db28866abe05a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da45b09a651f45428eae1161e1fe7999": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1478577662ba4928ba83a9eb8332cfb9",
       "IPY_MODEL_4abf93c146fb4673952105584434e2c6"
      ],
      "layout": "IPY_MODEL_4eb5761a48124709a0716b44285814d3"
     }
    },
    "dba318405fdc4ede84f4a67c902d4133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de7df4498eed4320a40221560a37c279": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dee35b7bebd84430b4e1c0a0764dc4b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df1a1c1134564433a186bbf33ae62cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e091269edbea49c6a4c6fab6fb2c5ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e14b7a5297054b7a90b4e1b8d550d411": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4fc2f17bff134d50bb9a539ed291b55b",
       "IPY_MODEL_d0c54e06b63d447b8993ab5fe73550de"
      ],
      "layout": "IPY_MODEL_fa0931bf9d114af9a9adbc8802ebd574"
     }
    },
    "e243812911094acf86dc2121819c5abb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9a36776134814451b54bc179968fa88d",
       "IPY_MODEL_2bc29174cf7f4d5eabadc37875b59da4"
      ],
      "layout": "IPY_MODEL_c1e14520dbdb48508b16067525a9989e"
     }
    },
    "e3061569043f490495d74e393abdb9f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e430cbf1c9dc4cd8b9100f97ff4bfbb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d0894f3b383486498606f37002af709",
       "IPY_MODEL_8470e65ae6c1419dae1ef7e350ca7a79"
      ],
      "layout": "IPY_MODEL_73b389c06cf34fd690e3e6946e28c584"
     }
    },
    "e4ddd1306036405e818635540557ca0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4dc930979e4448038fa799ac9c0f32b5",
       "IPY_MODEL_a05204edd9f24cb08622e46e61770ec4"
      ],
      "layout": "IPY_MODEL_8ea8fec13e304cf083e665ad501297e0"
     }
    },
    "e6b4e84658924f7ba25bb022bb368518": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7108f591e8842a49ae5511e9399ec5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e74267d2d1f54f49b32e19a3cf808c75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6b4e84658924f7ba25bb022bb368518",
      "placeholder": "​",
      "style": "IPY_MODEL_794f1a24b1a54420822d889703eb0c19",
      "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
     }
    },
    "e77b5c96f00a44b0aaf0a590d2abc8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4ebe1bb92f64975bb18a2a5df338b92",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_939fc2fea7324833a1bff56c19655119",
      "value": 1
     }
    },
    "ea1fe609106e413c860526a57f64b819": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2a19740c992423f8d6089b01d2d7175",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7100651797ce4f02b4b023ad3ba69b95",
      "value": 1
     }
    },
    "ecc0a0d33cf24f0b986931565df7631a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edccffdfd0684ff9962451dca5d7a19c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eec394f69d074fc3821e265efc0c3591": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eedbcba6558b41129c236a83b27ae5c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef019bb83cc24dda9460c798aaa37272": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a3f2f85ac694526b48b77b637437339",
      "placeholder": "​",
      "style": "IPY_MODEL_78a16ca307d349e2a3c5329a413445df",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "f263347a6d644a63ac69030c646708c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7560642955e1432383796072be676982",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74ac38af99934a218dd76d74e9e6cdd7",
      "value": 1
     }
    },
    "f3d8a575583c496ea32e91ad5084c441": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4ebe1bb92f64975bb18a2a5df338b92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f50a779f9ff041dfbcd9115ea0f6e642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f50f674fb0294291ba39e6d7ec16b451": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_695976b7669a47e4af758a8d8350cffe",
       "IPY_MODEL_635e1e101da34c91be92e9b515a054f0"
      ],
      "layout": "IPY_MODEL_72c99cba9a6344e8940dcd856348f274"
     }
    },
    "f7b5e399101846ff960d829bf2c755cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c8a7ff03e2345338a82afa37c3ac555",
       "IPY_MODEL_a7956a4026f84873bc3abe51e722ad29"
      ],
      "layout": "IPY_MODEL_7fc3ecd03ea148838630b8db60efa6ae"
     }
    },
    "f80251552fa24112be683012ce6e3b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09bca34ef164466bb07e8c3b7b25ce22",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dba318405fdc4ede84f4a67c902d4133",
      "value": 1
     }
    },
    "f9b70791140547b99a7da740cf1c2034": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa0931bf9d114af9a9adbc8802ebd574": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fadb336a0f0d4cf8ba5d48d06c3e0bc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb20a880e3394f92ba079a19618e6bdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbd2be1223c746b08c06b8da4f3643fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd184b956cac4641b7a72f653d52777b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e3df02e97a54c42bee0f2c47b972ba1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0dbe139b07f0496db28bdcf90b628522",
      "value": 1
     }
    },
    "fd47e4a6863741a2b1e8f6848c41b2fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff74237547ba41daa5b7abb345f790dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fffbbf91eb1b459dbc8d9d00a215b76e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
